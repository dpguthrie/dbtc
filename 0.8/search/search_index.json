{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"An unaffiliated python interface for dbt Cloud APIs Documentation : https://dbtc.dpguthrie.com Interactive Demo : https://dpguthrie-dbtc-streamlit-home-yy7c0b.streamlit.app/ Source Code : https://github.com/dpguthrie/dbtc V2 Docs : https://docs.getdbt.com/dbt-cloud/api-v2 V3 Docs (Unofficial) : https://documenter.getpostman.com/view/14183654/UVsSNiXC Quick Intro \u00b6 Overview \u00b6 dbtc is an unaffiliated python interface to various dbt Cloud API endpoints. This library acts as a convenient interface to two different APIs that dbt Cloud offers: Cloud API : This is a REST API that exposes endpoints that allow users to programatically create, read, update, and delete resources within their dbt Cloud Account. Metadata API : This is a GraphQL API that exposes metadata generated from a job run within dbt Cloud. Requirements \u00b6 Python 3.7+ Requests - The elegant and simple HTTP library for Python, built for human beings. sgqlc - Simple GraphQL Client Typer - Library for building CLI applications Installation \u00b6 pip install dbtc Successfully installed dbtc restart \u21bb Basic Usage \u00b6 Python \u00b6 The interface to both APIs are located in the dbtCloudClient class. The example below shows how you use the cloud property on an instance of the dbtCloudClient class to access methods that allow for programmatic control over dbt Cloud resources. from dbtc import dbtCloudClient client = dbtCloudClient () project = client . cloud . get_project ( account_id = 1 , project_id = 1 ) CLI \u00b6 All of the methods available via the dbtCloudClient class are also available through the command line via dbtc . The same code above can be written as follows using the CLI: dbtc get-project --account-id = 1 --project-id = 1 License \u00b6 This project is licensed under the terms of the MIT license.","title":"Home"},{"location":"#quick-intro","text":"","title":"Quick Intro"},{"location":"#overview","text":"dbtc is an unaffiliated python interface to various dbt Cloud API endpoints. This library acts as a convenient interface to two different APIs that dbt Cloud offers: Cloud API : This is a REST API that exposes endpoints that allow users to programatically create, read, update, and delete resources within their dbt Cloud Account. Metadata API : This is a GraphQL API that exposes metadata generated from a job run within dbt Cloud.","title":"Overview"},{"location":"#requirements","text":"Python 3.7+ Requests - The elegant and simple HTTP library for Python, built for human beings. sgqlc - Simple GraphQL Client Typer - Library for building CLI applications","title":"Requirements"},{"location":"#installation","text":"pip install dbtc Successfully installed dbtc restart \u21bb","title":"Installation"},{"location":"#basic-usage","text":"","title":"Basic Usage"},{"location":"#python","text":"The interface to both APIs are located in the dbtCloudClient class. The example below shows how you use the cloud property on an instance of the dbtCloudClient class to access methods that allow for programmatic control over dbt Cloud resources. from dbtc import dbtCloudClient client = dbtCloudClient () project = client . cloud . get_project ( account_id = 1 , project_id = 1 )","title":"Python"},{"location":"#cli","text":"All of the methods available via the dbtCloudClient class are also available through the command line via dbtc . The same code above can be written as follows using the CLI: dbtc get-project --account-id = 1 --project-id = 1","title":"CLI"},{"location":"#license","text":"This project is licensed under the terms of the MIT license.","title":"License"},{"location":"changelog/","text":"Changelog \u00b6 [0.4.2] - 2023-04-03 \u00b6 Fixed \u00b6 How the base URL was constructed as it was not properly accounting for other regions, single tenant instances properly [0.4.1] - 2023-04-02 \u00b6 Added \u00b6 Most recent updates for the Metadata API schema [0.4.0] - 2023-03-18 \u00b6 Added \u00b6 List, test, create, get, update, and delete methods for webhooks Support for pydantic models used for validation logic when creating Webhooks - eventually will add support for other create methods Decorator that sets a private property on the _Client class, _called_from , that helps understand when methods are called from another method. Updated \u00b6 list_users is now using a v3 endpoint Removed \u00b6 All v4 methods were removed as dbt Cloud will begin to deprecate their use soon [0.3.7] - 2023-03-04 \u00b6 Added \u00b6 A max_run_slots keyword argument to the trigger_autoscaling_ci_job method. This will allow a user to limit the amount of run slots that can be occupied by CI jobs. The default value will be None, which will ensure that the normal behavior of this method remains intact (e.g. it will clone the CI job until the number of run slots configured for the account is reached). [0.3.6] - 2023-02-28 \u00b6 Fixed \u00b6 An additional read-only field from a job definition needed to be removed prior to creating the cloned job. 500 errors were occuring because of this. [0.3.5] - 2023-02-22 \u00b6 Added \u00b6 version argument to the CLI. Invoke with dbtc --version . Ability to track what methods are being used. Important to note that you can opt out of this by passing do_not_track=True to the dbtCloudClient class. Additionally, nothing identifiable, like IDs, will be tracked - simply a way to understand what methods of the package are being used. Fixed \u00b6 Bad type argument for poll_interval in the CLI method for trigger-job-from-failure [0.3.4] - 2023-01-27 \u00b6 Added \u00b6 Additional keyword arguments to filter the list_projects endpoint by - project_id , state , offset , and limit . The offset will be useful if an account has greater than 100 (the max projects that can be returned) projects. Additional keyword arguments to filter the list_jobs endpoint by - environment_id , state , offset , and limit . Important to note that the project_id can either be a single project_id integer or a list of project_ids Convenience methods to return the most recent run, get_most_recent_run , and the recent run artifact, get_most_recent_run_artifact . Additional keyword arguments to filter the list_environments endpoint by - dbt_version , name , type , state , offset , and limit . Important to note that the project_id can either be a single project_id integer or a list of project_ids. fields argument to the methods on the metadata property. This allows you to limit the data returned from the Metadata API while still not having to write any GraphQL! query method on the metadata property. This allows you to write a GraphQL query and supply variables Fixed \u00b6 A bug in get_project_by_name A bug in the CLI related to any methods that accept the include_related argument. This is now valid syntax '[\"debug_logs\", \"run_steps\"]' . [0.3.3] - 2022-11-14 \u00b6 Fixed \u00b6 Autoscaling CI jobs were being improperly cloned when adding a commit to the same PR. [0.3.2] - 2022-11-08 \u00b6 Fixed \u00b6 Finding in progress PR runs using the PR ID within the payload [0.3.1] - 2022-11-07 \u00b6 Fixed \u00b6 In progress runs weren't properly being cancelled within the trigger_autoscaling_ci_job method. In addiiton to checking if the job has an in progress run, this method will now also check if there is a run in a \"running\" state for the PR ID given in the payload. This will ensure that a single PR can only have one run occuring at a given time (this wasn't the case in 0.3.0). [0.3.0] - 2022-11-05 \u00b6 Added \u00b6 trigger_autoscaling_ci_job method to the cloud property of the dbtCloudClient class. Changed \u00b6 The restart from failure functionality has now been moved to it's own separate method, trigger_job_from_failure . You'll still be able to trigger a job using the trigger_job method. [0.2.4] - 2022-10-17 \u00b6 Fixed \u00b6 Non json artifacts are now able to be retrieved from get_run_artifact [0.2.3] - 2022-09-16 \u00b6 Fixed \u00b6 Bad url configuration for create_job method [0.2.2] - 2022-09-15 \u00b6 Fixed \u00b6 Global CLI args --warn-error and --use-experimental-parser were not being considered. If they were present in the command, the modified command would have been invalid. These are now included within the modified_command if present in the initial step's command. Added \u00b6 --full-refresh flag is now being pulled in the modified_command if present in the initial step's command. [0.2.1] - 2022-08-31 \u00b6 Fixed \u00b6 Checking for an invalid result \"skip\" instead of \"skipped\" when identifying nodes that need to be reran. [0.2.0] - 2022-08-30 \u00b6 Added \u00b6 The ability to restart a job from failure. The trigger_job method now accepts an argument restart_from_failure (default False ) that will determine whether or not the last run attempt for a job was unsuccessful - in the event it was, it will parse the steps within that job and find the nodes that it needs to rerun as well as any steps that were skipped entirely. Additional commands to the trigger_job method: should_poll - Indicate whether or not the method should poll for completion (default True ) poll_interval - How long in between polling requests (default 10 seconds) restart_from_failure - Described above trigger_on_failure_only - Only relevant when setting restart_from_failure to True . This has the effect, when set to True , of only triggering the job when the prior invocation was not successful. Otherwise, the function will exit prior to triggering the job (default False ) Logging to stderr when using the trigger_job method (internally using the rich package that comes when installing Typer ) Multiple tests for the restart_from_failure functionality Removed \u00b6 The trigger_job_and_poll method within the cloud property of the dbtCloudClient class. The polling functionality is now rolled up into the single trigger_job method with the argument should_poll (default is True ) [0.1.4] - 2022-07-11 \u00b6 Added \u00b6 get_model_by_environment to the metadata property meta field is now available when you query columns [0.1.3] - 2022-07-08 \u00b6 Added \u00b6 The metadata methods are now available via the CLI A status arg can now be used in the list_runs method on the cloud property [0.1.2] - 2022-06-30 \u00b6 Fixed \u00b6 The _dbt_cloud_request private method, which is used in the CLI, now only uses typer.echo to return data from a request. Changed \u00b6 The trigger_job_and_poll method now returns the Run , represented as a dict . It will no longer raise an exception if the result of the run is cancelled or error. [0.1.1] - 2022-05-16 \u00b6 Added \u00b6 The cloud property on the dbtCloudClient class now contains v3 endpoints [0.1.0] - 2022-05-13 \u00b6 Added \u00b6 dbtCloudClient class is the main interface to the dbt Cloud APIs. The cloud property contains methods that allow for programmatic access to different resources within dbt Cloud (e.g. dbtCloudClient().cloud.list_accounts() ). The metadata property contains methods that allow for retrieval of metadata related to a dbt Cloud job run (e.g. dbtCloudClient().metadata.get_models(job_id, run_id) ). dbtc is a command line interface to the methods on the dbtCloudClient class (e.g. dbtc list-accounts )","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#042-2023-04-03","text":"","title":"[0.4.2] - 2023-04-03"},{"location":"changelog/#fixed","text":"How the base URL was constructed as it was not properly accounting for other regions, single tenant instances properly","title":"Fixed"},{"location":"changelog/#041-2023-04-02","text":"","title":"[0.4.1] - 2023-04-02"},{"location":"changelog/#added","text":"Most recent updates for the Metadata API schema","title":"Added"},{"location":"changelog/#040-2023-03-18","text":"","title":"[0.4.0] - 2023-03-18"},{"location":"changelog/#added_1","text":"List, test, create, get, update, and delete methods for webhooks Support for pydantic models used for validation logic when creating Webhooks - eventually will add support for other create methods Decorator that sets a private property on the _Client class, _called_from , that helps understand when methods are called from another method.","title":"Added"},{"location":"changelog/#updated","text":"list_users is now using a v3 endpoint","title":"Updated"},{"location":"changelog/#removed","text":"All v4 methods were removed as dbt Cloud will begin to deprecate their use soon","title":"Removed"},{"location":"changelog/#037-2023-03-04","text":"","title":"[0.3.7] - 2023-03-04"},{"location":"changelog/#added_2","text":"A max_run_slots keyword argument to the trigger_autoscaling_ci_job method. This will allow a user to limit the amount of run slots that can be occupied by CI jobs. The default value will be None, which will ensure that the normal behavior of this method remains intact (e.g. it will clone the CI job until the number of run slots configured for the account is reached).","title":"Added"},{"location":"changelog/#036-2023-02-28","text":"","title":"[0.3.6] - 2023-02-28"},{"location":"changelog/#fixed_1","text":"An additional read-only field from a job definition needed to be removed prior to creating the cloned job. 500 errors were occuring because of this.","title":"Fixed"},{"location":"changelog/#035-2023-02-22","text":"","title":"[0.3.5] - 2023-02-22"},{"location":"changelog/#added_3","text":"version argument to the CLI. Invoke with dbtc --version . Ability to track what methods are being used. Important to note that you can opt out of this by passing do_not_track=True to the dbtCloudClient class. Additionally, nothing identifiable, like IDs, will be tracked - simply a way to understand what methods of the package are being used.","title":"Added"},{"location":"changelog/#fixed_2","text":"Bad type argument for poll_interval in the CLI method for trigger-job-from-failure","title":"Fixed"},{"location":"changelog/#034-2023-01-27","text":"","title":"[0.3.4] - 2023-01-27"},{"location":"changelog/#added_4","text":"Additional keyword arguments to filter the list_projects endpoint by - project_id , state , offset , and limit . The offset will be useful if an account has greater than 100 (the max projects that can be returned) projects. Additional keyword arguments to filter the list_jobs endpoint by - environment_id , state , offset , and limit . Important to note that the project_id can either be a single project_id integer or a list of project_ids Convenience methods to return the most recent run, get_most_recent_run , and the recent run artifact, get_most_recent_run_artifact . Additional keyword arguments to filter the list_environments endpoint by - dbt_version , name , type , state , offset , and limit . Important to note that the project_id can either be a single project_id integer or a list of project_ids. fields argument to the methods on the metadata property. This allows you to limit the data returned from the Metadata API while still not having to write any GraphQL! query method on the metadata property. This allows you to write a GraphQL query and supply variables","title":"Added"},{"location":"changelog/#fixed_3","text":"A bug in get_project_by_name A bug in the CLI related to any methods that accept the include_related argument. This is now valid syntax '[\"debug_logs\", \"run_steps\"]' .","title":"Fixed"},{"location":"changelog/#033-2022-11-14","text":"","title":"[0.3.3] - 2022-11-14"},{"location":"changelog/#fixed_4","text":"Autoscaling CI jobs were being improperly cloned when adding a commit to the same PR.","title":"Fixed"},{"location":"changelog/#032-2022-11-08","text":"","title":"[0.3.2] - 2022-11-08"},{"location":"changelog/#fixed_5","text":"Finding in progress PR runs using the PR ID within the payload","title":"Fixed"},{"location":"changelog/#031-2022-11-07","text":"","title":"[0.3.1] - 2022-11-07"},{"location":"changelog/#fixed_6","text":"In progress runs weren't properly being cancelled within the trigger_autoscaling_ci_job method. In addiiton to checking if the job has an in progress run, this method will now also check if there is a run in a \"running\" state for the PR ID given in the payload. This will ensure that a single PR can only have one run occuring at a given time (this wasn't the case in 0.3.0).","title":"Fixed"},{"location":"changelog/#030-2022-11-05","text":"","title":"[0.3.0] - 2022-11-05"},{"location":"changelog/#added_5","text":"trigger_autoscaling_ci_job method to the cloud property of the dbtCloudClient class.","title":"Added"},{"location":"changelog/#changed","text":"The restart from failure functionality has now been moved to it's own separate method, trigger_job_from_failure . You'll still be able to trigger a job using the trigger_job method.","title":"Changed"},{"location":"changelog/#024-2022-10-17","text":"","title":"[0.2.4] - 2022-10-17"},{"location":"changelog/#fixed_7","text":"Non json artifacts are now able to be retrieved from get_run_artifact","title":"Fixed"},{"location":"changelog/#023-2022-09-16","text":"","title":"[0.2.3] - 2022-09-16"},{"location":"changelog/#fixed_8","text":"Bad url configuration for create_job method","title":"Fixed"},{"location":"changelog/#022-2022-09-15","text":"","title":"[0.2.2] - 2022-09-15"},{"location":"changelog/#fixed_9","text":"Global CLI args --warn-error and --use-experimental-parser were not being considered. If they were present in the command, the modified command would have been invalid. These are now included within the modified_command if present in the initial step's command.","title":"Fixed"},{"location":"changelog/#added_6","text":"--full-refresh flag is now being pulled in the modified_command if present in the initial step's command.","title":"Added"},{"location":"changelog/#021-2022-08-31","text":"","title":"[0.2.1] - 2022-08-31"},{"location":"changelog/#fixed_10","text":"Checking for an invalid result \"skip\" instead of \"skipped\" when identifying nodes that need to be reran.","title":"Fixed"},{"location":"changelog/#020-2022-08-30","text":"","title":"[0.2.0] - 2022-08-30"},{"location":"changelog/#added_7","text":"The ability to restart a job from failure. The trigger_job method now accepts an argument restart_from_failure (default False ) that will determine whether or not the last run attempt for a job was unsuccessful - in the event it was, it will parse the steps within that job and find the nodes that it needs to rerun as well as any steps that were skipped entirely. Additional commands to the trigger_job method: should_poll - Indicate whether or not the method should poll for completion (default True ) poll_interval - How long in between polling requests (default 10 seconds) restart_from_failure - Described above trigger_on_failure_only - Only relevant when setting restart_from_failure to True . This has the effect, when set to True , of only triggering the job when the prior invocation was not successful. Otherwise, the function will exit prior to triggering the job (default False ) Logging to stderr when using the trigger_job method (internally using the rich package that comes when installing Typer ) Multiple tests for the restart_from_failure functionality","title":"Added"},{"location":"changelog/#removed_1","text":"The trigger_job_and_poll method within the cloud property of the dbtCloudClient class. The polling functionality is now rolled up into the single trigger_job method with the argument should_poll (default is True )","title":"Removed"},{"location":"changelog/#014-2022-07-11","text":"","title":"[0.1.4] - 2022-07-11"},{"location":"changelog/#added_8","text":"get_model_by_environment to the metadata property meta field is now available when you query columns","title":"Added"},{"location":"changelog/#013-2022-07-08","text":"","title":"[0.1.3] - 2022-07-08"},{"location":"changelog/#added_9","text":"The metadata methods are now available via the CLI A status arg can now be used in the list_runs method on the cloud property","title":"Added"},{"location":"changelog/#012-2022-06-30","text":"","title":"[0.1.2] - 2022-06-30"},{"location":"changelog/#fixed_11","text":"The _dbt_cloud_request private method, which is used in the CLI, now only uses typer.echo to return data from a request.","title":"Fixed"},{"location":"changelog/#changed_1","text":"The trigger_job_and_poll method now returns the Run , represented as a dict . It will no longer raise an exception if the result of the run is cancelled or error.","title":"Changed"},{"location":"changelog/#011-2022-05-16","text":"","title":"[0.1.1] - 2022-05-16"},{"location":"changelog/#added_10","text":"The cloud property on the dbtCloudClient class now contains v3 endpoints","title":"Added"},{"location":"changelog/#010-2022-05-13","text":"","title":"[0.1.0] - 2022-05-13"},{"location":"changelog/#added_11","text":"dbtCloudClient class is the main interface to the dbt Cloud APIs. The cloud property contains methods that allow for programmatic access to different resources within dbt Cloud (e.g. dbtCloudClient().cloud.list_accounts() ). The metadata property contains methods that allow for retrieval of metadata related to a dbt Cloud job run (e.g. dbtCloudClient().metadata.get_models(job_id, run_id) ). dbtc is a command line interface to the methods on the dbtCloudClient class (e.g. dbtc list-accounts )","title":"Added"},{"location":"guide/autoscaling_ci/","text":"Autoscaling CI \u00b6 Thank You! As with the restart from failure functionality, a lot of credit goes to @matt-winkler for developing this feature. Intro \u00b6 Summary \u00b6 This library offers a convenient interface to create, what we call, an autoscaling CI job. As of the time of this writing (11/5/22), dbt Cloud does not allow a job to have concurrent runs. This largely makes sense in the context of regularly scheduled jobs - you would never want your daily job to be run in a concurrent fashion. However, this feature starts to become a limitation in the context of continuous integration (CI) jobs. Take the following scenarios: Adding a commit to an existing pull request that already has a job running Opening a separate pull request in the same repo that already has a running CI job In both of these instances, we'll have to wait until the existing job has completed before that same CI job can move from a queued state. How it Works \u00b6 In the event your CI job is already running, this package, through the trigger_autoscaling_ci_job method, will do the following: If a new commit is created for the pull request linked to the existing run for the referenced job, cancel the run and trigger again. If this is an entirely new pull request, clone the job definition and trigger the clone. It's important to note that the cloned job will be deleted by default after the run (you can change this through an argument to the function). Deleting the cloned job will also force the execution into a polling state (e.g. the function won't return a Run until it has encountered a completed state). This will also check to see if your account has met or exceeded the allotted run slots. In the event you have, a cloned job will not be created and the existing job will be triggered. Considerations \u00b6 dbt Cloud \u00b6 Normally, when you configure a dbt Cloud CI job , you'll do the following: Defer to another job Include a command with a state:modified+ selector And, trigger it via pull request To use this functionality, you want to follow all of the steps above EXCEPT the trigger piece. The action that you setup in your repo will take care of triggering the dbt Cloud job, so if you also check that checkbox, you'll be triggering this job in two different places. Payload \u00b6 In order to mimic the native Slim CI behavior within dbt Cloud, it's important to pass the appropriate payload. The payload should consist of the following (this is in the context of running against a github repository but it will be very similar across Gitlab and ADO). cause - Put whatever you want here - this is a required field schema_override - \"dbt_cloud_pr_\"$JOB_ID\"_\"$PULL_REQUEST_ID git_sha - ${{ github.event.pull_request.head.sha }} Depending on your git provider, one of github_pull_request_id , gitlab_merge_request_id , or azure_pull_request_id (in the GH action example, set to ${{ github.event.number }} ) Recommended Use \u00b6 This method is best suited to be used within a Github Action, Gitlab CI Pipeline, or an Azure Pipeline. The example below shows how you can use it within a Github Action. Examples \u00b6 Python CLI Github Action Response from dbtc import dbtCloudClient # Assumes I have DBT_CLOUD_SERVICE_TOKEN as an environment variable client = dbtCloudClient () account_id = 1 job_id = 1 payload = { 'cause' : 'Autoscaling CI' , 'schema_override' : 'dbt_cloud_pr_1_50' , 'github_pull_request_id' : 50 , 'git_sha' : 'jkafjdkfjallakjf' } run = client . cloud . trigger_autoscaling_ci_job ( account_id , job_id , payload ) Assuming that DBT_CLOUD_SERVICE_TOKEN and DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc trigger-autoscaling-ci-job \\ --job-id = $JOB_ID \\ --payload = '{\"cause\": \"Autoscaling Slim CI!\",\"git_sha\":\"' \" $GIT_SHA \" '\",\"schema_override\":\"' \" $SO \" '\",\"github_pull_request_id\":' \" $PULL_REQUEST_ID \" '}' \\ --no-should-poll ) Required : You'll need to create a secret in your repo called DBT_CLOUD_SERVICE_TOKEN . The token can be obtained from dbt Cloud name : Autoscaling dbt Cloud CI on : pull_request : branches : - main types : - opened - reopened - synchronize - ready_for_review jobs : autoscaling : if : github.event.pull_request.draft == false runs-on : ubuntu-latest env : DBT_CLOUD_SERVICE_TOKEN : ${{ secrets.DBT_CLOUD_SERVICE_TOKEN }} DBT_CLOUD_ACCOUNT_ID : 43786 JOB_ID : 73797 PULL_REQUEST_ID : ${{ github.event.number }} GIT_SHA : ${{ github.event.pull_request.head.sha }} steps : - uses : actions/checkout@v2 - uses : actions/setup-python@v2 with : python-version : \"3.9.x\" - name : Trigger Autoscaling CI Job run : | pip install dbtc==0.3.3 SO=\"dbt_cloud_pr_\"$JOB_ID\"_\"$PULL_REQUEST_ID run=$(dbtc trigger-autoscaling-ci-job \\ --job-id=$JOB_ID \\ --payload='{\"cause\": \"Autoscaling Slim CI!\",\"git_sha\":\"'\"$GIT_SHA\"'\",\"schema_override\":\"'\"$SO\"'\",\"github_pull_request_id\":'\"$PULL_REQUEST_ID\"'}' \\ --no-should-poll) { 's tatus ' : { 'code' : 200 , 'is_success' : True , 'user_message' : 'Success!' , 'developer_message' : '' }, 'da ta ' : { 'id' : 78614274 , ' tr igger_id' : 79329387 , 'accou nt _id' : 1 , 'e n viro n me nt _id' : 1 , 'projec t _id' : 1 , 'job_de f i n i t io n _id' : 1 , 's tatus ' : 1 , 'db t _versio n ' : ' 1.2.0- la test ' , 'gi t _bra n ch' : No ne , 'gi t _sha' : No ne , 's tatus _message' : No ne , 'ow ner _ t hread_id' : No ne , 'execu te d_by_ t hread_id' : No ne , 'de ferr i n g_ru n _id' : No ne , 'ar t i fa c ts _saved' : False , 'ar t i fa c t _s 3 _pa t h' : No ne , 'has_docs_ge nerate d' : False , 'has_sources_ge nerate d' : False , ' n o t i f ica t io ns _se nt ' : False , 'blocked_by' : [], 'scribe_e na bled' : True , 'crea te d_a t ' : ' 2022-08-31 02 : 18 : 57.855152+00 : 00 ' , 'upda te d_a t ' : ' 2022-08-31 02 : 18 : 57.855169+00 : 00 ' , 'dequeued_a t ' : No ne , 's tarte d_a t ' : No ne , ' f i n ished_a t ' : No ne , 'las t _checked_a t ' : No ne , 'las t _hear t bea t _a t ' : No ne , 'should_s tart _a t ' : No ne , ' tr igger' : { 'id' : 79329387 , 'cause' : 'Jus t cause' , 'job_de f i n i t io n _id' : 1 , 'gi t _bra n ch' : No ne , 'gi t _sha' : No ne , 'azure_pull_reques t _id' : No ne , 'gi t hub_pull_reques t _id' : No ne , 'gi tla b_merge_reques t _id' : No ne , 'schema_override' : No ne , 'db t _versio n _override' : No ne , ' t hreads_override' : No ne , ' tar ge t _ na me_override' : No ne , 'ge nerate _docs_override' : No ne , ' t imeou t _seco n ds_override' : No ne , 's te ps_override' : [ 'db t ru n - s bad_model -- vars \\' { \"key\" : \"value\" } \\'' ], 'crea te d_a t ' : ' 2022-08-31 02 : 18 : 57.846515+00 : 00 ' , 'cause_huma n ized' : 'Jus t cause' , 'job' : No ne }, 'job' : { 'execu t io n ' : { ' t imeou t _seco n ds' : 0 }, 'ge nerate _docs' : False , 'ru n _ge nerate _sources' : False , 'id' : 1 , 'accou nt _id' : 1 , 'projec t _id' : 1 , 'e n viro n me nt _id' : 1 , ' na me' : 'Tes t 10 - Res tart wi t h Vars' , 'db t _versio n ' : No ne , 'crea te d_a t ' : ' 2022-08-29 T 14 : 02 : 57.378279 Z' , 'upda te d_a t ' : ' 2022-08-29 T 14 : 06 : 31.485879 Z' , 'execu te _s te ps' : [ 'db t ru n - s good_model bad_model -- vars \\' { \"key\" : \"value\" } \\'' ], 's tate ' : 1 , 'deac t iva te d' : False , 'ru n _ fa ilure_cou nt ' : 0 , 'de ferr i n g_job_de f i n i t io n _id' : No ne , 'li fe cycle_webhooks' : False , 'li fe cycle_webhooks_url' : No ne , ' tr iggers' : { 'gi t hub_webhook' : False , 'gi t _provider_webhook' : False , 'cus t om_bra n ch_o nl y' : False , 'schedule' : False }, 'se tt i n gs' : { ' t hreads' : 4 , ' tar ge t _ na me' : 'de fault ' }, 'schedule' : { 'cro n ' : ' 0 * * * 0 , 1 , 2 , 3 , 4 , 5 , 6 ' , 'da te ' : 'days_o f _week' , ' t ime' : 'every_hour' }, 'is_de ferra ble' : False }, 'e n viro n me nt ' : No ne , 'ru n _s te ps' : [], 's tatus _huma n ized' : 'Queued' , 'i n _progress' : True , 'is_comple te ' : False , 'is_success' : False , 'is_error' : False , 'is_ca n celled' : False , 'hre f ' : 'h tt ps : //cloud.getdbt.com/#/accounts/43786/projects/146089/runs/78614274/', 'dura t io n ' : ' 00 : 00 : 00 ' , 'queued_dura t io n ' : ' 00 : 00 : 00 ' , 'ru n _dura t io n ' : ' 00 : 00 : 00 ' , 'dura t io n _huma n ized' : ' 0 mi nutes ' , 'queued_dura t io n _huma n ized' : ' 0 mi nutes ' , 'ru n _dura t io n _huma n ized' : ' 0 mi nutes ' , 'crea te d_a t _huma n ized' : ' 0 mi nutes ago' , ' f i n ished_a t _huma n ized' : ' 0 mi nutes fr om n ow' , 'job_id' : 1 , 'is_ru nn i n g' : No ne } }","title":"Autoscaling CI"},{"location":"guide/autoscaling_ci/#autoscaling-ci","text":"Thank You! As with the restart from failure functionality, a lot of credit goes to @matt-winkler for developing this feature.","title":"Autoscaling CI"},{"location":"guide/autoscaling_ci/#intro","text":"","title":"Intro"},{"location":"guide/autoscaling_ci/#summary","text":"This library offers a convenient interface to create, what we call, an autoscaling CI job. As of the time of this writing (11/5/22), dbt Cloud does not allow a job to have concurrent runs. This largely makes sense in the context of regularly scheduled jobs - you would never want your daily job to be run in a concurrent fashion. However, this feature starts to become a limitation in the context of continuous integration (CI) jobs. Take the following scenarios: Adding a commit to an existing pull request that already has a job running Opening a separate pull request in the same repo that already has a running CI job In both of these instances, we'll have to wait until the existing job has completed before that same CI job can move from a queued state.","title":"Summary"},{"location":"guide/autoscaling_ci/#how-it-works","text":"In the event your CI job is already running, this package, through the trigger_autoscaling_ci_job method, will do the following: If a new commit is created for the pull request linked to the existing run for the referenced job, cancel the run and trigger again. If this is an entirely new pull request, clone the job definition and trigger the clone. It's important to note that the cloned job will be deleted by default after the run (you can change this through an argument to the function). Deleting the cloned job will also force the execution into a polling state (e.g. the function won't return a Run until it has encountered a completed state). This will also check to see if your account has met or exceeded the allotted run slots. In the event you have, a cloned job will not be created and the existing job will be triggered.","title":"How it Works"},{"location":"guide/autoscaling_ci/#considerations","text":"","title":"Considerations"},{"location":"guide/autoscaling_ci/#dbt-cloud","text":"Normally, when you configure a dbt Cloud CI job , you'll do the following: Defer to another job Include a command with a state:modified+ selector And, trigger it via pull request To use this functionality, you want to follow all of the steps above EXCEPT the trigger piece. The action that you setup in your repo will take care of triggering the dbt Cloud job, so if you also check that checkbox, you'll be triggering this job in two different places.","title":"dbt Cloud"},{"location":"guide/autoscaling_ci/#payload","text":"In order to mimic the native Slim CI behavior within dbt Cloud, it's important to pass the appropriate payload. The payload should consist of the following (this is in the context of running against a github repository but it will be very similar across Gitlab and ADO). cause - Put whatever you want here - this is a required field schema_override - \"dbt_cloud_pr_\"$JOB_ID\"_\"$PULL_REQUEST_ID git_sha - ${{ github.event.pull_request.head.sha }} Depending on your git provider, one of github_pull_request_id , gitlab_merge_request_id , or azure_pull_request_id (in the GH action example, set to ${{ github.event.number }} )","title":"Payload"},{"location":"guide/autoscaling_ci/#recommended-use","text":"This method is best suited to be used within a Github Action, Gitlab CI Pipeline, or an Azure Pipeline. The example below shows how you can use it within a Github Action.","title":"Recommended Use"},{"location":"guide/autoscaling_ci/#examples","text":"Python CLI Github Action Response from dbtc import dbtCloudClient # Assumes I have DBT_CLOUD_SERVICE_TOKEN as an environment variable client = dbtCloudClient () account_id = 1 job_id = 1 payload = { 'cause' : 'Autoscaling CI' , 'schema_override' : 'dbt_cloud_pr_1_50' , 'github_pull_request_id' : 50 , 'git_sha' : 'jkafjdkfjallakjf' } run = client . cloud . trigger_autoscaling_ci_job ( account_id , job_id , payload ) Assuming that DBT_CLOUD_SERVICE_TOKEN and DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc trigger-autoscaling-ci-job \\ --job-id = $JOB_ID \\ --payload = '{\"cause\": \"Autoscaling Slim CI!\",\"git_sha\":\"' \" $GIT_SHA \" '\",\"schema_override\":\"' \" $SO \" '\",\"github_pull_request_id\":' \" $PULL_REQUEST_ID \" '}' \\ --no-should-poll ) Required : You'll need to create a secret in your repo called DBT_CLOUD_SERVICE_TOKEN . The token can be obtained from dbt Cloud name : Autoscaling dbt Cloud CI on : pull_request : branches : - main types : - opened - reopened - synchronize - ready_for_review jobs : autoscaling : if : github.event.pull_request.draft == false runs-on : ubuntu-latest env : DBT_CLOUD_SERVICE_TOKEN : ${{ secrets.DBT_CLOUD_SERVICE_TOKEN }} DBT_CLOUD_ACCOUNT_ID : 43786 JOB_ID : 73797 PULL_REQUEST_ID : ${{ github.event.number }} GIT_SHA : ${{ github.event.pull_request.head.sha }} steps : - uses : actions/checkout@v2 - uses : actions/setup-python@v2 with : python-version : \"3.9.x\" - name : Trigger Autoscaling CI Job run : | pip install dbtc==0.3.3 SO=\"dbt_cloud_pr_\"$JOB_ID\"_\"$PULL_REQUEST_ID run=$(dbtc trigger-autoscaling-ci-job \\ --job-id=$JOB_ID \\ --payload='{\"cause\": \"Autoscaling Slim CI!\",\"git_sha\":\"'\"$GIT_SHA\"'\",\"schema_override\":\"'\"$SO\"'\",\"github_pull_request_id\":'\"$PULL_REQUEST_ID\"'}' \\ --no-should-poll) { 's tatus ' : { 'code' : 200 , 'is_success' : True , 'user_message' : 'Success!' , 'developer_message' : '' }, 'da ta ' : { 'id' : 78614274 , ' tr igger_id' : 79329387 , 'accou nt _id' : 1 , 'e n viro n me nt _id' : 1 , 'projec t _id' : 1 , 'job_de f i n i t io n _id' : 1 , 's tatus ' : 1 , 'db t _versio n ' : ' 1.2.0- la test ' , 'gi t _bra n ch' : No ne , 'gi t _sha' : No ne , 's tatus _message' : No ne , 'ow ner _ t hread_id' : No ne , 'execu te d_by_ t hread_id' : No ne , 'de ferr i n g_ru n _id' : No ne , 'ar t i fa c ts _saved' : False , 'ar t i fa c t _s 3 _pa t h' : No ne , 'has_docs_ge nerate d' : False , 'has_sources_ge nerate d' : False , ' n o t i f ica t io ns _se nt ' : False , 'blocked_by' : [], 'scribe_e na bled' : True , 'crea te d_a t ' : ' 2022-08-31 02 : 18 : 57.855152+00 : 00 ' , 'upda te d_a t ' : ' 2022-08-31 02 : 18 : 57.855169+00 : 00 ' , 'dequeued_a t ' : No ne , 's tarte d_a t ' : No ne , ' f i n ished_a t ' : No ne , 'las t _checked_a t ' : No ne , 'las t _hear t bea t _a t ' : No ne , 'should_s tart _a t ' : No ne , ' tr igger' : { 'id' : 79329387 , 'cause' : 'Jus t cause' , 'job_de f i n i t io n _id' : 1 , 'gi t _bra n ch' : No ne , 'gi t _sha' : No ne , 'azure_pull_reques t _id' : No ne , 'gi t hub_pull_reques t _id' : No ne , 'gi tla b_merge_reques t _id' : No ne , 'schema_override' : No ne , 'db t _versio n _override' : No ne , ' t hreads_override' : No ne , ' tar ge t _ na me_override' : No ne , 'ge nerate _docs_override' : No ne , ' t imeou t _seco n ds_override' : No ne , 's te ps_override' : [ 'db t ru n - s bad_model -- vars \\' { \"key\" : \"value\" } \\'' ], 'crea te d_a t ' : ' 2022-08-31 02 : 18 : 57.846515+00 : 00 ' , 'cause_huma n ized' : 'Jus t cause' , 'job' : No ne }, 'job' : { 'execu t io n ' : { ' t imeou t _seco n ds' : 0 }, 'ge nerate _docs' : False , 'ru n _ge nerate _sources' : False , 'id' : 1 , 'accou nt _id' : 1 , 'projec t _id' : 1 , 'e n viro n me nt _id' : 1 , ' na me' : 'Tes t 10 - Res tart wi t h Vars' , 'db t _versio n ' : No ne , 'crea te d_a t ' : ' 2022-08-29 T 14 : 02 : 57.378279 Z' , 'upda te d_a t ' : ' 2022-08-29 T 14 : 06 : 31.485879 Z' , 'execu te _s te ps' : [ 'db t ru n - s good_model bad_model -- vars \\' { \"key\" : \"value\" } \\'' ], 's tate ' : 1 , 'deac t iva te d' : False , 'ru n _ fa ilure_cou nt ' : 0 , 'de ferr i n g_job_de f i n i t io n _id' : No ne , 'li fe cycle_webhooks' : False , 'li fe cycle_webhooks_url' : No ne , ' tr iggers' : { 'gi t hub_webhook' : False , 'gi t _provider_webhook' : False , 'cus t om_bra n ch_o nl y' : False , 'schedule' : False }, 'se tt i n gs' : { ' t hreads' : 4 , ' tar ge t _ na me' : 'de fault ' }, 'schedule' : { 'cro n ' : ' 0 * * * 0 , 1 , 2 , 3 , 4 , 5 , 6 ' , 'da te ' : 'days_o f _week' , ' t ime' : 'every_hour' }, 'is_de ferra ble' : False }, 'e n viro n me nt ' : No ne , 'ru n _s te ps' : [], 's tatus _huma n ized' : 'Queued' , 'i n _progress' : True , 'is_comple te ' : False , 'is_success' : False , 'is_error' : False , 'is_ca n celled' : False , 'hre f ' : 'h tt ps : //cloud.getdbt.com/#/accounts/43786/projects/146089/runs/78614274/', 'dura t io n ' : ' 00 : 00 : 00 ' , 'queued_dura t io n ' : ' 00 : 00 : 00 ' , 'ru n _dura t io n ' : ' 00 : 00 : 00 ' , 'dura t io n _huma n ized' : ' 0 mi nutes ' , 'queued_dura t io n _huma n ized' : ' 0 mi nutes ' , 'ru n _dura t io n _huma n ized' : ' 0 mi nutes ' , 'crea te d_a t _huma n ized' : ' 0 mi nutes ago' , ' f i n ished_a t _huma n ized' : ' 0 mi nutes fr om n ow' , 'job_id' : 1 , 'is_ru nn i n g' : No ne } }","title":"Examples"},{"location":"guide/cloud/","text":"Cloud \u00b6 The cloud property on the dbtCloudClient class contains methods that allow a user to perform CRUD operations against dbt Cloud resources. Account \u00b6 get_account \u00b6 Get an account by its ID. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required Source code in dbtc/client/admin.py 508 509 510 511 512 513 514 515 @v2 def get_account ( self , account_id : int ) -> Dict : \"\"\"Get an account by its ID. Args: account_id (int): Numeric ID of the account to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } \" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_account ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-account get_account_by_name \u00b6 Get an account by its name. Parameters: Name Type Description Default account_name str Name of an account required Source code in dbtc/client/admin.py 517 518 519 520 521 522 523 524 525 526 527 528 529 530 @set_called_from @v2 def get_account_by_name ( self , account_name : str ) -> Dict : \"\"\"Get an account by its name. Args: account_name (str): Name of an account \"\"\" accounts = self . list_accounts () account = self . _get_by_name ( accounts [ \"data\" ], account_name ) if account is not None : return self . get_account ( account [ \"id\" ]) raise Exception ( f 'Account \" { account_name } \" was not found' ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_account_by_name ( account_name ) dbtc get-account-by-name --account-name = name get_account_licenses \u00b6 List account licenses for a specified account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required Source code in dbtc/client/admin.py 532 533 534 535 536 537 538 539 @v2 def get_account_licenses ( self , account_id : int ) -> Dict : \"\"\"List account licenses for a specified account. Args: account_id (int): Numeric ID of the account to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /licenses\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_account_licenses ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-account-licenses list_accounts \u00b6 List of accounts that your API Token is authorized to access. Source code in dbtc/client/admin.py 821 822 823 824 @v2 def list_accounts ( self ) -> Dict : \"\"\"List of accounts that your API Token is authorized to access.\"\"\" return self . _simple_request ( \"accounts/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_accounts () dbtc list-accounts Artifact \u00b6 get_most_recent_run_artifact \u00b6 Fetch artifacts from the most recent run Once a run has completed, you can use this endpoint to download the manifest.json , run_results.json or catalog.json files from dbt Cloud. These artifacts contain information about the models in your dbt project, timing information around their execution, and a status message indicating the result of the model build. Note By default, this endpoint returns artifacts from the last step in the run. To list artifacts from other steps in the run, use the step query parameter described below. Warning If requesting a non JSON artifact, the result will be a str Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required path str Paths are rooted at the target/ directory. Use manifest.json, catalog.json, or run_results.json to download dbt-generated artifacts for the run. required job_definition_id int Applies a filter to only return runs from the specified Job. None environment_id int Numeric ID of the environment None project_id int or list The project ID or IDs None deferring_run_id int Numeric ID of a deferred run None step str The index of the Step in the Run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this endpoint will return the artifacts compiled for the last step in the run. None Source code in dbtc/client/admin.py 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 @set_called_from @v2 def get_most_recent_run_artifact ( self , account_id : int , path : str , * , job_definition_id : int = None , environment_id : int = None , project_id : int = None , deferring_run_id : int = None , step : int = None , ): \"\"\"Fetch artifacts from the most recent run Once a run has completed, you can use this endpoint to download the `manifest.json`, `run_results.json` or `catalog.json` files from dbt Cloud. These artifacts contain information about the models in your dbt project, timing information around their execution, and a status message indicating the result of the model build. !!! note By default, this endpoint returns artifacts from the last step in the run. To list artifacts from other steps in the run, use the step query parameter described below. !!! warning If requesting a non JSON artifact, the result will be a `str` Args: account_id (int): Numeric ID of the account to retrieve path (str): Paths are rooted at the target/ directory. Use manifest.json, catalog.json, or run_results.json to download dbt-generated artifacts for the run. job_definition_id (int, optional): Applies a filter to only return runs from the specified Job. environment_id (int, optional): Numeric ID of the environment project_id (int or list, optional): The project ID or IDs deferring_run_id (int, optional): Numeric ID of a deferred run step (str, optional): The index of the Step in the Run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this endpoint will return the artifacts compiled for the last step in the run. \"\"\" runs = self . get_most_recent_run ( account_id , job_definition_id = job_definition_id , environment_id = environment_id , project_id = project_id , deferring_run_id = deferring_run_id , status = \"success\" , ) # Reset called from after being set to None in get_most_recent_run self . _called_from = \"get_most_recent_run_artifact\" try : run_id = runs . get ( \"data\" , {})[ \"id\" ] except KeyError : raise Exception ( \"A run could not be found with the provided arguments.\" ) else : return self . get_run_artifact ( account_id , run_id , path , step = step ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_most_recent_run_artifact ( account_id , path ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-most-recent-run-artifact --path manifest.json get_run_artifact \u00b6 Fetch artifacts from a completed run. Once a run has completed, you can use this endpoint to download the manifest.json , run_results.json or catalog.json files from dbt Cloud. These artifacts contain information about the models in your dbt project, timing information around their execution, and a status message indicating the result of the model build. Note By default, this endpoint returns artifacts from the last step in the run. To list artifacts from other steps in the run, use the step query parameter described below. Warning If requesting a non JSON artifact, the result will be a str Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required run_id int Numeric ID of the run to retrieve required path str Paths are rooted at the target/ directory. Use manifest.json, catalog.json, or run_results.json to download dbt-generated artifacts for the run. required step str The index of the Step in the Run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this endpoint will return the artifacts compiled for the last step in the run. None Source code in dbtc/client/admin.py 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 @v2 def get_run_artifact ( self , account_id : int , run_id : int , path : str , * , step : int = None , ) -> Union [ str , Dict ]: \"\"\"Fetch artifacts from a completed run. Once a run has completed, you can use this endpoint to download the `manifest.json`, `run_results.json` or `catalog.json` files from dbt Cloud. These artifacts contain information about the models in your dbt project, timing information around their execution, and a status message indicating the result of the model build. !!! note By default, this endpoint returns artifacts from the last step in the run. To list artifacts from other steps in the run, use the step query parameter described below. !!! warning If requesting a non JSON artifact, the result will be a `str` Args: account_id (int): Numeric ID of the account to retrieve run_id (int): Numeric ID of the run to retrieve path (str): Paths are rooted at the target/ directory. Use manifest.json, catalog.json, or run_results.json to download dbt-generated artifacts for the run. step (str, optional): The index of the Step in the Run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this endpoint will return the artifacts compiled for the last step in the run. \"\"\" url_path = f \"accounts/ { account_id } /runs/ { run_id } /artifacts/ { path } \" params = { \"step\" : step } if path [ - 5 :] == \".json\" : return self . _simple_request ( url_path , params = params ) response = self . _make_request ( url_path , params = params ) return response . text Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_run_artifact ( account_id , run_id , path ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-run-artifact --run-id = 1 --path = manifest.json list_run_artifacts \u00b6 Fetch a list of artifact files generated for a completed run. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required run_id int Numeric ID of the run to retrieve required step str The index of the Step in the Run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this endpoint will return the artifacts compiled for the last step in the run. None Source code in dbtc/client/admin.py 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 @v2 def list_run_artifacts ( self , account_id : int , run_id : int , * , step : int = None , ) -> Dict : \"\"\"Fetch a list of artifact files generated for a completed run. Args: account_id (int): Numeric ID of the account to retrieve run_id (int): Numeric ID of the run to retrieve step (str, optional): The index of the Step in the Run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this endpoint will return the artifacts compiled for the last step in the run. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /runs/ { run_id } /artifacts\" , params = { \"step\" : step }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_run_artifacts ( account_id , run_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-environments --run-id = 1 Audit Log \u00b6 list_audit_logs \u00b6 List audit logs for a specific account Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required logged_at_start str Date to begin retrieving audit logs Format is yyyy-mm-dd None logged_at_end str Date to stop retrieving audit logs. Format is yyyy-mm-dd None offset int The offset to apply when listing runs. Use with limit to paginate results. None limit int The limit to apply when listing runs. Use with offset to paginate results. None Source code in dbtc/client/admin.py 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 @v3 def list_audit_logs ( self , account_id : int , * , logged_at_start : str = None , logged_at_end : str = None , offset : int = None , limit : int = None , ) -> Dict : \"\"\"List audit logs for a specific account Args: account_id (int): Numeric ID of the account to retrieve logged_at_start (str, optional): Date to begin retrieving audit logs Format is yyyy-mm-dd logged_at_end (str, optional): Date to stop retrieving audit logs. Format is yyyy-mm-dd offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /audit-logs\" , params = { \"logged_at_start\" : logged_at_start , \"logged_at_end\" : logged_at_end , \"offset\" : offset , \"limit\" : limit , }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_audit_logs ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-audit-logs Connection \u00b6 create_adapter \u00b6 Create an adapter Note This is a prerequisite for creating a Databricks connection Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload dict Dictionary representing the adapter to create required Source code in dbtc/client/admin.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 @v3 def create_adapter ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Create an adapter !!! note This is a prerequisite for creating a Databricks connection Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (dict): Dictionary representing the adapter to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /adapters/\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_adapter ( account_id , project_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc create-adapter --payload = '{\"id\": null, \"account_id\": 1, \"created_by_id\": 1, \"project_id\": 1, \"state\": 1, \"adapter_version\": \"databricks_spark_v0\"}' # noqa: E501 payload = { 'id' : None , 'account_id' : 1 , 'created_by_id' : 1 , 'project_id' : 1 , 'state' : 1 , 'adapter_version' : 'databricks_spark_v0' , } create_connection \u00b6 Create a connection Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload dict Dictionary representing the connection to create required Source code in dbtc/client/admin.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 @v3 def create_connection ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Create a connection Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (dict): Dictionary representing the connection to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /connections/\" , method = \"post\" , json = payload , ) Examples: Python CLI Snowflake Bigquery Redshift Assuming that client is an instance of dbtCloudClient client . cloud . create_connection ( account_id , project_id , payload ) dbtc create-connection --payload = '{\"id\": null, \"name\": \"<connection-name>\", \"type\": \"redshift\", \"details\": {\"hostname\": \"<hostname>\", \"port\": 5439, \"dbname\": \"<your-db-name>\", \"tunnel_enabled\": false}, \"state\": 1, \"account_id\": 1, \"project_id\": 1}' # noqa: E501 payload = { 'id' : None , 'name' : 'Test' , 'type' : 'snowflake' , 'details' : { 'account' : snowflake_account , 'role' : snowflake_role , 'database' : snowflake_database , 'warehouse' : snowflake_warehouse , 'oauth_client_id' : None , 'oauth_client_secret' : None , 'client_session_keep_alive' : False , 'allow_sso' : False , }, 'state' : 1 , 'account_id' : 1 , 'project_id' : 1 , } payload = { 'id' : None , 'name' : '<test-bigquery-connection>' , 'type' : 'bigquery' , 'details' : { 'retries' : 1 , 'maximum_bytes_billed' : 0 , 'locaiton' : None , 'timeout_seconds' : 300 , 'project_id' : google_cloud_project_id , 'private_key_id' : service_account_private_key_id , 'private_key' : '-----BEGIN PRIVATE KEY----' , 'client_email' : 'service_account_email@gmail.com' , 'client_id' : '<service-account-client-id' , 'auth_uri' : 'https://accounts.google.com/o/oauth2/auth' , 'token_uri' : 'https://oauth2.googleapis.com/token' , 'auth_provider_x509_cert_url' : 'https://www.googleapiscom/robot/v1/metadata/x509/<service-account-email>' , 'application_id' : None , 'application_secret' : None , }, 'state' : 1 , 'account_id' : 1 , 'project_id' : 1 , } payload = { 'id' : None , 'name' : '<connection-name>' , 'type' : 'redshift' , 'details' : { 'hostname' : '<hostname>' , 'port' : 5439 , 'dbname' : '<your-db-name>' , 'tunnel_enabled' : False , }, 'state' : 1 , 'account_id' : 1 , 'project_id' : 1 , } delete_connection \u00b6 Delete a connection Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required connection_id int Numeric ID of the connection to delete required Source code in dbtc/client/admin.py 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 @v3 def delete_connection ( self , account_id : int , project_id : int , connection_id : int ) -> Dict : \"\"\"Delete a connection Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project connection_id (int): Numeric ID of the connection to delete \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /connections/ { connection_id } \" , method = \"delete\" , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . delete_connection ( account_id , project_id , connection_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc delete-connection --connection-id = 1 list_connections \u00b6 List connections for a specific account and project Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required project_id int Numeric ID of the project to retrieve required state int 1 = active, 2 = deleted None offset int The offset to apply when listing runs. Use with limit to paginate results. None limit int The limit to apply when listing runs. Use with offset to paginate results. None Source code in dbtc/client/admin.py 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 @v3 def list_connections ( self , account_id : int , project_id : int , * , state : int = None , offset : int = None , limit : int = None , ) -> Dict : \"\"\"List connections for a specific account and project Args: account_id (int): Numeric ID of the account to retrieve project_id (int): Numeric ID of the project to retrieve state (int, optional): 1 = active, 2 = deleted offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /connections\" , params = { \"state\" : state , \"limit\" : limit , \"offset\" : offset }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_connections ( account_id , project_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc list-connections test_connection \u00b6 Test a connection Parameters: Name Type Description Default account_id int Numeric ID of the account required payload dict Dictionary representing the connection to test required Source code in dbtc/client/admin.py 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 @v3 def test_connection ( self , account_id : int , payload : Dict ) -> Dict : \"\"\"Test a connection Args: account_id (int): Numeric ID of the account payload (dict): Dictionary representing the connection to test \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /connections/test/\" , method = \"post\" , json = payload ) update_connection \u00b6 Update a connection Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required connection_id int Numeric ID of the connection to update required payload dict Dictionary representing the connection to update required Source code in dbtc/client/admin.py 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 @v3 def update_connection ( self , account_id : int , project_id : int , connection_id : int , payload : Dict ) -> Dict : \"\"\"Update a connection Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project connection_id (int): Numeric ID of the connection to update payload (dict): Dictionary representing the connection to update \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /connections/ { connection_id } /\" , method = \"post\" , json = payload , ) Credentials \u00b6 create_credentials \u00b6 Create credentials Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload dict Dictionary representing the credentials to create required Source code in dbtc/client/admin.py 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 @v3 def create_credentials ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Create credentials Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (dict): Dictionary representing the credentials to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /credentials/\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_credentials ( account_id , project_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc create-credentials --payload = '{\"id\": null, \"account_id\": 1, \"created_by_id\": 1, \"project_id\": 1, \"state\": 1, \"adapter_version\": \"databricks_spark_v0\"}' # noqa: E501 payload = { 'id' : None , 'account_id' : 1 , 'created_by_id' : 1 , 'project_id' : 1 , 'state' : 1 , 'adapter_version' : 'databricks_spark_v0' , } list_credentials \u00b6 List credentials for a specific account and project Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required project_id int Numeric ID of the project to retrieve required Source code in dbtc/client/admin.py 886 887 888 889 890 891 892 893 894 895 896 @v3 def list_credentials ( self , account_id : int , project_id : int ) -> Dict : \"\"\"List credentials for a specific account and project Args: account_id (int): Numeric ID of the account to retrieve project_id (int): Numeric ID of the project to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /credentials\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_credentials ( account_id , project_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc list-credentials update_credentials \u00b6 Update credentials Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required credentials_id int Numeric ID of the credentials to update required payload dict Dictionary representing the credentials to update required Source code in dbtc/client/admin.py 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 @v3 def update_credentials ( self , account_id : int , project_id : int , credentials_id : int , payload : Dict ) -> Dict : \"\"\"Update credentials Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project credentials_id (int): Numeric ID of the credentials to update payload (dict): Dictionary representing the credentials to update \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /credentials/ { credentials_id } /\" , # noqa: E50 method = \"post\" , json = payload , ) Environment \u00b6 create_environment \u00b6 Create an environment Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload dict Dictionary representing the environment to create required Source code in dbtc/client/admin.py 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 @v3 def create_environment ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Create an environment Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (dict): Dictionary representing the environment to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /environments/\" , method = \"post\" , json = payload , ) delete_environment \u00b6 Delete job for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required environment_id int Numeric ID of the environment to delete required Source code in dbtc/client/admin.py 402 403 404 405 406 407 408 409 410 411 412 413 @v3 def delete_environment ( self , account_id : int , environment_id : int ) -> Dict : \"\"\"Delete job for a specified account Args: account_id (int): Numeric ID of the account environment_id (int): Numeric ID of the environment to delete \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /environments/ { environment_id } /\" , method = \"delete\" , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . delete_environment ( account_id , project_id , environment_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc delete-environment --environment-id = 1 list_environments \u00b6 List environments for a specific account Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required project_id int or list The project ID or IDs None dbt_version str or list The version of dbt the environment is using None name str Name of the environment to retrieve None type str Type of the environment (deployment or development) None state int 1 = active, 2 = deleted None offset int The offset to apply when listing runs. Use with limit to paginate results. None limit int The limit to apply when listing runs. Use with offset to paginate results. None order_by str Field to order the result by. None Source code in dbtc/client/admin.py 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 @v3 def list_environments ( self , account_id : int , * , project_id : Union [ int , List [ int ]] = None , dbt_version : Union [ str , List [ str ]] = None , name : str = None , type : str = None , state : int = None , offset : int = None , limit : int = None , order_by : str = None , ) -> Dict : \"\"\"List environments for a specific account Args: account_id (int): Numeric ID of the account to retrieve project_id (int or list, optional): The project ID or IDs dbt_version (str or list, optional): The version of dbt the environment is using name (str, optional): Name of the environment to retrieve type (str, optional): Type of the environment (deployment or development) state (int, optional): 1 = active, 2 = deleted offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. order_by (str, optional): Field to order the result by. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /environments/\" , params = { \"project_id__in\" : json_listify ( project_id ), \"dbt_version__in\" : json_listify ( dbt_version ), \"name\" : name , \"type\" : type , \"state\" : state , \"offset\" : offset , \"limit\" : limit , \"order_by\" : order_by , }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_environments ( account_id , project_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc list-environments update_environment \u00b6 Update a connection Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required environment_id int Numeric ID of the environment to update required payload dict Dictionary representing the environment to update required Source code in dbtc/client/admin.py 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 @v3 def update_environment ( self , account_id : int , project_id : int , environment_id : int , payload : Dict ) -> Dict : \"\"\"Update a connection Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project environment_id (int): Numeric ID of the environment to update payload (dict): Dictionary representing the environment to update \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /environments/ { environment_id } /\" , # noqa: E501 method = \"post\" , json = payload , ) Environment Variables \u00b6 create_environment_variables \u00b6 Create environment variabless Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload dict Dictionary representing the environment variables to create required Source code in dbtc/client/admin.py 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 @v3 def create_environment_variables ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Create environment variabless Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (dict): Dictionary representing the environment variables to create \"\"\" url = f \"accounts/ { account_id } /projects/ { project_id } /environment-variables/\" if len ( payload . keys ()) > 1 : url += \"bulk/\" return self . _simple_request ( url , method = \"post\" , json = payload ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_environment_variables ( account_id , project_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc create-credentials --payload = '{\"env_var\": {\"name\": \"DBT_ENV_TEST\", \"ids\": [], \"new_name\": \"DBT_ENV_TEST\", \"project\": \"foo\", \"{{development_environment_name}}\": \"dev_value\", \"{{deployment_environment_name}}\": \"deploy_value\"}}' payload = { 'env_var' : { 'name' : 'DBT_ENV_TEST' , 'ids' : [], 'new_name' : 'DBT_ENV_TEST' , 'project' : 'foo' , '{{development_environment_name}}' : 'dev_value' , '{{deployment_environment_name}}' : 'deploy_value' } } delete_environment_variables \u00b6 Delete environment variables for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload Dict Dictionary representing environment variables to delete required Source code in dbtc/client/admin.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 @v3 def delete_environment_variables ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Delete environment variables for a specified account Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (Dict): Dictionary representing environment variables to delete \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /environment-variables/bulk/\" , method = \"delete\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . delete_environment_variables ( account_id , project_id , environment_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc delete-environment --payload = '{\"name\": \"DBT_MY_AWESOME_VARIABLE\"}' payload = { 'name' : 'DBT_MY_AWESOME_VARIABLE' } Feature Flags \u00b6 list_feature_flags \u00b6 List feature flags for a specific account Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required Source code in dbtc/client/admin.py 1005 1006 1007 1008 1009 1010 1011 1012 @v3 def list_feature_flags ( self , account_id : int ) -> Dict : \"\"\"List feature flags for a specific account Args: account_id (int): Numeric ID of the account to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /feature-flag/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_feature_flags ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-feature-flags Group \u00b6 assign_group_permissions \u00b6 Assign group permissions Parameters: Name Type Description Default account_id int Numeric ID of the account required group_id int Numeric ID of the group required payload dict Dictionary representing the group to create required Source code in dbtc/client/admin.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 @v3 def assign_group_permissions ( self , account_id : int , group_id : int , payload : Dict ) -> Dict : \"\"\"Assign group permissions Args: account_id (int): Numeric ID of the account group_id (int): Numeric ID of the group payload (dict): Dictionary representing the group to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /group-permissions/ { group_id } /\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . assign_service_token_permissions ( account_id , group_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc assign-group-permissions --payload = '[{\"group_id\": 1, \"account_id\": 1, \"permission_set\": \"analyst\", \"project_id\": 1, \"all_projects\": false}]' payload = [ { 'group_id' : 1 , 'account_id' : 1 , 'permission_set' : 'analyst' , 'project_id' : 1 , 'all_projects' : False }, ] assign_user_to_group \u00b6 Assign a user to a group Parameters: Name Type Description Default account_id int Numeric ID of the account required payload dict Dictionary representing the user to assign required Source code in dbtc/client/admin.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 @v3 def assign_user_to_group ( self , account_id : int , payload : Dict ) -> Dict : \"\"\"Assign a user to a group Args: account_id (int): Numeric ID of the account payload (dict): Dictionary representing the user to assign { \"user_id\": int, \"desired_group_ids\": list(int) } \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /assign-groups/\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . assign_user_to_group ( account_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc assign-user-to-group --payload = '{\"user_id\": 1, \"desired_group_ids\": [1]}' payload = { 'user_id' : 1 , 'desired_group_ids' : [ 1 ], } create_user_group \u00b6 Create a user group Parameters: Name Type Description Default account_id int Numeric ID of the account required payload dict Dictionary representing the group to create required Note The group_name is the name of the dbt Cloud group. The list of sso_mapping_groups are string values that dbt Cloud will attempt to match with incoming information from your identity provider at login time, in order to assign the group with group_name to the user. Source code in dbtc/client/admin.py 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 @v3 def create_user_group ( self , account_id : int , payload : Dict ) -> Dict : \"\"\"Create a user group Args: account_id (int): Numeric ID of the account payload (dict): Dictionary representing the group to create !!! note The group_name is the name of the dbt Cloud group. The list of sso_mapping_groups are string values that dbt Cloud will attempt to match with incoming information from your identity provider at login time, in order to assign the group with group_name to the user. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /groups/\" , method = \"post\" , json = payload ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_user_group ( account_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc create-user-group --payload = '{\"account_id\": 1, \"name\": \"{{group_name}}\", \"assign_by_default\": false, \"sso_mapping_groups\": [\"mapping_group_1\"]}' payload = { 'account_id' : 1 , 'name' : '{{group_name}}' , 'assign_by_default' : False , 'sso_mapping_groups' :[ 'mapping_group_1' ] } delete_user_group \u00b6 Delete group for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required group_id int Numeric ID of the group to delete required payload dict Dictionary representing the group to delete with the format { \"account_id\": int, \"name\": str, \"id\": int, \"state\":2, \"assign_by_default\":false, \"sso_mapping_groups\": list } required Source code in dbtc/client/admin.py 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 @v3 def delete_user_group ( self , account_id : int , group_id : int , payload : Dict ) -> Dict : \"\"\"Delete group for a specified account Args: account_id (int): Numeric ID of the account group_id (int): Numeric ID of the group to delete payload (dict): Dictionary representing the group to delete with the format { \"account_id\": int, \"name\": str, \"id\": int, \"state\":2, \"assign_by_default\":false, \"sso_mapping_groups\": list } \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /groups/ { group_id } /\" , method = \"post\" , payload = payload ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . delete_group ( account_id , group_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc delete-environment --group-id = 1 payload = { 'account_id' : 1 , 'name' : '{{ group_name }}' , 'id' : 1 , 'state' : 2 , 'assign_by_default' : False , 'sso_mapping_groups' : [] } list_groups \u00b6 List groups for a specific account and project Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required Source code in dbtc/client/admin.py 1014 1015 1016 1017 1018 1019 1020 1021 @v3 def list_groups ( self , account_id : int ) -> Dict : \"\"\"List groups for a specific account and project Args: account_id (int): Numeric ID of the account to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /groups/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_groups ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-groups Job \u00b6 create_job \u00b6 Create a job Parameters: Name Type Description Default account_id int Numeric ID of the account required payload dict Dictionary representing the job to create required Source code in dbtc/client/admin.py 261 262 263 264 265 266 267 268 269 270 271 272 273 @v2 def create_job ( self , account_id : int , payload : Dict ) -> Dict : \"\"\"Create a job Args: account_id (int): Numeric ID of the account payload (dict): Dictionary representing the job to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /jobs/\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_job ( account_id , project_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc create-credentials --payload = '{\"account_id\": 1, \"project_id\": 1, \"id\": null, \"environment_id\": 1, \"name\": \"<your-job-name>\", \"dbt_version\": \"1.0.1\", \"triggers\": {\"github_webhook\": false, \"schedule\": false, \"custom_branch_only\": false}, \"execute_steps\": [\"dbt build\"], \"settings\": {\"threads\": 1, \"target_name\": \"default\"}, \"state\": 1, \"generate_docs\": false, \"schedule\": {\"date\": {\"type\": \"every_day\"}, \"time\": {\"type\": \"every_hour\", \"interval\": 1}}}' payload = { 'account_id' : 1 , 'project_id' : 1 , 'id' : None , 'environment_id' : 1 , 'name' : '<your-job-name>' , 'dbt_version' : '1.0.1' , 'triggers' : { 'github_webhook' : False , 'schedule' : False , 'custom_branch_only' : False }, 'execute_steps' : [ 'dbt build' ], 'settings' : { 'threads' : 1 , 'target_name' : 'default' }, 'state' : 1 , 'generate_docs' : False , 'schedule' : { 'date' : { 'type' : 'every_day' }, 'time' : { 'type' : 'every_hour' , 'interval' : 1 } } } delete_job \u00b6 Delete job for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required job_id int Numeric ID of the project to delete required Source code in dbtc/client/admin.py 432 433 434 435 436 437 438 439 440 441 442 443 @v2 def delete_job ( self , account_id : int , job_id : int ) -> Dict : \"\"\"Delete job for a specified account Args: account_id (int): Numeric ID of the account job_id (int): Numeric ID of the project to delete \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /jobs/ { job_id } /\" , method = \"delete\" , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . delete_job ( account_id , job_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc delete-environment --job-id = 1 get_job \u00b6 Get a job by its ID. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required job_id int Numeric ID of the job to retrieve required order_by str Field to order the result by. Use - to indicate reverse order. None Source code in dbtc/client/admin.py 541 542 543 544 545 546 547 548 549 550 551 552 553 554 @v2 def get_job ( self , account_id : int , job_id : int , * , order_by : str = None ) -> Dict : \"\"\"Get a job by its ID. Args: account_id (int): Numeric ID of the account to retrieve job_id (int): Numeric ID of the job to retrieve order_by (str, optional): Field to order the result by. Use - to indicate reverse order. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /jobs/ { job_id } /\" , params = { \"order_by\" : order_by }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_job ( account_id , job_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-job --job-id = 1 list_jobs \u00b6 List jobs in an account or specific project. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required environment_id int Numeric ID of the environment to retrieve None project_id int or list The project ID or IDs None state int 1 = active, 2 = deleted None offset int The offset to apply when listing runs. Use with limit to paginate results. None limit int The limit to apply when listing runs. Use with offset to paginate results. None order_by str Field to order the result by. Use - to indicate reverse order. None Source code in dbtc/client/admin.py 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 @v2 def list_jobs ( self , account_id : int , * , environment_id : int = None , project_id : Union [ int , List [ int ]] = None , state : int = None , offset : int = None , limit : int = None , order_by : str = None , ) -> Dict : \"\"\"List jobs in an account or specific project. Args: account_id (int): Numeric ID of the account to retrieve environment_id (int): Numeric ID of the environment to retrieve project_id (int or list, optional): The project ID or IDs state (int, optional): 1 = active, 2 = deleted offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. order_by (str, optional): Field to order the result by. Use - to indicate reverse order. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /jobs/\" , params = { \"environment_id\" : environment_id , \"project_id__in\" : json_listify ( project_id ), \"state\" : state , \"offset\" : offset , \"limit\" : limit , \"order_by\" : order_by , }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_jobs ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-jobs trigger_autoscaling_ci_job \u00b6 Trigger an autoscaling CI job Info In the event your CI job is already running, this will do the following: If a new commit is created for the currently running job, cancel the job and then trigger again If this is an entirely new pull request, clone the job and trigger This will also check to see if your account has met or exceeded the allotted run slots. In the event you have, a cloned job will not be created and the existing job will be triggered. More info here Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required job_id int Numeric ID of the job to trigger required payload dict Payload required in triggering a job. It's important that the payload consists of the following keys in order to mimic the native behavior of dbt Cloud's Slim CI functionality: git_sha cause schema_override Depending on your git provider, one of github_pull_request_id , gitlab_merge_request_id , or azure_pull_request_id required should_poll bool Poll until completion if True , completion is one of success, failure, or cancelled False poll_interval int Number of seconds to wait in between polling 10 delete_cloned_job bool Indicate if cloned job should be deleted after being triggered True max_run_slots int Number of run slots that should be available to this process. This will limit the ability to run concurrent PRs up the the allocated run slots for your account. When set to None , the run_slots allocated to your account will be used to determine if a job should be cloned. None Source code in dbtc/client/admin.py 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 @set_called_from @v2 def trigger_autoscaling_ci_job ( self , account_id : int , job_id : int , payload : Dict , * , should_poll : bool = False , poll_interval : int = 10 , delete_cloned_job : bool = True , max_run_slots : int = None , ): \"\"\"Trigger an autoscaling CI job !!! info In the event your CI job is already running, this will do the following: - If a new commit is created for the currently running job, cancel the job and then trigger again - If this is an entirely new pull request, clone the job and trigger - This will also check to see if your account has met or exceeded the allotted run slots. In the event you have, a cloned job will not be created and the existing job will be triggered. More info [here](/latest/guide/autoscaling_ci) Args: account_id (int): Numeric ID of the account to retrieve job_id (int): Numeric ID of the job to trigger payload (dict): Payload required in triggering a job. It's important that the payload consists of the following keys in order to mimic the native behavior of dbt Cloud's Slim CI functionality: - `git_sha` - `cause` - `schema_override` - Depending on your git provider, one of `github_pull_request_id`, `gitlab_merge_request_id`, or `azure_pull_request_id` should_poll (bool, optional): Poll until completion if `True`, completion is one of success, failure, or cancelled poll_interval (int, optional): Number of seconds to wait in between polling delete_cloned_job (bool, optional): Indicate if cloned job should be deleted after being triggered max_run_slots (int, optional): Number of run slots that should be available to this process. This will limit the ability to run concurrent PRs up the the allocated run slots for your account. When set to `None`, the `run_slots` allocated to your account will be used to determine if a job should be cloned. \"\"\" self . console . log ( \"Finding any in progress runs...\" ) cloned_job = None payload_pr_id = None pull_request_key : Optional [ str ] = None # Get all runs in \"running\" state in_progress_runs = self . list_runs ( account_id , status = [ \"queued\" , \"starting\" , \"running\" ], include_related = [ \"trigger\" ], ) . get ( \"data\" , []) # Find any runs that match the job_id specified in function signature in_progress_job_run = [ r for r in in_progress_runs if r . get ( \"job_definition_id\" , - 1 ) == job_id ] # Find the valid pull_request_key to use in pulling out relevant PR IDs for pull_request_key in PULL_REQUESTS : if pull_request_key in payload : payload_pr_id = payload [ pull_request_key ] break else : pull_request_key = None # This will be used to identify if the PR within the payload has a run # that's in a running state. in_progress_pr_run = [ r for r in in_progress_runs if r . get ( \"trigger\" , {}) . get ( pull_request_key , - 1 ) == payload_pr_id ] if in_progress_pr_run : # A PR should only have one run in a queued, running, or starting state # at any given time pr_run = in_progress_pr_run [ 0 ] self . console . log ( f \"Found an in progress run for PR # { payload_pr_id } . Run \" f ' { pr_run [ \"id\" ] } will be canceled and a job triggered for the new ' \"commit.\" ) _ = self . cancel_run ( account_id , pr_run [ \"id\" ]) else : pr_run = {} if in_progress_job_run : # Job can only have one run in a queued, running, or starting state job_run = in_progress_job_run [ 0 ] job_run_is_pr_run = pr_run . get ( \"id\" , None ) == job_run [ \"id\" ] # Only clone the job if this job run isn't the same as the PR run we just # cancelled above if not job_run_is_pr_run : run_slots = ( self . get_account ( account_id ) . get ( \"data\" , {}) . get ( \"run_slots\" , 0 ) ) max_run_slots = min ( max_run_slots or run_slots , run_slots ) if max_run_slots > len ( in_progress_runs ): self . console . log ( f 'Job { job_id } is currently being used in run { job_run [ \"id\" ] } . ' \"This job definition will be cloned and then triggered for \" f \"pull request # { payload_pr_id } .\" ) current_job = self . get_job ( account_id , job_id ) . get ( \"data\" , {}) # Alter the current job definition so it can be cloned read_only_fields = [ \"is_deferrable\" , \"raw_dbt_version\" , \"job_type\" ] for read_only_field in read_only_fields : current_job . pop ( read_only_field ) current_job [ \"id\" ] = None now = datetime . now () . strftime ( \"%m/ %d /%Y %H:%M:%S\" ) current_job [ \"name\" ] = current_job [ \"name\" ] + f \" [CLONED { now } ]\" cloned_job = self . create_job ( account_id , current_job )[ \"data\" ] # Modify the should_poll argument - this needs to be `True` # if we're deleting the cloned job. Otherwise, dbt Cloud # will cancel the run because it can't find an associated job if delete_cloned_job : should_poll = True job_id = cloned_job [ \"id\" ] else : self . console . log ( \"Not cloning the job as your account has met or exceeded the \" \"number of run slots or a limit was placed by the user. The \" \"normal job will be queued.\" ) else : self . console . log ( \"No in progress job run found. Triggering as normal\" ) run = self . trigger_job ( account_id , job_id , payload , should_poll = should_poll , poll_interval = poll_interval , ) # This property was set to `None` in the trigger_job method, reset here self . _called_from = \"trigger_autoscaling_ci_job\" if cloned_job is not None and delete_cloned_job : self . delete_job ( account_id , job_id ) return run trigger_job \u00b6 Trigger a job by its ID Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required job_id int Numeric ID of the job to trigger required payload dict Payload required for post request required should_poll bool Poll until completion if True , completion is one of success, failure, or cancelled True poll_interval int Number of seconds to wait in between polling 10 Source code in dbtc/client/admin.py 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 @set_called_from @v2 def trigger_job ( self , account_id : int , job_id : int , payload : Dict , * , should_poll : bool = True , poll_interval : int = 10 , retries : int = 0 , ): \"\"\"Trigger a job by its ID Args: account_id (int): Numeric ID of the account to retrieve job_id (int): Numeric ID of the job to trigger payload (dict): Payload required for post request should_poll (bool, optional): Poll until completion if `True`, completion is one of success, failure, or cancelled poll_interval (int, optional): Number of seconds to wait in between polling \"\"\" def is_run_complete ( run : Dict ): return run [ \"data\" ][ \"status\" ] in [ JobRunStatus . SUCCESS , JobRunStatus . CANCELLED , ] run = self . _simple_request ( f \"accounts/ { account_id } /jobs/ { job_id } /run/\" , method = \"post\" , json = payload , ) if not run [ \"status\" ][ \"is_success\" ]: self . console . log ( f \"Run NOT triggered for job { job_id } . See run response.\" ) return run self . console . log ( self . _run_status_formatted ( run , 0 )) if should_poll or retries > 0 : run = self . _poll_for_completion ( run , poll_interval ) while retries > 0 and not is_run_complete ( run ): self . console . log ( f \"Retrying job { job_id } after failure. Retries left: { retries - 1 } \" ) run = self . trigger_job_from_failure ( account_id , job_id ) retries -= 1 return run trigger_job_from_failure \u00b6 Trigger job from point of failure Use this method to retry a failed run for a job from the point of failure, if the run failed. Otherwise trigger a new run. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required job_id int Numeric ID of the job to trigger required Source code in dbtc/client/admin.py 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 @set_called_from @v2 def trigger_job_from_failure ( self , account_id : int , job_id : int , * , should_poll : bool = True , poll_interval : int = 10 , ): \"\"\"Trigger job from point of failure Use this method to retry a failed run for a job from the point of failure, if the run failed. Otherwise trigger a new run. Args: account_id (int): Numeric ID of the account to retrieve job_id (int): Numeric ID of the job to trigger \"\"\" run = self . _simple_request ( f \"accounts/ { account_id } /jobs/ { job_id } /rerun/\" , method = \"post\" , ) self . console . log ( self . _run_status_formatted ( run , 0 )) if should_poll : run = self . _poll_for_completion ( run , poll_interval ) return run update_job \u00b6 Update a job by its ID. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required job_id int Numeric ID of the job to retrieve required payload dict Payload required for post request required Source code in dbtc/client/admin.py 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 @v2 def update_job ( self , account_id : int , job_id : int , payload : Dict ) -> Dict : \"\"\"Update a job by its ID. Args: account_id (int): Numeric ID of the account to retrieve job_id (int): Numeric ID of the job to retrieve payload (dict): Payload required for post request \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /jobs/ { job_id } /\" , method = \"post\" , json = payload , ) Repository \u00b6 create_repository \u00b6 Create a repository Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload dict Dictionary representing the repository to create required Note After creating / updating a dbt Cloud repository's SSH key, you will need to add the generated key text as a deploy key to the target repository. This gives dbt Cloud permissions to read / write in the repository You can read more in the docs # noqa: E501 Source code in dbtc/client/admin.py 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 @v3 def create_repository ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Create a repository Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (dict): Dictionary representing the repository to create !!! note After creating / updating a dbt Cloud repository's SSH key, you will need to add the generated key text as a deploy key to the target repository. This gives dbt Cloud permissions to read / write in the repository You can read more in the [docs](https://docs.getdbt.com/docs/dbt-cloud/cloud-configuring-dbt-cloud/cloud-configuring-repositories) # noqa: E501 \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /repositories/\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_repository ( account_id , project_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc create-repository --payload = '{\"account_id\": 1, \"project_id\": 1, \"remote_url\": \"{{git_clone_url}}\", \"git_clone_strategy\": \"deploy_key\", \"github_installation_id\": null, \"token_str\": null}' payload = { 'account_id' : 1 , 'project_id' : 1 , 'remote_url' : '{{git_clone_url}}' , 'git_clone_strategy' : 'deploy_key' , 'github_installation_id' : None , 'token_str' : None } delete_repository \u00b6 Delete repository for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required repository_id int Numeric ID of the repository to delete required Source code in dbtc/client/admin.py 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 @v3 def delete_repository ( self , account_id : int , project_id : int , repository_id : int ) -> Dict : \"\"\"Delete repository for a specified account Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project repository_id (int): Numeric ID of the repository to delete \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /repositories/ { repository_id } \" , method = \"delete\" , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . delete_repository ( account_id , project_id , repository_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc delete-repository --repository-id = 1 list_repositories \u00b6 List repositories for a specific account and project Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required project_id int Numeric ID of the project to retrieve required Source code in dbtc/client/admin.py 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 @v3 def list_repositories ( self , account_id : int , project_id : int ) -> Dict : \"\"\"List repositories for a specific account and project Args: account_id (int): Numeric ID of the account to retrieve project_id (int): Numeric ID of the project to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /repositories/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_repositories ( account_id , project_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc list-repositories update_repository \u00b6 Update a connection Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required repository_id int Numeric ID of the repository to update required payload dict Dictionary representing the repository to update required Source code in dbtc/client/admin.py 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 @v3 def update_repository ( self , account_id : int , project_id : int , repository_id : int , payload : Dict ) -> Dict : \"\"\"Update a connection Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project repository_id (int): Numeric ID of the repository to update payload (dict): Dictionary representing the repository to update \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /repositories/ { repository_id } /\" , # noqa: E501 method = \"post\" , json = payload , ) Run \u00b6 cancel_run \u00b6 Cancel a run. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required run_id int Numeric ID of the run to retrieve required Source code in dbtc/client/admin.py 163 164 165 166 167 168 169 170 171 172 173 174 @v2 def cancel_run ( self , account_id : int , run_id : int ) -> Dict : \"\"\"Cancel a run. Args: account_id (int): Numeric ID of the account to retrieve run_id (int): Numeric ID of the run to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /runs/ { run_id } /cancel\" , method = \"post\" , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . cancel_run ( account_id , run_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. ```bash dbtc cancel-run --account-id=1 --run-id=1 get_most_recent_run \u00b6 Get the most recent run Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required include_related list List of related fields to pull with the run. Valid values are trigger , job , repository , debug_logs , run_steps , and environment . None job_definition_id int Applies a filter to only return runs from the specified Job. None environment_id int Numeric ID of the environment None project_id int or list The project ID or IDs None deferring_run_id int Numeric ID of a deferred run None status str or list The status to apply when listing runs. Options include queued, starting, running, success, error, and cancelled None Source code in dbtc/client/admin.py 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 @set_called_from @v2 def get_most_recent_run ( self , account_id : int , * , include_related : List [ str ] = None , job_definition_id : int = None , environment_id : int = None , project_id : int = None , deferring_run_id : int = None , status : Union [ List [ str ], str ] = None , ) -> Dict : \"\"\"Get the most recent run Args: account_id (int): Numeric ID of the account to retrieve include_related (list): List of related fields to pull with the run. Valid values are `trigger`, `job`, `repository`, `debug_logs`, `run_steps`, and `environment`. job_definition_id (int, optional): Applies a filter to only return runs from the specified Job. environment_id (int, optional): Numeric ID of the environment project_id (int or list, optional): The project ID or IDs deferring_run_id (int, optional): Numeric ID of a deferred run status (str or list, optional): The status to apply when listing runs. Options include queued, starting, running, success, error, and cancelled \"\"\" runs = self . list_runs ( account_id , include_related = include_related , job_definition_id = job_definition_id , environment_id = environment_id , project_id = project_id , deferring_run_id = deferring_run_id , order_by = \"-id\" , limit = 1 , status = status , ) try : runs [ \"data\" ] = runs . get ( \"data\" , [])[ 0 ] except IndexError : runs [ \"data\" ] = {} return runs Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_most_recent_run ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-most-recent-run get_run \u00b6 Get a run by its ID. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required run_id int Numeric ID of the run to retrieve required include_related list List of related fields to pull with the run. Valid values are trigger , job , repository , debug_logs , run_steps , and environment . None Source code in dbtc/client/admin.py 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 @v2 def get_run ( self , account_id : int , run_id : int , * , include_related : List [ str ] = None ) -> Dict : \"\"\"Get a run by its ID. Args: account_id (int): Numeric ID of the account to retrieve run_id (int): Numeric ID of the run to retrieve include_related (list): List of related fields to pull with the run. Valid values are `trigger`, `job`, `repository`, `debug_logs`, `run_steps`, and `environment`. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /runs/ { run_id } \" , params = { \"include_related\" : \",\" . join ( include_related or [])}, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_run ( account_id , run_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-run --run-id = 1 get_run_timing_details \u00b6 Retrieves the timing details related to a run Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required run_id int Numeric ID of the run to retrieve required Source code in dbtc/client/admin.py 773 774 775 776 777 778 779 780 781 782 783 784 785 @v3 def get_run_timing_details ( self , account_id : int , project_id : int , run_id : int ) -> Dict : \"\"\"Retrieves the timing details related to a run Args: account_id (int): Numeric ID of the account to retrieve run_id (int): Numeric ID of the run to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /runs/ { run_id } /timing/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_run_timing_details ( account_id , project_id , run_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc get-run-timing-details --run-id = 1 list_runs \u00b6 List runs in an account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required include_related list List of related fields to pull with the run. Valid values are trigger , job , repository , debug_logs , run_steps , and environment . None job_definition_id int Applies a filter to only return runs from the specified Job. None environment_id int Numeric ID of the environment None project_id int or list The project ID or IDs None deferring_run_id int Numeric ID of a deferred run None status str or list The status to apply when listing runs. Options include queued, starting, running, success, error, and cancelled None order_by str Field to order the result by. Use - to indicate reverse order. None offset int The offset to apply when listing runs. Use with limit to paginate results. None limit int The limit to apply when listing runs. Use with offset to paginate results. None Source code in dbtc/client/admin.py 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 @v2 def list_runs ( self , account_id : int , * , include_related : List [ str ] = None , job_definition_id : int = None , environment_id : int = None , project_id : Union [ int , List [ int ]] = None , deferring_run_id : int = None , status : Union [ List [ str ], str ] = None , order_by : str = None , offset : int = None , limit : int = None , ) -> Dict : \"\"\"List runs in an account. Args: account_id (int): Numeric ID of the account to retrieve include_related (list): List of related fields to pull with the run. Valid values are `trigger`, `job`, `repository`, `debug_logs`, `run_steps`, and `environment`. job_definition_id (int, optional): Applies a filter to only return runs from the specified Job. environment_id (int, optional): Numeric ID of the environment project_id (int or list, optional): The project ID or IDs deferring_run_id (int, optional): Numeric ID of a deferred run status (str or list, optional): The status to apply when listing runs. Options include queued, starting, running, success, error, and cancelled order_by (str, optional): Field to order the result by. Use - to indicate reverse order. offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. \"\"\" if status is not None : try : status = [ getattr ( JobRunStatus , s . upper ()) for s in listify ( status )] except AttributeError : raise else : status = json . dumps ( status ) return self . _simple_request ( f \"accounts/ { account_id } /runs\" , params = { \"include_related\" : \",\" . join ( include_related or []), \"job_definition_id\" : job_definition_id , \"environment_id\" : environment_id , \"project_id__in\" : json_listify ( project_id ), \"deferring_run_id\" : deferring_run_id , \"order_by\" : order_by , \"offset\" : offset , \"limit\" : limit , \"status__in\" : status , }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_runs ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-runs Project \u00b6 create_project \u00b6 Create a project Parameters: Name Type Description Default account_id int Numeric ID of the account required payload dict Dictionary representing the project to create required Source code in dbtc/client/admin.py 275 276 277 278 279 280 281 282 283 284 285 @v3 def create_project ( self , account_id : int , payload : Dict ) -> Dict : \"\"\"Create a project Args: account_id (int): Numeric ID of the account payload (dict): Dictionary representing the project to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/\" , method = \"post\" , json = payload ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_project ( account_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc create-project --payload = '{\"id\": null, \"name\": \"{{project_name}}\", \"dbt_project_subdirectory\": null, \"account_id\": 1, \"connection_id\": null, \"repository_id\": null}' payload = { 'id' : None , 'name' : '{{project_name}}' , 'dbt_project_subdirectory' : None , 'account_id' : 1 , 'connection_id' : None , 'repository_id' : None } delete_project \u00b6 Delete project for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project to delete required Source code in dbtc/client/admin.py 445 446 447 448 449 450 451 452 453 454 455 456 @v3 def delete_project ( self , account_id : int , project_id : int ) -> Dict : \"\"\"Delete project for a specified account Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project to delete \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /\" , method = \"delete\" , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . delete_project ( account_id , project_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc delete-project get_project \u00b6 Get a project by its ID. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required project_id int Numeric ID of the project to retrieve required Source code in dbtc/client/admin.py 556 557 558 559 560 561 562 563 564 @v2 def get_project ( self , account_id : int , project_id : int ) -> Dict : \"\"\"Get a project by its ID. Args: account_id (int): Numeric ID of the account to retrieve project_id (int): Numeric ID of the project to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } \" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_project ( account_id , project_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc get-project get_project_by_name \u00b6 Get a project by its name. Parameters: Name Type Description Default project_name str Name of project to retrieve required account_id int Numeric ID of the account to retrieve None account_name str Name of account to retrieve None Source code in dbtc/client/admin.py 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 @set_called_from @v2 def get_project_by_name ( self , project_name : str , account_id : int = None , account_name : str = None ) -> Dict : \"\"\"Get a project by its name. Args: project_name (str): Name of project to retrieve account_id (int, optional): Numeric ID of the account to retrieve account_name (str, optional): Name of account to retrieve \"\"\" if account_id is None and account_name is None : accounts = self . list_accounts () for account in accounts [ \"data\" ]: projects = self . list_projects ( account [ \"id\" ]) project = self . _get_by_name ( projects [ \"data\" ], project_name ) if project is not None : break else : if account_id is not None : account = self . get_account ( account_id ) else : account = self . get_account_by_name ( account_name ) if account . get ( \"data\" , None ) is not None : projects = self . list_projects ( account [ \"data\" ][ \"id\" ]) project = self . _get_by_name ( projects [ \"data\" ], project_name ) else : project = None if project is not None : return self . get_project ( project [ \"account_id\" ], project [ \"id\" ]) raise Exception ( f 'Project \" { project_name } \" was not found.' ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_project_by_name ( account_id , project_name ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-project --project-name = name list_projects \u00b6 List projects for a specified account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required project_id int or list The project ID or IDs None state int 1 = active, 2 = deleted None offset int The offset to apply when listing runs. Use with limit to paginate results. None limit int The limit to apply when listing runs. Use with offset to paginate results. None Source code in dbtc/client/admin.py 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 @v3 def list_projects ( self , account_id : int , * , project_id : Union [ int , List [ int ]] = None , state : int = None , offset : int = None , limit : int = None , ) -> Dict : \"\"\"List projects for a specified account. Args: account_id (int): Numeric ID of the account to retrieve project_id (int or list, optional): The project ID or IDs state (int, optional): 1 = active, 2 = deleted offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects\" , params = { \"pk__in\" : json_listify ( project_id ), \"state\" : state , \"offset\" : offset , \"limit\" : limit , }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_projects ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-projects update_project \u00b6 Update project for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project to update required payload dict Dictionary representing the project to update required Source code in dbtc/client/admin.py 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 @v3 def update_project ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Update project for a specified account Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project to update payload (dict): Dictionary representing the project to update \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /\" , method = \"POST\" , json = payload ) Service Token \u00b6 assign_service_token_permissions \u00b6 Assign permissions to a service token. Parameters: Name Type Description Default account_id int Numeric ID of the account required service_token_id int Numeric ID of the service token required payload list List of dictionaries representing the permissions to assign required Source code in dbtc/client/admin.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @v3 def assign_service_token_permissions ( self , account_id : int , service_token_id : int , payload : List [ Dict ] ) -> Dict : \"\"\"Assign permissions to a service token. Args: account_id (int): Numeric ID of the account service_token_id (int): Numeric ID of the service token payload (list): List of dictionaries representing the permissions to assign \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /service-tokens/ { service_token_id } /permissions/\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . assign_service_token_permissions ( account_id , service_token_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc assign-service-token-permissions --payload = '[{\"service_token_id\": 1, \"account_id\": 1, \"permission_set\": \"job_viewer\", \"project_id\": 1, \"all_projects\": false}]' payload = [ { 'service_token_id' : 1 , 'account_id' : 1 , 'permission_set' : 'job_viewer' , 'project_id' : 1 , 'all_projects' : False }, ] create_service_token \u00b6 Create a service token Parameters: Name Type Description Default account_id int Numeric ID of the account required payload dict Dictionary representing the service token to create required Note This request creates a service token, but does not assign permissions to it. Permissions are assigned via the assign_service_token_permissions See the user tokens # noqa: E501 and service tokens # noqa: E501 documentation for more information. Source code in dbtc/client/admin.py 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 @v3 def create_service_token ( self , account_id : int , payload : Dict ) -> Dict : \"\"\"Create a service token Args: account_id (int): Numeric ID of the account payload (dict): Dictionary representing the service token to create !!! note This request creates a service token, but does not assign permissions to it. Permissions are assigned via the [assign_service_token_permissions](cloud.md#assign_service_token_permissions) See the [user tokens](https://docs.getdbt.com/docs/dbt-cloud/dbt-cloud-api/user-tokens) # noqa: E501 and [service tokens](https://docs.getdbt.com/docs/dbt-cloud/dbt-cloud-api/service-tokens) # noqa: E501 documentation for more information. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /service-tokens/\" , method = \"post\" , json = payload ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_service_token ( account_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc create-service-token --payload = '{\"id\": null, \"name\": \"api-test\", \"state\": 1, \"account_id\": 1, \"access\": {\"admin\": {\"permissionSet\": \"admin\", \"projects\": [1]}, \"job_admin\": {\"permissionSet\": \"job_admin\", \"projects\": [1]}}}' payload = { 'id' : None , 'name' : 'api-test' , 'state' : 1 , 'account_id' : 1 , 'access' : { 'admin' : { 'permissionSet' : 'admin' , 'projects' : [ 1 ] }, 'job_admin' : { 'permissionSet' : 'job_admin' , 'projects' : [ 1 ] } } } get_service_token \u00b6 Retrieves a service token. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required service_token_id int Numeric ID of the service token to retrieve required Source code in dbtc/client/admin.py 787 788 789 790 791 792 793 794 795 796 797 @v3 def get_service_token ( self , account_id : int , service_token_id : int ) -> Dict : \"\"\"Retrieves a service token. Args: account_id (int): Numeric ID of the account to retrieve service_token_id (int): Numeric ID of the service token to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /service-tokens/ { service_token_id } \" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_service_toke ( account_id , service_token_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-service-token --service-token-id = 1 list_service_tokens \u00b6 List service tokens for a specific account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required Source code in dbtc/client/admin.py 1209 1210 1211 1212 1213 1214 1215 1216 @v3 def list_service_tokens ( self , account_id : int ) -> Dict : \"\"\"List service tokens for a specific account. Args: account_id (int): Numeric ID of the account to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /service-tokens/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_service_tokens ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-service-tokens list_service_token_permissions \u00b6 List service token permissions for a specific account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required service_token_id int Numeric ID of the service token to retrieve required Source code in dbtc/client/admin.py 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 @v3 def list_service_token_permissions ( self , account_id : int , service_token_id : int ) -> Dict : \"\"\"List service token permissions for a specific account. Args: account_id (int): Numeric ID of the account to retrieve service_token_id (int): Numeric ID of the service token to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /service-tokens/ { service_token_id } /permissions\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_service_token_permissions ( account_id , service_token_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-service-token-permissions --service-token-id = 1 User \u00b6 deactivate_user_license \u00b6 Deactivate user license Parameters: Name Type Description Default account_id int Numeric ID of the account required permission_id int Numeric ID of the permission that contains user you'd like to deactivate required Note Ensure the groups object contains all of a user's assigned group permissions. This request will fail if a user has already been deactivated. Source code in dbtc/client/admin.py 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 @v2 def deactivate_user_license ( self , account_id : int , permission_id : int , payload : Dict ) -> Dict : \"\"\"Deactivate user license Args: account_id (int): Numeric ID of the account permission_id (int): Numeric ID of the permission that contains user you'd like to deactivate !!! note Ensure the `groups` object contains all of a user's assigned group permissions. This request will fail if a user has already been deactivated. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /permissions/ { permission_id } \" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . deactivate_user_license ( account_id , permission_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc deactivate-user-license --permission_id = 1 --payload = '{\"license_type\": \"developer\", \"id\": 1, \"user_id\": 1, \"account_id\": 1, \"state\": 2, \"groups\": [{\"account_id\": 1, \"name\": \"test-group-with-sso-mappings\", \"id\": 1, \"state\": 1, \"assign_by_default\": false, \"sso_mapping_groups\": [\"something\"], \"group_permissions\": [{\"account_id\": 1, \"group_id\": 1, \"project_id\": null, \"all_projects\": true, \"permission_set\": \"analyst\", \"permission_level\": null, \"id\": \"{{group_permission_id}}\", \"state\": 1}]}], \"permission_statements\": [{\"permission\": \"invitations_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"license_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"projects_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"environments_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"jobs_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"runs_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"metadata_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"custom_environment_variables_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"projects_develop\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"credentials_write\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"develop_access\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"custom_environment_variables_write\", \"target_resource\": null, \"all_resources\": true}]}' payload = { 'license_type' : 'developer' , 'id' : 1 , 'user_id' : 1 , 'account_id' : 1 , 'state' : 2 , 'groups' : [ { 'account_id' : 1 , 'name' : 'test-group-with-sso-mappings' , 'id' : 1 , 'state' : 1 , 'assign_by_default' : False , 'sso_mapping_groups' : [ 'something' ], 'group_permissions' : [ { 'account_id' : 1 , 'group_id' : 1 , 'project_id' : None , 'all_projects' : True , 'permission_set' : 'analyst' , 'permission_level' : None , 'id' : '{{group_permission_id}}' , 'state' : 1 } ] } ], 'permission_statements' : [ { 'permission' : 'invitations_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'license_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'projects_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'environments_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'jobs_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'runs_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'metadata_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'custom_environment_variables_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'projects_develop' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'credentials_write' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'develop_access' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'custom_environment_variables_write' , 'target_resource' : None , 'all_resources' : True } ] } get_user \u00b6 List invited users in an account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required user_id int Numeric ID of the user to retrieve required Source code in dbtc/client/admin.py 811 812 813 814 815 816 817 818 819 @v2 def get_user ( self , account_id : int , user_id : int ) -> Dict : \"\"\"List invited users in an account. Args: account_id (int): Numeric ID of the account to retrieve user_id (int): Numeric ID of the user to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /users/ { user_id } /\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_user ( account_id , user_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get_user --user-id = 1 list_invited_users \u00b6 List invited users in an account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required Source code in dbtc/client/admin.py 1023 1024 1025 1026 1027 1028 1029 1030 @v2 def list_invited_users ( self , account_id : int ) -> Dict : \"\"\"List invited users in an account. Args: account_id (int): Numeric ID of the account to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /invites/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_invited_users ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-invited-users list_users \u00b6 List users in an account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required state int 1 = active, 2 = deleted None limit int The limit to apply when listing runs. Use with offset to paginate results. None offset int The offset to apply when listing runs. Use with limit to paginate results. None order_by str Field to order the result by. Use - to indicate reverse order. 'email' Source code in dbtc/client/admin.py 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 @v3 def list_users ( self , account_id : int , * , state : int = None , limit : int = None , offset : int = None , order_by : str = \"email\" , ) -> Dict : \"\"\"List users in an account. Args: account_id (int): Numeric ID of the account to retrieve state (int, optional): 1 = active, 2 = deleted limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. order_by (str, optional): Field to order the result by. Use - to indicate reverse order. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /users/\" , params = { \"limit\" : limit , \"offset\" : offset , \"order_by\" : order_by , \"state\" : state , }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_users ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-users","title":"Cloud"},{"location":"guide/cloud/#cloud","text":"The cloud property on the dbtCloudClient class contains methods that allow a user to perform CRUD operations against dbt Cloud resources.","title":"Cloud"},{"location":"guide/cloud/#account","text":"","title":"Account"},{"location":"guide/cloud/#get_account","text":"Get an account by its ID. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required Source code in dbtc/client/admin.py 508 509 510 511 512 513 514 515 @v2 def get_account ( self , account_id : int ) -> Dict : \"\"\"Get an account by its ID. Args: account_id (int): Numeric ID of the account to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } \" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_account ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-account","title":"get_account"},{"location":"guide/cloud/#get_account_by_name","text":"Get an account by its name. Parameters: Name Type Description Default account_name str Name of an account required Source code in dbtc/client/admin.py 517 518 519 520 521 522 523 524 525 526 527 528 529 530 @set_called_from @v2 def get_account_by_name ( self , account_name : str ) -> Dict : \"\"\"Get an account by its name. Args: account_name (str): Name of an account \"\"\" accounts = self . list_accounts () account = self . _get_by_name ( accounts [ \"data\" ], account_name ) if account is not None : return self . get_account ( account [ \"id\" ]) raise Exception ( f 'Account \" { account_name } \" was not found' ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_account_by_name ( account_name ) dbtc get-account-by-name --account-name = name","title":"get_account_by_name"},{"location":"guide/cloud/#get_account_licenses","text":"List account licenses for a specified account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required Source code in dbtc/client/admin.py 532 533 534 535 536 537 538 539 @v2 def get_account_licenses ( self , account_id : int ) -> Dict : \"\"\"List account licenses for a specified account. Args: account_id (int): Numeric ID of the account to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /licenses\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_account_licenses ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-account-licenses","title":"get_account_licenses"},{"location":"guide/cloud/#list_accounts","text":"List of accounts that your API Token is authorized to access. Source code in dbtc/client/admin.py 821 822 823 824 @v2 def list_accounts ( self ) -> Dict : \"\"\"List of accounts that your API Token is authorized to access.\"\"\" return self . _simple_request ( \"accounts/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_accounts () dbtc list-accounts","title":"list_accounts"},{"location":"guide/cloud/#artifact","text":"","title":"Artifact"},{"location":"guide/cloud/#get_most_recent_run_artifact","text":"Fetch artifacts from the most recent run Once a run has completed, you can use this endpoint to download the manifest.json , run_results.json or catalog.json files from dbt Cloud. These artifacts contain information about the models in your dbt project, timing information around their execution, and a status message indicating the result of the model build. Note By default, this endpoint returns artifacts from the last step in the run. To list artifacts from other steps in the run, use the step query parameter described below. Warning If requesting a non JSON artifact, the result will be a str Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required path str Paths are rooted at the target/ directory. Use manifest.json, catalog.json, or run_results.json to download dbt-generated artifacts for the run. required job_definition_id int Applies a filter to only return runs from the specified Job. None environment_id int Numeric ID of the environment None project_id int or list The project ID or IDs None deferring_run_id int Numeric ID of a deferred run None step str The index of the Step in the Run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this endpoint will return the artifacts compiled for the last step in the run. None Source code in dbtc/client/admin.py 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 @set_called_from @v2 def get_most_recent_run_artifact ( self , account_id : int , path : str , * , job_definition_id : int = None , environment_id : int = None , project_id : int = None , deferring_run_id : int = None , step : int = None , ): \"\"\"Fetch artifacts from the most recent run Once a run has completed, you can use this endpoint to download the `manifest.json`, `run_results.json` or `catalog.json` files from dbt Cloud. These artifacts contain information about the models in your dbt project, timing information around their execution, and a status message indicating the result of the model build. !!! note By default, this endpoint returns artifacts from the last step in the run. To list artifacts from other steps in the run, use the step query parameter described below. !!! warning If requesting a non JSON artifact, the result will be a `str` Args: account_id (int): Numeric ID of the account to retrieve path (str): Paths are rooted at the target/ directory. Use manifest.json, catalog.json, or run_results.json to download dbt-generated artifacts for the run. job_definition_id (int, optional): Applies a filter to only return runs from the specified Job. environment_id (int, optional): Numeric ID of the environment project_id (int or list, optional): The project ID or IDs deferring_run_id (int, optional): Numeric ID of a deferred run step (str, optional): The index of the Step in the Run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this endpoint will return the artifacts compiled for the last step in the run. \"\"\" runs = self . get_most_recent_run ( account_id , job_definition_id = job_definition_id , environment_id = environment_id , project_id = project_id , deferring_run_id = deferring_run_id , status = \"success\" , ) # Reset called from after being set to None in get_most_recent_run self . _called_from = \"get_most_recent_run_artifact\" try : run_id = runs . get ( \"data\" , {})[ \"id\" ] except KeyError : raise Exception ( \"A run could not be found with the provided arguments.\" ) else : return self . get_run_artifact ( account_id , run_id , path , step = step ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_most_recent_run_artifact ( account_id , path ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-most-recent-run-artifact --path manifest.json","title":"get_most_recent_run_artifact"},{"location":"guide/cloud/#get_run_artifact","text":"Fetch artifacts from a completed run. Once a run has completed, you can use this endpoint to download the manifest.json , run_results.json or catalog.json files from dbt Cloud. These artifacts contain information about the models in your dbt project, timing information around their execution, and a status message indicating the result of the model build. Note By default, this endpoint returns artifacts from the last step in the run. To list artifacts from other steps in the run, use the step query parameter described below. Warning If requesting a non JSON artifact, the result will be a str Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required run_id int Numeric ID of the run to retrieve required path str Paths are rooted at the target/ directory. Use manifest.json, catalog.json, or run_results.json to download dbt-generated artifacts for the run. required step str The index of the Step in the Run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this endpoint will return the artifacts compiled for the last step in the run. None Source code in dbtc/client/admin.py 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 @v2 def get_run_artifact ( self , account_id : int , run_id : int , path : str , * , step : int = None , ) -> Union [ str , Dict ]: \"\"\"Fetch artifacts from a completed run. Once a run has completed, you can use this endpoint to download the `manifest.json`, `run_results.json` or `catalog.json` files from dbt Cloud. These artifacts contain information about the models in your dbt project, timing information around their execution, and a status message indicating the result of the model build. !!! note By default, this endpoint returns artifacts from the last step in the run. To list artifacts from other steps in the run, use the step query parameter described below. !!! warning If requesting a non JSON artifact, the result will be a `str` Args: account_id (int): Numeric ID of the account to retrieve run_id (int): Numeric ID of the run to retrieve path (str): Paths are rooted at the target/ directory. Use manifest.json, catalog.json, or run_results.json to download dbt-generated artifacts for the run. step (str, optional): The index of the Step in the Run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this endpoint will return the artifacts compiled for the last step in the run. \"\"\" url_path = f \"accounts/ { account_id } /runs/ { run_id } /artifacts/ { path } \" params = { \"step\" : step } if path [ - 5 :] == \".json\" : return self . _simple_request ( url_path , params = params ) response = self . _make_request ( url_path , params = params ) return response . text Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_run_artifact ( account_id , run_id , path ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-run-artifact --run-id = 1 --path = manifest.json","title":"get_run_artifact"},{"location":"guide/cloud/#list_run_artifacts","text":"Fetch a list of artifact files generated for a completed run. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required run_id int Numeric ID of the run to retrieve required step str The index of the Step in the Run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this endpoint will return the artifacts compiled for the last step in the run. None Source code in dbtc/client/admin.py 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 @v2 def list_run_artifacts ( self , account_id : int , run_id : int , * , step : int = None , ) -> Dict : \"\"\"Fetch a list of artifact files generated for a completed run. Args: account_id (int): Numeric ID of the account to retrieve run_id (int): Numeric ID of the run to retrieve step (str, optional): The index of the Step in the Run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this endpoint will return the artifacts compiled for the last step in the run. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /runs/ { run_id } /artifacts\" , params = { \"step\" : step }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_run_artifacts ( account_id , run_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-environments --run-id = 1","title":"list_run_artifacts"},{"location":"guide/cloud/#audit-log","text":"","title":"Audit Log"},{"location":"guide/cloud/#list_audit_logs","text":"List audit logs for a specific account Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required logged_at_start str Date to begin retrieving audit logs Format is yyyy-mm-dd None logged_at_end str Date to stop retrieving audit logs. Format is yyyy-mm-dd None offset int The offset to apply when listing runs. Use with limit to paginate results. None limit int The limit to apply when listing runs. Use with offset to paginate results. None Source code in dbtc/client/admin.py 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 @v3 def list_audit_logs ( self , account_id : int , * , logged_at_start : str = None , logged_at_end : str = None , offset : int = None , limit : int = None , ) -> Dict : \"\"\"List audit logs for a specific account Args: account_id (int): Numeric ID of the account to retrieve logged_at_start (str, optional): Date to begin retrieving audit logs Format is yyyy-mm-dd logged_at_end (str, optional): Date to stop retrieving audit logs. Format is yyyy-mm-dd offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /audit-logs\" , params = { \"logged_at_start\" : logged_at_start , \"logged_at_end\" : logged_at_end , \"offset\" : offset , \"limit\" : limit , }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_audit_logs ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-audit-logs","title":"list_audit_logs"},{"location":"guide/cloud/#connection","text":"","title":"Connection"},{"location":"guide/cloud/#create_adapter","text":"Create an adapter Note This is a prerequisite for creating a Databricks connection Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload dict Dictionary representing the adapter to create required Source code in dbtc/client/admin.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 @v3 def create_adapter ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Create an adapter !!! note This is a prerequisite for creating a Databricks connection Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (dict): Dictionary representing the adapter to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /adapters/\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_adapter ( account_id , project_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc create-adapter --payload = '{\"id\": null, \"account_id\": 1, \"created_by_id\": 1, \"project_id\": 1, \"state\": 1, \"adapter_version\": \"databricks_spark_v0\"}' # noqa: E501 payload = { 'id' : None , 'account_id' : 1 , 'created_by_id' : 1 , 'project_id' : 1 , 'state' : 1 , 'adapter_version' : 'databricks_spark_v0' , }","title":"create_adapter"},{"location":"guide/cloud/#create_connection","text":"Create a connection Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload dict Dictionary representing the connection to create required Source code in dbtc/client/admin.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 @v3 def create_connection ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Create a connection Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (dict): Dictionary representing the connection to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /connections/\" , method = \"post\" , json = payload , ) Examples: Python CLI Snowflake Bigquery Redshift Assuming that client is an instance of dbtCloudClient client . cloud . create_connection ( account_id , project_id , payload ) dbtc create-connection --payload = '{\"id\": null, \"name\": \"<connection-name>\", \"type\": \"redshift\", \"details\": {\"hostname\": \"<hostname>\", \"port\": 5439, \"dbname\": \"<your-db-name>\", \"tunnel_enabled\": false}, \"state\": 1, \"account_id\": 1, \"project_id\": 1}' # noqa: E501 payload = { 'id' : None , 'name' : 'Test' , 'type' : 'snowflake' , 'details' : { 'account' : snowflake_account , 'role' : snowflake_role , 'database' : snowflake_database , 'warehouse' : snowflake_warehouse , 'oauth_client_id' : None , 'oauth_client_secret' : None , 'client_session_keep_alive' : False , 'allow_sso' : False , }, 'state' : 1 , 'account_id' : 1 , 'project_id' : 1 , } payload = { 'id' : None , 'name' : '<test-bigquery-connection>' , 'type' : 'bigquery' , 'details' : { 'retries' : 1 , 'maximum_bytes_billed' : 0 , 'locaiton' : None , 'timeout_seconds' : 300 , 'project_id' : google_cloud_project_id , 'private_key_id' : service_account_private_key_id , 'private_key' : '-----BEGIN PRIVATE KEY----' , 'client_email' : 'service_account_email@gmail.com' , 'client_id' : '<service-account-client-id' , 'auth_uri' : 'https://accounts.google.com/o/oauth2/auth' , 'token_uri' : 'https://oauth2.googleapis.com/token' , 'auth_provider_x509_cert_url' : 'https://www.googleapiscom/robot/v1/metadata/x509/<service-account-email>' , 'application_id' : None , 'application_secret' : None , }, 'state' : 1 , 'account_id' : 1 , 'project_id' : 1 , } payload = { 'id' : None , 'name' : '<connection-name>' , 'type' : 'redshift' , 'details' : { 'hostname' : '<hostname>' , 'port' : 5439 , 'dbname' : '<your-db-name>' , 'tunnel_enabled' : False , }, 'state' : 1 , 'account_id' : 1 , 'project_id' : 1 , }","title":"create_connection"},{"location":"guide/cloud/#delete_connection","text":"Delete a connection Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required connection_id int Numeric ID of the connection to delete required Source code in dbtc/client/admin.py 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 @v3 def delete_connection ( self , account_id : int , project_id : int , connection_id : int ) -> Dict : \"\"\"Delete a connection Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project connection_id (int): Numeric ID of the connection to delete \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /connections/ { connection_id } \" , method = \"delete\" , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . delete_connection ( account_id , project_id , connection_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc delete-connection --connection-id = 1","title":"delete_connection"},{"location":"guide/cloud/#list_connections","text":"List connections for a specific account and project Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required project_id int Numeric ID of the project to retrieve required state int 1 = active, 2 = deleted None offset int The offset to apply when listing runs. Use with limit to paginate results. None limit int The limit to apply when listing runs. Use with offset to paginate results. None Source code in dbtc/client/admin.py 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 @v3 def list_connections ( self , account_id : int , project_id : int , * , state : int = None , offset : int = None , limit : int = None , ) -> Dict : \"\"\"List connections for a specific account and project Args: account_id (int): Numeric ID of the account to retrieve project_id (int): Numeric ID of the project to retrieve state (int, optional): 1 = active, 2 = deleted offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /connections\" , params = { \"state\" : state , \"limit\" : limit , \"offset\" : offset }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_connections ( account_id , project_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc list-connections","title":"list_connections"},{"location":"guide/cloud/#test_connection","text":"Test a connection Parameters: Name Type Description Default account_id int Numeric ID of the account required payload dict Dictionary representing the connection to test required Source code in dbtc/client/admin.py 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 @v3 def test_connection ( self , account_id : int , payload : Dict ) -> Dict : \"\"\"Test a connection Args: account_id (int): Numeric ID of the account payload (dict): Dictionary representing the connection to test \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /connections/test/\" , method = \"post\" , json = payload )","title":"test_connection"},{"location":"guide/cloud/#update_connection","text":"Update a connection Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required connection_id int Numeric ID of the connection to update required payload dict Dictionary representing the connection to update required Source code in dbtc/client/admin.py 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 @v3 def update_connection ( self , account_id : int , project_id : int , connection_id : int , payload : Dict ) -> Dict : \"\"\"Update a connection Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project connection_id (int): Numeric ID of the connection to update payload (dict): Dictionary representing the connection to update \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /connections/ { connection_id } /\" , method = \"post\" , json = payload , )","title":"update_connection"},{"location":"guide/cloud/#credentials","text":"","title":"Credentials"},{"location":"guide/cloud/#create_credentials","text":"Create credentials Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload dict Dictionary representing the credentials to create required Source code in dbtc/client/admin.py 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 @v3 def create_credentials ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Create credentials Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (dict): Dictionary representing the credentials to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /credentials/\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_credentials ( account_id , project_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc create-credentials --payload = '{\"id\": null, \"account_id\": 1, \"created_by_id\": 1, \"project_id\": 1, \"state\": 1, \"adapter_version\": \"databricks_spark_v0\"}' # noqa: E501 payload = { 'id' : None , 'account_id' : 1 , 'created_by_id' : 1 , 'project_id' : 1 , 'state' : 1 , 'adapter_version' : 'databricks_spark_v0' , }","title":"create_credentials"},{"location":"guide/cloud/#list_credentials","text":"List credentials for a specific account and project Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required project_id int Numeric ID of the project to retrieve required Source code in dbtc/client/admin.py 886 887 888 889 890 891 892 893 894 895 896 @v3 def list_credentials ( self , account_id : int , project_id : int ) -> Dict : \"\"\"List credentials for a specific account and project Args: account_id (int): Numeric ID of the account to retrieve project_id (int): Numeric ID of the project to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /credentials\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_credentials ( account_id , project_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc list-credentials","title":"list_credentials"},{"location":"guide/cloud/#update_credentials","text":"Update credentials Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required credentials_id int Numeric ID of the credentials to update required payload dict Dictionary representing the credentials to update required Source code in dbtc/client/admin.py 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 @v3 def update_credentials ( self , account_id : int , project_id : int , credentials_id : int , payload : Dict ) -> Dict : \"\"\"Update credentials Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project credentials_id (int): Numeric ID of the credentials to update payload (dict): Dictionary representing the credentials to update \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /credentials/ { credentials_id } /\" , # noqa: E50 method = \"post\" , json = payload , )","title":"update_credentials"},{"location":"guide/cloud/#environment","text":"","title":"Environment"},{"location":"guide/cloud/#create_environment","text":"Create an environment Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload dict Dictionary representing the environment to create required Source code in dbtc/client/admin.py 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 @v3 def create_environment ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Create an environment Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (dict): Dictionary representing the environment to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /environments/\" , method = \"post\" , json = payload , )","title":"create_environment"},{"location":"guide/cloud/#delete_environment","text":"Delete job for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required environment_id int Numeric ID of the environment to delete required Source code in dbtc/client/admin.py 402 403 404 405 406 407 408 409 410 411 412 413 @v3 def delete_environment ( self , account_id : int , environment_id : int ) -> Dict : \"\"\"Delete job for a specified account Args: account_id (int): Numeric ID of the account environment_id (int): Numeric ID of the environment to delete \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /environments/ { environment_id } /\" , method = \"delete\" , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . delete_environment ( account_id , project_id , environment_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc delete-environment --environment-id = 1","title":"delete_environment"},{"location":"guide/cloud/#list_environments","text":"List environments for a specific account Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required project_id int or list The project ID or IDs None dbt_version str or list The version of dbt the environment is using None name str Name of the environment to retrieve None type str Type of the environment (deployment or development) None state int 1 = active, 2 = deleted None offset int The offset to apply when listing runs. Use with limit to paginate results. None limit int The limit to apply when listing runs. Use with offset to paginate results. None order_by str Field to order the result by. None Source code in dbtc/client/admin.py 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 @v3 def list_environments ( self , account_id : int , * , project_id : Union [ int , List [ int ]] = None , dbt_version : Union [ str , List [ str ]] = None , name : str = None , type : str = None , state : int = None , offset : int = None , limit : int = None , order_by : str = None , ) -> Dict : \"\"\"List environments for a specific account Args: account_id (int): Numeric ID of the account to retrieve project_id (int or list, optional): The project ID or IDs dbt_version (str or list, optional): The version of dbt the environment is using name (str, optional): Name of the environment to retrieve type (str, optional): Type of the environment (deployment or development) state (int, optional): 1 = active, 2 = deleted offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. order_by (str, optional): Field to order the result by. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /environments/\" , params = { \"project_id__in\" : json_listify ( project_id ), \"dbt_version__in\" : json_listify ( dbt_version ), \"name\" : name , \"type\" : type , \"state\" : state , \"offset\" : offset , \"limit\" : limit , \"order_by\" : order_by , }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_environments ( account_id , project_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc list-environments","title":"list_environments"},{"location":"guide/cloud/#update_environment","text":"Update a connection Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required environment_id int Numeric ID of the environment to update required payload dict Dictionary representing the environment to update required Source code in dbtc/client/admin.py 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 @v3 def update_environment ( self , account_id : int , project_id : int , environment_id : int , payload : Dict ) -> Dict : \"\"\"Update a connection Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project environment_id (int): Numeric ID of the environment to update payload (dict): Dictionary representing the environment to update \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /environments/ { environment_id } /\" , # noqa: E501 method = \"post\" , json = payload , )","title":"update_environment"},{"location":"guide/cloud/#environment-variables","text":"","title":"Environment Variables"},{"location":"guide/cloud/#create_environment_variables","text":"Create environment variabless Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload dict Dictionary representing the environment variables to create required Source code in dbtc/client/admin.py 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 @v3 def create_environment_variables ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Create environment variabless Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (dict): Dictionary representing the environment variables to create \"\"\" url = f \"accounts/ { account_id } /projects/ { project_id } /environment-variables/\" if len ( payload . keys ()) > 1 : url += \"bulk/\" return self . _simple_request ( url , method = \"post\" , json = payload ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_environment_variables ( account_id , project_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc create-credentials --payload = '{\"env_var\": {\"name\": \"DBT_ENV_TEST\", \"ids\": [], \"new_name\": \"DBT_ENV_TEST\", \"project\": \"foo\", \"{{development_environment_name}}\": \"dev_value\", \"{{deployment_environment_name}}\": \"deploy_value\"}}' payload = { 'env_var' : { 'name' : 'DBT_ENV_TEST' , 'ids' : [], 'new_name' : 'DBT_ENV_TEST' , 'project' : 'foo' , '{{development_environment_name}}' : 'dev_value' , '{{deployment_environment_name}}' : 'deploy_value' } }","title":"create_environment_variables"},{"location":"guide/cloud/#delete_environment_variables","text":"Delete environment variables for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload Dict Dictionary representing environment variables to delete required Source code in dbtc/client/admin.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 @v3 def delete_environment_variables ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Delete environment variables for a specified account Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (Dict): Dictionary representing environment variables to delete \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /environment-variables/bulk/\" , method = \"delete\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . delete_environment_variables ( account_id , project_id , environment_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc delete-environment --payload = '{\"name\": \"DBT_MY_AWESOME_VARIABLE\"}' payload = { 'name' : 'DBT_MY_AWESOME_VARIABLE' }","title":"delete_environment_variables"},{"location":"guide/cloud/#feature-flags","text":"","title":"Feature Flags"},{"location":"guide/cloud/#list_feature_flags","text":"List feature flags for a specific account Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required Source code in dbtc/client/admin.py 1005 1006 1007 1008 1009 1010 1011 1012 @v3 def list_feature_flags ( self , account_id : int ) -> Dict : \"\"\"List feature flags for a specific account Args: account_id (int): Numeric ID of the account to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /feature-flag/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_feature_flags ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-feature-flags","title":"list_feature_flags"},{"location":"guide/cloud/#group","text":"","title":"Group"},{"location":"guide/cloud/#assign_group_permissions","text":"Assign group permissions Parameters: Name Type Description Default account_id int Numeric ID of the account required group_id int Numeric ID of the group required payload dict Dictionary representing the group to create required Source code in dbtc/client/admin.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 @v3 def assign_group_permissions ( self , account_id : int , group_id : int , payload : Dict ) -> Dict : \"\"\"Assign group permissions Args: account_id (int): Numeric ID of the account group_id (int): Numeric ID of the group payload (dict): Dictionary representing the group to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /group-permissions/ { group_id } /\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . assign_service_token_permissions ( account_id , group_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc assign-group-permissions --payload = '[{\"group_id\": 1, \"account_id\": 1, \"permission_set\": \"analyst\", \"project_id\": 1, \"all_projects\": false}]' payload = [ { 'group_id' : 1 , 'account_id' : 1 , 'permission_set' : 'analyst' , 'project_id' : 1 , 'all_projects' : False }, ]","title":"assign_group_permissions"},{"location":"guide/cloud/#assign_user_to_group","text":"Assign a user to a group Parameters: Name Type Description Default account_id int Numeric ID of the account required payload dict Dictionary representing the user to assign required Source code in dbtc/client/admin.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 @v3 def assign_user_to_group ( self , account_id : int , payload : Dict ) -> Dict : \"\"\"Assign a user to a group Args: account_id (int): Numeric ID of the account payload (dict): Dictionary representing the user to assign { \"user_id\": int, \"desired_group_ids\": list(int) } \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /assign-groups/\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . assign_user_to_group ( account_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc assign-user-to-group --payload = '{\"user_id\": 1, \"desired_group_ids\": [1]}' payload = { 'user_id' : 1 , 'desired_group_ids' : [ 1 ], }","title":"assign_user_to_group"},{"location":"guide/cloud/#create_user_group","text":"Create a user group Parameters: Name Type Description Default account_id int Numeric ID of the account required payload dict Dictionary representing the group to create required Note The group_name is the name of the dbt Cloud group. The list of sso_mapping_groups are string values that dbt Cloud will attempt to match with incoming information from your identity provider at login time, in order to assign the group with group_name to the user. Source code in dbtc/client/admin.py 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 @v3 def create_user_group ( self , account_id : int , payload : Dict ) -> Dict : \"\"\"Create a user group Args: account_id (int): Numeric ID of the account payload (dict): Dictionary representing the group to create !!! note The group_name is the name of the dbt Cloud group. The list of sso_mapping_groups are string values that dbt Cloud will attempt to match with incoming information from your identity provider at login time, in order to assign the group with group_name to the user. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /groups/\" , method = \"post\" , json = payload ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_user_group ( account_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc create-user-group --payload = '{\"account_id\": 1, \"name\": \"{{group_name}}\", \"assign_by_default\": false, \"sso_mapping_groups\": [\"mapping_group_1\"]}' payload = { 'account_id' : 1 , 'name' : '{{group_name}}' , 'assign_by_default' : False , 'sso_mapping_groups' :[ 'mapping_group_1' ] }","title":"create_user_group"},{"location":"guide/cloud/#delete_user_group","text":"Delete group for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required group_id int Numeric ID of the group to delete required payload dict Dictionary representing the group to delete with the format { \"account_id\": int, \"name\": str, \"id\": int, \"state\":2, \"assign_by_default\":false, \"sso_mapping_groups\": list } required Source code in dbtc/client/admin.py 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 @v3 def delete_user_group ( self , account_id : int , group_id : int , payload : Dict ) -> Dict : \"\"\"Delete group for a specified account Args: account_id (int): Numeric ID of the account group_id (int): Numeric ID of the group to delete payload (dict): Dictionary representing the group to delete with the format { \"account_id\": int, \"name\": str, \"id\": int, \"state\":2, \"assign_by_default\":false, \"sso_mapping_groups\": list } \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /groups/ { group_id } /\" , method = \"post\" , payload = payload ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . delete_group ( account_id , group_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc delete-environment --group-id = 1 payload = { 'account_id' : 1 , 'name' : '{{ group_name }}' , 'id' : 1 , 'state' : 2 , 'assign_by_default' : False , 'sso_mapping_groups' : [] }","title":"delete_user_group"},{"location":"guide/cloud/#list_groups","text":"List groups for a specific account and project Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required Source code in dbtc/client/admin.py 1014 1015 1016 1017 1018 1019 1020 1021 @v3 def list_groups ( self , account_id : int ) -> Dict : \"\"\"List groups for a specific account and project Args: account_id (int): Numeric ID of the account to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /groups/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_groups ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-groups","title":"list_groups"},{"location":"guide/cloud/#job","text":"","title":"Job"},{"location":"guide/cloud/#create_job","text":"Create a job Parameters: Name Type Description Default account_id int Numeric ID of the account required payload dict Dictionary representing the job to create required Source code in dbtc/client/admin.py 261 262 263 264 265 266 267 268 269 270 271 272 273 @v2 def create_job ( self , account_id : int , payload : Dict ) -> Dict : \"\"\"Create a job Args: account_id (int): Numeric ID of the account payload (dict): Dictionary representing the job to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /jobs/\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_job ( account_id , project_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc create-credentials --payload = '{\"account_id\": 1, \"project_id\": 1, \"id\": null, \"environment_id\": 1, \"name\": \"<your-job-name>\", \"dbt_version\": \"1.0.1\", \"triggers\": {\"github_webhook\": false, \"schedule\": false, \"custom_branch_only\": false}, \"execute_steps\": [\"dbt build\"], \"settings\": {\"threads\": 1, \"target_name\": \"default\"}, \"state\": 1, \"generate_docs\": false, \"schedule\": {\"date\": {\"type\": \"every_day\"}, \"time\": {\"type\": \"every_hour\", \"interval\": 1}}}' payload = { 'account_id' : 1 , 'project_id' : 1 , 'id' : None , 'environment_id' : 1 , 'name' : '<your-job-name>' , 'dbt_version' : '1.0.1' , 'triggers' : { 'github_webhook' : False , 'schedule' : False , 'custom_branch_only' : False }, 'execute_steps' : [ 'dbt build' ], 'settings' : { 'threads' : 1 , 'target_name' : 'default' }, 'state' : 1 , 'generate_docs' : False , 'schedule' : { 'date' : { 'type' : 'every_day' }, 'time' : { 'type' : 'every_hour' , 'interval' : 1 } } }","title":"create_job"},{"location":"guide/cloud/#delete_job","text":"Delete job for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required job_id int Numeric ID of the project to delete required Source code in dbtc/client/admin.py 432 433 434 435 436 437 438 439 440 441 442 443 @v2 def delete_job ( self , account_id : int , job_id : int ) -> Dict : \"\"\"Delete job for a specified account Args: account_id (int): Numeric ID of the account job_id (int): Numeric ID of the project to delete \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /jobs/ { job_id } /\" , method = \"delete\" , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . delete_job ( account_id , job_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc delete-environment --job-id = 1","title":"delete_job"},{"location":"guide/cloud/#get_job","text":"Get a job by its ID. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required job_id int Numeric ID of the job to retrieve required order_by str Field to order the result by. Use - to indicate reverse order. None Source code in dbtc/client/admin.py 541 542 543 544 545 546 547 548 549 550 551 552 553 554 @v2 def get_job ( self , account_id : int , job_id : int , * , order_by : str = None ) -> Dict : \"\"\"Get a job by its ID. Args: account_id (int): Numeric ID of the account to retrieve job_id (int): Numeric ID of the job to retrieve order_by (str, optional): Field to order the result by. Use - to indicate reverse order. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /jobs/ { job_id } /\" , params = { \"order_by\" : order_by }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_job ( account_id , job_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-job --job-id = 1","title":"get_job"},{"location":"guide/cloud/#list_jobs","text":"List jobs in an account or specific project. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required environment_id int Numeric ID of the environment to retrieve None project_id int or list The project ID or IDs None state int 1 = active, 2 = deleted None offset int The offset to apply when listing runs. Use with limit to paginate results. None limit int The limit to apply when listing runs. Use with offset to paginate results. None order_by str Field to order the result by. Use - to indicate reverse order. None Source code in dbtc/client/admin.py 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 @v2 def list_jobs ( self , account_id : int , * , environment_id : int = None , project_id : Union [ int , List [ int ]] = None , state : int = None , offset : int = None , limit : int = None , order_by : str = None , ) -> Dict : \"\"\"List jobs in an account or specific project. Args: account_id (int): Numeric ID of the account to retrieve environment_id (int): Numeric ID of the environment to retrieve project_id (int or list, optional): The project ID or IDs state (int, optional): 1 = active, 2 = deleted offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. order_by (str, optional): Field to order the result by. Use - to indicate reverse order. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /jobs/\" , params = { \"environment_id\" : environment_id , \"project_id__in\" : json_listify ( project_id ), \"state\" : state , \"offset\" : offset , \"limit\" : limit , \"order_by\" : order_by , }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_jobs ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-jobs","title":"list_jobs"},{"location":"guide/cloud/#trigger_autoscaling_ci_job","text":"Trigger an autoscaling CI job Info In the event your CI job is already running, this will do the following: If a new commit is created for the currently running job, cancel the job and then trigger again If this is an entirely new pull request, clone the job and trigger This will also check to see if your account has met or exceeded the allotted run slots. In the event you have, a cloned job will not be created and the existing job will be triggered. More info here Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required job_id int Numeric ID of the job to trigger required payload dict Payload required in triggering a job. It's important that the payload consists of the following keys in order to mimic the native behavior of dbt Cloud's Slim CI functionality: git_sha cause schema_override Depending on your git provider, one of github_pull_request_id , gitlab_merge_request_id , or azure_pull_request_id required should_poll bool Poll until completion if True , completion is one of success, failure, or cancelled False poll_interval int Number of seconds to wait in between polling 10 delete_cloned_job bool Indicate if cloned job should be deleted after being triggered True max_run_slots int Number of run slots that should be available to this process. This will limit the ability to run concurrent PRs up the the allocated run slots for your account. When set to None , the run_slots allocated to your account will be used to determine if a job should be cloned. None Source code in dbtc/client/admin.py 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 @set_called_from @v2 def trigger_autoscaling_ci_job ( self , account_id : int , job_id : int , payload : Dict , * , should_poll : bool = False , poll_interval : int = 10 , delete_cloned_job : bool = True , max_run_slots : int = None , ): \"\"\"Trigger an autoscaling CI job !!! info In the event your CI job is already running, this will do the following: - If a new commit is created for the currently running job, cancel the job and then trigger again - If this is an entirely new pull request, clone the job and trigger - This will also check to see if your account has met or exceeded the allotted run slots. In the event you have, a cloned job will not be created and the existing job will be triggered. More info [here](/latest/guide/autoscaling_ci) Args: account_id (int): Numeric ID of the account to retrieve job_id (int): Numeric ID of the job to trigger payload (dict): Payload required in triggering a job. It's important that the payload consists of the following keys in order to mimic the native behavior of dbt Cloud's Slim CI functionality: - `git_sha` - `cause` - `schema_override` - Depending on your git provider, one of `github_pull_request_id`, `gitlab_merge_request_id`, or `azure_pull_request_id` should_poll (bool, optional): Poll until completion if `True`, completion is one of success, failure, or cancelled poll_interval (int, optional): Number of seconds to wait in between polling delete_cloned_job (bool, optional): Indicate if cloned job should be deleted after being triggered max_run_slots (int, optional): Number of run slots that should be available to this process. This will limit the ability to run concurrent PRs up the the allocated run slots for your account. When set to `None`, the `run_slots` allocated to your account will be used to determine if a job should be cloned. \"\"\" self . console . log ( \"Finding any in progress runs...\" ) cloned_job = None payload_pr_id = None pull_request_key : Optional [ str ] = None # Get all runs in \"running\" state in_progress_runs = self . list_runs ( account_id , status = [ \"queued\" , \"starting\" , \"running\" ], include_related = [ \"trigger\" ], ) . get ( \"data\" , []) # Find any runs that match the job_id specified in function signature in_progress_job_run = [ r for r in in_progress_runs if r . get ( \"job_definition_id\" , - 1 ) == job_id ] # Find the valid pull_request_key to use in pulling out relevant PR IDs for pull_request_key in PULL_REQUESTS : if pull_request_key in payload : payload_pr_id = payload [ pull_request_key ] break else : pull_request_key = None # This will be used to identify if the PR within the payload has a run # that's in a running state. in_progress_pr_run = [ r for r in in_progress_runs if r . get ( \"trigger\" , {}) . get ( pull_request_key , - 1 ) == payload_pr_id ] if in_progress_pr_run : # A PR should only have one run in a queued, running, or starting state # at any given time pr_run = in_progress_pr_run [ 0 ] self . console . log ( f \"Found an in progress run for PR # { payload_pr_id } . Run \" f ' { pr_run [ \"id\" ] } will be canceled and a job triggered for the new ' \"commit.\" ) _ = self . cancel_run ( account_id , pr_run [ \"id\" ]) else : pr_run = {} if in_progress_job_run : # Job can only have one run in a queued, running, or starting state job_run = in_progress_job_run [ 0 ] job_run_is_pr_run = pr_run . get ( \"id\" , None ) == job_run [ \"id\" ] # Only clone the job if this job run isn't the same as the PR run we just # cancelled above if not job_run_is_pr_run : run_slots = ( self . get_account ( account_id ) . get ( \"data\" , {}) . get ( \"run_slots\" , 0 ) ) max_run_slots = min ( max_run_slots or run_slots , run_slots ) if max_run_slots > len ( in_progress_runs ): self . console . log ( f 'Job { job_id } is currently being used in run { job_run [ \"id\" ] } . ' \"This job definition will be cloned and then triggered for \" f \"pull request # { payload_pr_id } .\" ) current_job = self . get_job ( account_id , job_id ) . get ( \"data\" , {}) # Alter the current job definition so it can be cloned read_only_fields = [ \"is_deferrable\" , \"raw_dbt_version\" , \"job_type\" ] for read_only_field in read_only_fields : current_job . pop ( read_only_field ) current_job [ \"id\" ] = None now = datetime . now () . strftime ( \"%m/ %d /%Y %H:%M:%S\" ) current_job [ \"name\" ] = current_job [ \"name\" ] + f \" [CLONED { now } ]\" cloned_job = self . create_job ( account_id , current_job )[ \"data\" ] # Modify the should_poll argument - this needs to be `True` # if we're deleting the cloned job. Otherwise, dbt Cloud # will cancel the run because it can't find an associated job if delete_cloned_job : should_poll = True job_id = cloned_job [ \"id\" ] else : self . console . log ( \"Not cloning the job as your account has met or exceeded the \" \"number of run slots or a limit was placed by the user. The \" \"normal job will be queued.\" ) else : self . console . log ( \"No in progress job run found. Triggering as normal\" ) run = self . trigger_job ( account_id , job_id , payload , should_poll = should_poll , poll_interval = poll_interval , ) # This property was set to `None` in the trigger_job method, reset here self . _called_from = \"trigger_autoscaling_ci_job\" if cloned_job is not None and delete_cloned_job : self . delete_job ( account_id , job_id ) return run","title":"trigger_autoscaling_ci_job"},{"location":"guide/cloud/#trigger_job","text":"Trigger a job by its ID Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required job_id int Numeric ID of the job to trigger required payload dict Payload required for post request required should_poll bool Poll until completion if True , completion is one of success, failure, or cancelled True poll_interval int Number of seconds to wait in between polling 10 Source code in dbtc/client/admin.py 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 @set_called_from @v2 def trigger_job ( self , account_id : int , job_id : int , payload : Dict , * , should_poll : bool = True , poll_interval : int = 10 , retries : int = 0 , ): \"\"\"Trigger a job by its ID Args: account_id (int): Numeric ID of the account to retrieve job_id (int): Numeric ID of the job to trigger payload (dict): Payload required for post request should_poll (bool, optional): Poll until completion if `True`, completion is one of success, failure, or cancelled poll_interval (int, optional): Number of seconds to wait in between polling \"\"\" def is_run_complete ( run : Dict ): return run [ \"data\" ][ \"status\" ] in [ JobRunStatus . SUCCESS , JobRunStatus . CANCELLED , ] run = self . _simple_request ( f \"accounts/ { account_id } /jobs/ { job_id } /run/\" , method = \"post\" , json = payload , ) if not run [ \"status\" ][ \"is_success\" ]: self . console . log ( f \"Run NOT triggered for job { job_id } . See run response.\" ) return run self . console . log ( self . _run_status_formatted ( run , 0 )) if should_poll or retries > 0 : run = self . _poll_for_completion ( run , poll_interval ) while retries > 0 and not is_run_complete ( run ): self . console . log ( f \"Retrying job { job_id } after failure. Retries left: { retries - 1 } \" ) run = self . trigger_job_from_failure ( account_id , job_id ) retries -= 1 return run","title":"trigger_job"},{"location":"guide/cloud/#trigger_job_from_failure","text":"Trigger job from point of failure Use this method to retry a failed run for a job from the point of failure, if the run failed. Otherwise trigger a new run. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required job_id int Numeric ID of the job to trigger required Source code in dbtc/client/admin.py 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 @set_called_from @v2 def trigger_job_from_failure ( self , account_id : int , job_id : int , * , should_poll : bool = True , poll_interval : int = 10 , ): \"\"\"Trigger job from point of failure Use this method to retry a failed run for a job from the point of failure, if the run failed. Otherwise trigger a new run. Args: account_id (int): Numeric ID of the account to retrieve job_id (int): Numeric ID of the job to trigger \"\"\" run = self . _simple_request ( f \"accounts/ { account_id } /jobs/ { job_id } /rerun/\" , method = \"post\" , ) self . console . log ( self . _run_status_formatted ( run , 0 )) if should_poll : run = self . _poll_for_completion ( run , poll_interval ) return run","title":"trigger_job_from_failure"},{"location":"guide/cloud/#update_job","text":"Update a job by its ID. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required job_id int Numeric ID of the job to retrieve required payload dict Payload required for post request required Source code in dbtc/client/admin.py 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 @v2 def update_job ( self , account_id : int , job_id : int , payload : Dict ) -> Dict : \"\"\"Update a job by its ID. Args: account_id (int): Numeric ID of the account to retrieve job_id (int): Numeric ID of the job to retrieve payload (dict): Payload required for post request \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /jobs/ { job_id } /\" , method = \"post\" , json = payload , )","title":"update_job"},{"location":"guide/cloud/#repository","text":"","title":"Repository"},{"location":"guide/cloud/#create_repository","text":"Create a repository Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required payload dict Dictionary representing the repository to create required Note After creating / updating a dbt Cloud repository's SSH key, you will need to add the generated key text as a deploy key to the target repository. This gives dbt Cloud permissions to read / write in the repository You can read more in the docs # noqa: E501 Source code in dbtc/client/admin.py 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 @v3 def create_repository ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Create a repository Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project payload (dict): Dictionary representing the repository to create !!! note After creating / updating a dbt Cloud repository's SSH key, you will need to add the generated key text as a deploy key to the target repository. This gives dbt Cloud permissions to read / write in the repository You can read more in the [docs](https://docs.getdbt.com/docs/dbt-cloud/cloud-configuring-dbt-cloud/cloud-configuring-repositories) # noqa: E501 \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /repositories/\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_repository ( account_id , project_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc create-repository --payload = '{\"account_id\": 1, \"project_id\": 1, \"remote_url\": \"{{git_clone_url}}\", \"git_clone_strategy\": \"deploy_key\", \"github_installation_id\": null, \"token_str\": null}' payload = { 'account_id' : 1 , 'project_id' : 1 , 'remote_url' : '{{git_clone_url}}' , 'git_clone_strategy' : 'deploy_key' , 'github_installation_id' : None , 'token_str' : None }","title":"create_repository"},{"location":"guide/cloud/#delete_repository","text":"Delete repository for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required repository_id int Numeric ID of the repository to delete required Source code in dbtc/client/admin.py 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 @v3 def delete_repository ( self , account_id : int , project_id : int , repository_id : int ) -> Dict : \"\"\"Delete repository for a specified account Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project repository_id (int): Numeric ID of the repository to delete \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /repositories/ { repository_id } \" , method = \"delete\" , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . delete_repository ( account_id , project_id , repository_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc delete-repository --repository-id = 1","title":"delete_repository"},{"location":"guide/cloud/#list_repositories","text":"List repositories for a specific account and project Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required project_id int Numeric ID of the project to retrieve required Source code in dbtc/client/admin.py 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 @v3 def list_repositories ( self , account_id : int , project_id : int ) -> Dict : \"\"\"List repositories for a specific account and project Args: account_id (int): Numeric ID of the account to retrieve project_id (int): Numeric ID of the project to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /repositories/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_repositories ( account_id , project_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc list-repositories","title":"list_repositories"},{"location":"guide/cloud/#update_repository","text":"Update a connection Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project required repository_id int Numeric ID of the repository to update required payload dict Dictionary representing the repository to update required Source code in dbtc/client/admin.py 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 @v3 def update_repository ( self , account_id : int , project_id : int , repository_id : int , payload : Dict ) -> Dict : \"\"\"Update a connection Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project repository_id (int): Numeric ID of the repository to update payload (dict): Dictionary representing the repository to update \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /repositories/ { repository_id } /\" , # noqa: E501 method = \"post\" , json = payload , )","title":"update_repository"},{"location":"guide/cloud/#run","text":"","title":"Run"},{"location":"guide/cloud/#cancel_run","text":"Cancel a run. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required run_id int Numeric ID of the run to retrieve required Source code in dbtc/client/admin.py 163 164 165 166 167 168 169 170 171 172 173 174 @v2 def cancel_run ( self , account_id : int , run_id : int ) -> Dict : \"\"\"Cancel a run. Args: account_id (int): Numeric ID of the account to retrieve run_id (int): Numeric ID of the run to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /runs/ { run_id } /cancel\" , method = \"post\" , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . cancel_run ( account_id , run_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. ```bash dbtc cancel-run --account-id=1 --run-id=1","title":"cancel_run"},{"location":"guide/cloud/#get_most_recent_run","text":"Get the most recent run Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required include_related list List of related fields to pull with the run. Valid values are trigger , job , repository , debug_logs , run_steps , and environment . None job_definition_id int Applies a filter to only return runs from the specified Job. None environment_id int Numeric ID of the environment None project_id int or list The project ID or IDs None deferring_run_id int Numeric ID of a deferred run None status str or list The status to apply when listing runs. Options include queued, starting, running, success, error, and cancelled None Source code in dbtc/client/admin.py 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 @set_called_from @v2 def get_most_recent_run ( self , account_id : int , * , include_related : List [ str ] = None , job_definition_id : int = None , environment_id : int = None , project_id : int = None , deferring_run_id : int = None , status : Union [ List [ str ], str ] = None , ) -> Dict : \"\"\"Get the most recent run Args: account_id (int): Numeric ID of the account to retrieve include_related (list): List of related fields to pull with the run. Valid values are `trigger`, `job`, `repository`, `debug_logs`, `run_steps`, and `environment`. job_definition_id (int, optional): Applies a filter to only return runs from the specified Job. environment_id (int, optional): Numeric ID of the environment project_id (int or list, optional): The project ID or IDs deferring_run_id (int, optional): Numeric ID of a deferred run status (str or list, optional): The status to apply when listing runs. Options include queued, starting, running, success, error, and cancelled \"\"\" runs = self . list_runs ( account_id , include_related = include_related , job_definition_id = job_definition_id , environment_id = environment_id , project_id = project_id , deferring_run_id = deferring_run_id , order_by = \"-id\" , limit = 1 , status = status , ) try : runs [ \"data\" ] = runs . get ( \"data\" , [])[ 0 ] except IndexError : runs [ \"data\" ] = {} return runs Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_most_recent_run ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-most-recent-run","title":"get_most_recent_run"},{"location":"guide/cloud/#get_run","text":"Get a run by its ID. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required run_id int Numeric ID of the run to retrieve required include_related list List of related fields to pull with the run. Valid values are trigger , job , repository , debug_logs , run_steps , and environment . None Source code in dbtc/client/admin.py 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 @v2 def get_run ( self , account_id : int , run_id : int , * , include_related : List [ str ] = None ) -> Dict : \"\"\"Get a run by its ID. Args: account_id (int): Numeric ID of the account to retrieve run_id (int): Numeric ID of the run to retrieve include_related (list): List of related fields to pull with the run. Valid values are `trigger`, `job`, `repository`, `debug_logs`, `run_steps`, and `environment`. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /runs/ { run_id } \" , params = { \"include_related\" : \",\" . join ( include_related or [])}, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_run ( account_id , run_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-run --run-id = 1","title":"get_run"},{"location":"guide/cloud/#get_run_timing_details","text":"Retrieves the timing details related to a run Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required run_id int Numeric ID of the run to retrieve required Source code in dbtc/client/admin.py 773 774 775 776 777 778 779 780 781 782 783 784 785 @v3 def get_run_timing_details ( self , account_id : int , project_id : int , run_id : int ) -> Dict : \"\"\"Retrieves the timing details related to a run Args: account_id (int): Numeric ID of the account to retrieve run_id (int): Numeric ID of the run to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /runs/ { run_id } /timing/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_run_timing_details ( account_id , project_id , run_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc get-run-timing-details --run-id = 1","title":"get_run_timing_details"},{"location":"guide/cloud/#list_runs","text":"List runs in an account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required include_related list List of related fields to pull with the run. Valid values are trigger , job , repository , debug_logs , run_steps , and environment . None job_definition_id int Applies a filter to only return runs from the specified Job. None environment_id int Numeric ID of the environment None project_id int or list The project ID or IDs None deferring_run_id int Numeric ID of a deferred run None status str or list The status to apply when listing runs. Options include queued, starting, running, success, error, and cancelled None order_by str Field to order the result by. Use - to indicate reverse order. None offset int The offset to apply when listing runs. Use with limit to paginate results. None limit int The limit to apply when listing runs. Use with offset to paginate results. None Source code in dbtc/client/admin.py 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 @v2 def list_runs ( self , account_id : int , * , include_related : List [ str ] = None , job_definition_id : int = None , environment_id : int = None , project_id : Union [ int , List [ int ]] = None , deferring_run_id : int = None , status : Union [ List [ str ], str ] = None , order_by : str = None , offset : int = None , limit : int = None , ) -> Dict : \"\"\"List runs in an account. Args: account_id (int): Numeric ID of the account to retrieve include_related (list): List of related fields to pull with the run. Valid values are `trigger`, `job`, `repository`, `debug_logs`, `run_steps`, and `environment`. job_definition_id (int, optional): Applies a filter to only return runs from the specified Job. environment_id (int, optional): Numeric ID of the environment project_id (int or list, optional): The project ID or IDs deferring_run_id (int, optional): Numeric ID of a deferred run status (str or list, optional): The status to apply when listing runs. Options include queued, starting, running, success, error, and cancelled order_by (str, optional): Field to order the result by. Use - to indicate reverse order. offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. \"\"\" if status is not None : try : status = [ getattr ( JobRunStatus , s . upper ()) for s in listify ( status )] except AttributeError : raise else : status = json . dumps ( status ) return self . _simple_request ( f \"accounts/ { account_id } /runs\" , params = { \"include_related\" : \",\" . join ( include_related or []), \"job_definition_id\" : job_definition_id , \"environment_id\" : environment_id , \"project_id__in\" : json_listify ( project_id ), \"deferring_run_id\" : deferring_run_id , \"order_by\" : order_by , \"offset\" : offset , \"limit\" : limit , \"status__in\" : status , }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_runs ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-runs","title":"list_runs"},{"location":"guide/cloud/#project","text":"","title":"Project"},{"location":"guide/cloud/#create_project","text":"Create a project Parameters: Name Type Description Default account_id int Numeric ID of the account required payload dict Dictionary representing the project to create required Source code in dbtc/client/admin.py 275 276 277 278 279 280 281 282 283 284 285 @v3 def create_project ( self , account_id : int , payload : Dict ) -> Dict : \"\"\"Create a project Args: account_id (int): Numeric ID of the account payload (dict): Dictionary representing the project to create \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/\" , method = \"post\" , json = payload ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_project ( account_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc create-project --payload = '{\"id\": null, \"name\": \"{{project_name}}\", \"dbt_project_subdirectory\": null, \"account_id\": 1, \"connection_id\": null, \"repository_id\": null}' payload = { 'id' : None , 'name' : '{{project_name}}' , 'dbt_project_subdirectory' : None , 'account_id' : 1 , 'connection_id' : None , 'repository_id' : None }","title":"create_project"},{"location":"guide/cloud/#delete_project","text":"Delete project for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project to delete required Source code in dbtc/client/admin.py 445 446 447 448 449 450 451 452 453 454 455 456 @v3 def delete_project ( self , account_id : int , project_id : int ) -> Dict : \"\"\"Delete project for a specified account Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project to delete \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /\" , method = \"delete\" , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . delete_project ( account_id , project_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc delete-project","title":"delete_project"},{"location":"guide/cloud/#get_project","text":"Get a project by its ID. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required project_id int Numeric ID of the project to retrieve required Source code in dbtc/client/admin.py 556 557 558 559 560 561 562 563 564 @v2 def get_project ( self , account_id : int , project_id : int ) -> Dict : \"\"\"Get a project by its ID. Args: account_id (int): Numeric ID of the account to retrieve project_id (int): Numeric ID of the project to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } \" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_project ( account_id , project_id ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc get-project","title":"get_project"},{"location":"guide/cloud/#get_project_by_name","text":"Get a project by its name. Parameters: Name Type Description Default project_name str Name of project to retrieve required account_id int Numeric ID of the account to retrieve None account_name str Name of account to retrieve None Source code in dbtc/client/admin.py 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 @set_called_from @v2 def get_project_by_name ( self , project_name : str , account_id : int = None , account_name : str = None ) -> Dict : \"\"\"Get a project by its name. Args: project_name (str): Name of project to retrieve account_id (int, optional): Numeric ID of the account to retrieve account_name (str, optional): Name of account to retrieve \"\"\" if account_id is None and account_name is None : accounts = self . list_accounts () for account in accounts [ \"data\" ]: projects = self . list_projects ( account [ \"id\" ]) project = self . _get_by_name ( projects [ \"data\" ], project_name ) if project is not None : break else : if account_id is not None : account = self . get_account ( account_id ) else : account = self . get_account_by_name ( account_name ) if account . get ( \"data\" , None ) is not None : projects = self . list_projects ( account [ \"data\" ][ \"id\" ]) project = self . _get_by_name ( projects [ \"data\" ], project_name ) else : project = None if project is not None : return self . get_project ( project [ \"account_id\" ], project [ \"id\" ]) raise Exception ( f 'Project \" { project_name } \" was not found.' ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_project_by_name ( account_id , project_name ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-project --project-name = name","title":"get_project_by_name"},{"location":"guide/cloud/#list_projects","text":"List projects for a specified account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required project_id int or list The project ID or IDs None state int 1 = active, 2 = deleted None offset int The offset to apply when listing runs. Use with limit to paginate results. None limit int The limit to apply when listing runs. Use with offset to paginate results. None Source code in dbtc/client/admin.py 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 @v3 def list_projects ( self , account_id : int , * , project_id : Union [ int , List [ int ]] = None , state : int = None , offset : int = None , limit : int = None , ) -> Dict : \"\"\"List projects for a specified account. Args: account_id (int): Numeric ID of the account to retrieve project_id (int or list, optional): The project ID or IDs state (int, optional): 1 = active, 2 = deleted offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects\" , params = { \"pk__in\" : json_listify ( project_id ), \"state\" : state , \"offset\" : offset , \"limit\" : limit , }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_projects ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-projects","title":"list_projects"},{"location":"guide/cloud/#update_project","text":"Update project for a specified account Parameters: Name Type Description Default account_id int Numeric ID of the account required project_id int Numeric ID of the project to update required payload dict Dictionary representing the project to update required Source code in dbtc/client/admin.py 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 @v3 def update_project ( self , account_id : int , project_id : int , payload : Dict ) -> Dict : \"\"\"Update project for a specified account Args: account_id (int): Numeric ID of the account project_id (int): Numeric ID of the project to update payload (dict): Dictionary representing the project to update \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /projects/ { project_id } /\" , method = \"POST\" , json = payload )","title":"update_project"},{"location":"guide/cloud/#service-token","text":"","title":"Service Token"},{"location":"guide/cloud/#assign_service_token_permissions","text":"Assign permissions to a service token. Parameters: Name Type Description Default account_id int Numeric ID of the account required service_token_id int Numeric ID of the service token required payload list List of dictionaries representing the permissions to assign required Source code in dbtc/client/admin.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @v3 def assign_service_token_permissions ( self , account_id : int , service_token_id : int , payload : List [ Dict ] ) -> Dict : \"\"\"Assign permissions to a service token. Args: account_id (int): Numeric ID of the account service_token_id (int): Numeric ID of the service token payload (list): List of dictionaries representing the permissions to assign \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /service-tokens/ { service_token_id } /permissions/\" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . assign_service_token_permissions ( account_id , service_token_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables have been set. dbtc assign-service-token-permissions --payload = '[{\"service_token_id\": 1, \"account_id\": 1, \"permission_set\": \"job_viewer\", \"project_id\": 1, \"all_projects\": false}]' payload = [ { 'service_token_id' : 1 , 'account_id' : 1 , 'permission_set' : 'job_viewer' , 'project_id' : 1 , 'all_projects' : False }, ]","title":"assign_service_token_permissions"},{"location":"guide/cloud/#create_service_token","text":"Create a service token Parameters: Name Type Description Default account_id int Numeric ID of the account required payload dict Dictionary representing the service token to create required Note This request creates a service token, but does not assign permissions to it. Permissions are assigned via the assign_service_token_permissions See the user tokens # noqa: E501 and service tokens # noqa: E501 documentation for more information. Source code in dbtc/client/admin.py 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 @v3 def create_service_token ( self , account_id : int , payload : Dict ) -> Dict : \"\"\"Create a service token Args: account_id (int): Numeric ID of the account payload (dict): Dictionary representing the service token to create !!! note This request creates a service token, but does not assign permissions to it. Permissions are assigned via the [assign_service_token_permissions](cloud.md#assign_service_token_permissions) See the [user tokens](https://docs.getdbt.com/docs/dbt-cloud/dbt-cloud-api/user-tokens) # noqa: E501 and [service tokens](https://docs.getdbt.com/docs/dbt-cloud/dbt-cloud-api/service-tokens) # noqa: E501 documentation for more information. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /service-tokens/\" , method = \"post\" , json = payload ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . create_service_token ( account_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc create-service-token --payload = '{\"id\": null, \"name\": \"api-test\", \"state\": 1, \"account_id\": 1, \"access\": {\"admin\": {\"permissionSet\": \"admin\", \"projects\": [1]}, \"job_admin\": {\"permissionSet\": \"job_admin\", \"projects\": [1]}}}' payload = { 'id' : None , 'name' : 'api-test' , 'state' : 1 , 'account_id' : 1 , 'access' : { 'admin' : { 'permissionSet' : 'admin' , 'projects' : [ 1 ] }, 'job_admin' : { 'permissionSet' : 'job_admin' , 'projects' : [ 1 ] } } }","title":"create_service_token"},{"location":"guide/cloud/#get_service_token","text":"Retrieves a service token. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required service_token_id int Numeric ID of the service token to retrieve required Source code in dbtc/client/admin.py 787 788 789 790 791 792 793 794 795 796 797 @v3 def get_service_token ( self , account_id : int , service_token_id : int ) -> Dict : \"\"\"Retrieves a service token. Args: account_id (int): Numeric ID of the account to retrieve service_token_id (int): Numeric ID of the service token to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /service-tokens/ { service_token_id } \" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_service_toke ( account_id , service_token_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get-service-token --service-token-id = 1","title":"get_service_token"},{"location":"guide/cloud/#list_service_tokens","text":"List service tokens for a specific account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required Source code in dbtc/client/admin.py 1209 1210 1211 1212 1213 1214 1215 1216 @v3 def list_service_tokens ( self , account_id : int ) -> Dict : \"\"\"List service tokens for a specific account. Args: account_id (int): Numeric ID of the account to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /service-tokens/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_service_tokens ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-service-tokens","title":"list_service_tokens"},{"location":"guide/cloud/#list_service_token_permissions","text":"List service token permissions for a specific account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required service_token_id int Numeric ID of the service token to retrieve required Source code in dbtc/client/admin.py 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 @v3 def list_service_token_permissions ( self , account_id : int , service_token_id : int ) -> Dict : \"\"\"List service token permissions for a specific account. Args: account_id (int): Numeric ID of the account to retrieve service_token_id (int): Numeric ID of the service token to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /service-tokens/ { service_token_id } /permissions\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_service_token_permissions ( account_id , service_token_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-service-token-permissions --service-token-id = 1","title":"list_service_token_permissions"},{"location":"guide/cloud/#user","text":"","title":"User"},{"location":"guide/cloud/#deactivate_user_license","text":"Deactivate user license Parameters: Name Type Description Default account_id int Numeric ID of the account required permission_id int Numeric ID of the permission that contains user you'd like to deactivate required Note Ensure the groups object contains all of a user's assigned group permissions. This request will fail if a user has already been deactivated. Source code in dbtc/client/admin.py 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 @v2 def deactivate_user_license ( self , account_id : int , permission_id : int , payload : Dict ) -> Dict : \"\"\"Deactivate user license Args: account_id (int): Numeric ID of the account permission_id (int): Numeric ID of the permission that contains user you'd like to deactivate !!! note Ensure the `groups` object contains all of a user's assigned group permissions. This request will fail if a user has already been deactivated. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /permissions/ { permission_id } \" , method = \"post\" , json = payload , ) Examples: Python CLI Payload Assuming that client is an instance of dbtCloudClient client . cloud . deactivate_user_license ( account_id , permission_id , payload ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc deactivate-user-license --permission_id = 1 --payload = '{\"license_type\": \"developer\", \"id\": 1, \"user_id\": 1, \"account_id\": 1, \"state\": 2, \"groups\": [{\"account_id\": 1, \"name\": \"test-group-with-sso-mappings\", \"id\": 1, \"state\": 1, \"assign_by_default\": false, \"sso_mapping_groups\": [\"something\"], \"group_permissions\": [{\"account_id\": 1, \"group_id\": 1, \"project_id\": null, \"all_projects\": true, \"permission_set\": \"analyst\", \"permission_level\": null, \"id\": \"{{group_permission_id}}\", \"state\": 1}]}], \"permission_statements\": [{\"permission\": \"invitations_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"license_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"projects_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"environments_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"jobs_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"runs_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"metadata_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"custom_environment_variables_read\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"projects_develop\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"credentials_write\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"develop_access\", \"target_resource\": null, \"all_resources\": true}, {\"permission\": \"custom_environment_variables_write\", \"target_resource\": null, \"all_resources\": true}]}' payload = { 'license_type' : 'developer' , 'id' : 1 , 'user_id' : 1 , 'account_id' : 1 , 'state' : 2 , 'groups' : [ { 'account_id' : 1 , 'name' : 'test-group-with-sso-mappings' , 'id' : 1 , 'state' : 1 , 'assign_by_default' : False , 'sso_mapping_groups' : [ 'something' ], 'group_permissions' : [ { 'account_id' : 1 , 'group_id' : 1 , 'project_id' : None , 'all_projects' : True , 'permission_set' : 'analyst' , 'permission_level' : None , 'id' : '{{group_permission_id}}' , 'state' : 1 } ] } ], 'permission_statements' : [ { 'permission' : 'invitations_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'license_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'projects_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'environments_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'jobs_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'runs_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'metadata_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'custom_environment_variables_read' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'projects_develop' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'credentials_write' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'develop_access' , 'target_resource' : None , 'all_resources' : True }, { 'permission' : 'custom_environment_variables_write' , 'target_resource' : None , 'all_resources' : True } ] }","title":"deactivate_user_license"},{"location":"guide/cloud/#get_user","text":"List invited users in an account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required user_id int Numeric ID of the user to retrieve required Source code in dbtc/client/admin.py 811 812 813 814 815 816 817 818 819 @v2 def get_user ( self , account_id : int , user_id : int ) -> Dict : \"\"\"List invited users in an account. Args: account_id (int): Numeric ID of the account to retrieve user_id (int): Numeric ID of the user to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /users/ { user_id } /\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . get_user ( account_id , user_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc get_user --user-id = 1","title":"get_user"},{"location":"guide/cloud/#list_invited_users","text":"List invited users in an account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required Source code in dbtc/client/admin.py 1023 1024 1025 1026 1027 1028 1029 1030 @v2 def list_invited_users ( self , account_id : int ) -> Dict : \"\"\"List invited users in an account. Args: account_id (int): Numeric ID of the account to retrieve \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /invites/\" ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_invited_users ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-invited-users","title":"list_invited_users"},{"location":"guide/cloud/#list_users","text":"List users in an account. Parameters: Name Type Description Default account_id int Numeric ID of the account to retrieve required state int 1 = active, 2 = deleted None limit int The limit to apply when listing runs. Use with offset to paginate results. None offset int The offset to apply when listing runs. Use with limit to paginate results. None order_by str Field to order the result by. Use - to indicate reverse order. 'email' Source code in dbtc/client/admin.py 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 @v3 def list_users ( self , account_id : int , * , state : int = None , limit : int = None , offset : int = None , order_by : str = \"email\" , ) -> Dict : \"\"\"List users in an account. Args: account_id (int): Numeric ID of the account to retrieve state (int, optional): 1 = active, 2 = deleted limit (int, optional): The limit to apply when listing runs. Use with offset to paginate results. offset (int, optional): The offset to apply when listing runs. Use with limit to paginate results. order_by (str, optional): Field to order the result by. Use - to indicate reverse order. \"\"\" return self . _simple_request ( f \"accounts/ { account_id } /users/\" , params = { \"limit\" : limit , \"offset\" : offset , \"order_by\" : order_by , \"state\" : state , }, ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . cloud . list_users ( account_id ) Assuming that DBT_CLOUD_ACCOUNT_ID environment variable has been set. dbtc list-users","title":"list_users"},{"location":"guide/intro/","text":"Introduction \u00b6 Python \u00b6 Class \u00b6 The dbtCloudClient class is the main interface through which you will interact with dbt Cloud API endpoints. The class accepts three optional arguments: api_key service_token host An api_key can be used to access endpoints from any version of the dbt Cloud API (v2 or v3). The service_token can be used for either the dbt Cloud API or the Metadata API. If you have the proper permissions , you would only need to pass a service token. from dbtc import dbtCloudClient client = dbtCloudClient ( service_token = 'this-is-my-service-token' ) Alternatively, you can set the following environment variables in place of passing the arguments to the class: api_key --> DBT_CLOUD_API_KEY service_token --> DBT_CLOUD_SERVICE_TOKEN host --> DBT_CLOUD_HOST If you have set environment variables, and have the proper permissions, you'll be able to instantiate the dbtCloudClient class as follows: from dbtc import dbtCloudClient client = dbtCloudClient () Info The host argument is only necessary for customers on single-tenant instances Interfaces \u00b6 The dbtCloudClient class contains two properties: cloud - instance of the _AdminClient class, which contains methods to create, read, update, and delete dbt Cloud resources metadata - instance of the _MetadataClient class, which contains methods to retrieve metadata generated from a dbt Cloud job run cloud from dbtc import dbtCloudClient # Assuming we've set the `DBT_CLOUD_SERVICET_TOKEN` environment variable` client = dbtCloudClient () accounts = client . cloud . list_accounts () metadata from dbtc import dbtCloudClient client = dbtCloudClient () job_id = < xxx > run_id = < xxx > models = client . metadata . get_models ( job_id , run_id ) CLI \u00b6 This package also comes with a command-line utility, dbtc . All of the methods available through the cloud or metadata properties on the dbtCloudClient class are available through the command line as well. The command line interface also accepts additional environment variables: DBT_CLOUD_ACCOUNT_ID DBT_CLOUD_PROJECT_ID Setting these will reduce the amount of arguments you'll need to pass. dbtc get-project --account-id = 1 --project-id = 1 Or, if you've set the DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables. dbtc get-project","title":"Introduction"},{"location":"guide/intro/#introduction","text":"","title":"Introduction"},{"location":"guide/intro/#python","text":"","title":"Python"},{"location":"guide/intro/#class","text":"The dbtCloudClient class is the main interface through which you will interact with dbt Cloud API endpoints. The class accepts three optional arguments: api_key service_token host An api_key can be used to access endpoints from any version of the dbt Cloud API (v2 or v3). The service_token can be used for either the dbt Cloud API or the Metadata API. If you have the proper permissions , you would only need to pass a service token. from dbtc import dbtCloudClient client = dbtCloudClient ( service_token = 'this-is-my-service-token' ) Alternatively, you can set the following environment variables in place of passing the arguments to the class: api_key --> DBT_CLOUD_API_KEY service_token --> DBT_CLOUD_SERVICE_TOKEN host --> DBT_CLOUD_HOST If you have set environment variables, and have the proper permissions, you'll be able to instantiate the dbtCloudClient class as follows: from dbtc import dbtCloudClient client = dbtCloudClient () Info The host argument is only necessary for customers on single-tenant instances","title":"Class"},{"location":"guide/intro/#interfaces","text":"The dbtCloudClient class contains two properties: cloud - instance of the _AdminClient class, which contains methods to create, read, update, and delete dbt Cloud resources metadata - instance of the _MetadataClient class, which contains methods to retrieve metadata generated from a dbt Cloud job run cloud from dbtc import dbtCloudClient # Assuming we've set the `DBT_CLOUD_SERVICET_TOKEN` environment variable` client = dbtCloudClient () accounts = client . cloud . list_accounts () metadata from dbtc import dbtCloudClient client = dbtCloudClient () job_id = < xxx > run_id = < xxx > models = client . metadata . get_models ( job_id , run_id )","title":"Interfaces"},{"location":"guide/intro/#cli","text":"This package also comes with a command-line utility, dbtc . All of the methods available through the cloud or metadata properties on the dbtCloudClient class are available through the command line as well. The command line interface also accepts additional environment variables: DBT_CLOUD_ACCOUNT_ID DBT_CLOUD_PROJECT_ID Setting these will reduce the amount of arguments you'll need to pass. dbtc get-project --account-id = 1 --project-id = 1 Or, if you've set the DBT_CLOUD_ACCOUNT_ID and DBT_CLOUD_PROJECT_ID environment variables. dbtc get-project","title":"CLI"},{"location":"guide/metadata/","text":"Metadata \u00b6 The metadata property on the dbtCloudClient class contains methods that allow a user to retrieve metadata which pertains to the accuracy, recency, configuration, and structure of the views and tables in the warehouse. The Metadata API is a GraphQL API. Normally, this would require a user to write a GraphQL query as part of the required payload. However, this package provides a convenient interface that allows a user to write the GraphQL query in a more pythonic way. There are two options: Simply provide the minimal set of arguments to the functions below and get every field in the desired schema, including those that are nested. An example is below for the models schema: from dbtc import dbtCloudClient # Assuming DBT_CLOUD_SERVICE_TOKEN is set as an environment variable client = dbtCloudClient () job_id = 1 models = client . metadata . get_models ( job_id ) If you don't want or need all of the fields from a particular schema, use the optional fields argument to limit the amount of data that's returned. This argument accepts a list of strings where the strings are names of fields within the schema. Additionally, you can ask for nested fields using dot notation. from dbtc import dbtCloudClient # Assuming DBT_CLOUD_SERVICE_TOKEN is set as an environment variable client = dbtCloudClient () job_id = 1 fields = [ 'uniqueId' , 'runId' , 'projectId' , 'environmentId' , 'alias' , 'description' , 'parentsSources.name' , 'parentsSources.criteria.warnAfter.period' , 'parentsSources.criteria.warnAfter.count' , ] models = client . metadata . get_models ( job_id , fields = fields ) The video below provides some more detail. get_exposure \u00b6 The exposure object allows you to query information about a particular exposure. You can learn more about exposures here . Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this expsoure was generated for required name str The name of this particular exposure required run_id int The run ID of the run in dbt Cloud that this exposure was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def get_exposure ( self , job_id : int , name : str , * , run_id : int = None , fields : List [ str ] = None ) -> Dict : \"\"\" The exposure object allows you to query information about a particular exposure. You can learn more about exposures [here]( https://docs.getdbt.com/docs/building-a-dbt-project/exposures). Args: job_id (int): The unique ID of the job in dbt Cloud that this expsoure was generated for name (str): The name of this particular exposure run_id (int, optional): The run ID of the run in dbt Cloud that this exposure was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"exposure\" , { \"job_id\" : job_id , \"name\" : name , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_exposure ( job_id ) dbtc get-exposure --job-id = 12345 get_exposures \u00b6 The exposures object allows you to query information about all exposures in a given job. You can learn more about exposures here . Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this exposure was generated for required run_id int The run ID of the run in dbt Cloud that this exposure was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 def get_exposures ( self , job_id : int , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The exposures object allows you to query information about all exposures in a given job. You can learn more about exposures [here]( https://docs.getdbt.com/docs/building-a-dbt-project/exposures). Args: job_id (int): The unique ID of the job in dbt Cloud that this exposure was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this exposure was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"exposures\" , { \"job_id\" : job_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_exposures ( job_id ) dbtc get-exposures --job-id = 12345 get_macro \u00b6 The macro object allows you to query information about a particular macro in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this macro was generated for required unique_id str The unique ID of this particular macro required run_id int The run ID of the run in dbt Cloud that this macro was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def get_macro ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The macro object allows you to query information about a particular macro in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this macro was generated for unique_id (str): The unique ID of this particular macro run_id (int, optional): The run ID of the run in dbt Cloud that this macro was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"macro\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_macro ( job_id ) dbtc get-macro --job-id = 12345 get_macros \u00b6 The macros object allows you to query information about all macros in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this macro was generated for required run_id int The run ID of the run in dbt Cloud that this macro was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def get_macros ( self , job_id : int , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The macros object allows you to query information about all macros in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this macro was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this macro was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"macros\" , { \"job_id\" : job_id , \"run_id\" : run_id }, fields ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_macros ( job_id ) dbtc get-macros --job-id = 12345 get_metric \u00b6 The metric object allows you to query information about metrics . Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this metric was generated for required unique_id str The unique ID of this particular metric required run_id int The run ID of the run in dbt Cloud that this metric was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 def get_metric ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The metric object allows you to query information about [metrics]( https://docs.getdbt.com/docs/building-a-dbt-project/metrics). Args: job_id (int): The unique ID of the job in dbt Cloud that this metric was generated for unique_id (str): The unique ID of this particular metric run_id (int, optional): The run ID of the run in dbt Cloud that this metric was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"metric\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_metric ( job_id ) dbtc get-metric --job-id = 12345 get_metrics \u00b6 The metrics object allows you to query information about metrics . Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this metric was generated for required run_id int The run ID of the run in dbt Cloud that this metric was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 def get_metrics ( self , job_id : int , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The metrics object allows you to query information about [metrics]( https://docs.getdbt.com/docs/building-a-dbt-project/metrics). Args: job_id (int): The unique ID of the job in dbt Cloud that this metric was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this metric was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"metrics\" , { \"job_id\" : job_id , \"run_id\" : run_id }, fields ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_metrics ( job_id ) dbtc get-metrics --job-id = 12345 get_model \u00b6 The model object allows you to query information about a particular model in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this model was generated for required unique_id str The unique ID of this particular model required run_id int The run ID of the run in dbt Cloud that this model was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 def get_model ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The model object allows you to query information about a particular model in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this model was generated for unique_id (str): The unique ID of this particular model run_id (int, optional): The run ID of the run in dbt Cloud that this model was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"model\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_model ( job_id ) dbtc get-model --job-id = 12345 get_model_by_environment \u00b6 The model by environment object allows you to query information about a particular model based on environment_id Warning This feature is currently in beta and subject to change. Parameters: Name Type Description Default environment_id int The environment_id for this model required unique_id str The unique ID of this model required last_run_count int Number of last run results where this model was built to return (max of 10). Defaults to 10. 10 with_catalog bool If true, return only runs that have catalog information for this model. Defaults to False. False fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 def get_model_by_environment ( self , environment_id : int , unique_id : str , last_run_count : int = 10 , with_catalog : bool = False , fields : List [ str ] = None , ): \"\"\"The model by environment object allows you to query information about a particular model based on environment_id !!! warning This feature is currently in beta and subject to change. Args: environment_id (int): The environment_id for this model unique_id (str): The unique ID of this model last_run_count (int, optional): Number of last run results where this model was built to return (max of 10). Defaults to 10. with_catalog (bool, optional): If true, return only runs that have catalog information for this model. Defaults to False. fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"model_by_environment\" , { \"environment_id\" : environment_id , \"unique_id\" : unique_id , \"last_run_count\" : last_run_count , \"with_catalog\" : with_catalog , }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_model_by_environment ( environment_id , unique_id ) dbtc get-model-by-environment --environment-id = 12345 --unique-id = models.tpch.order_items get_models \u00b6 The models object allows you to query information about all models in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this model was generated for required run_id int The run ID of the run in dbt Cloud that this model was generated for None database str The database where this table/view lives None schema str The schema where this table/view lives None identifier str The identifier of this table/view None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 def get_models ( self , job_id : int , * , database : str = None , schema : str = None , identifier : str = None , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The models object allows you to query information about all models in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this model was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this model was generated for database (str, optional): The database where this table/view lives schema (str, optional): The schema where this table/view lives identifier (str, optional): The identifier of this table/view fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"models\" , { \"job_id\" : job_id , \"database\" : database , \"schema\" : schema , \"identifier\" : identifier , \"run_id\" : run_id , }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_models ( job_id ) dbtc get-models --job-id = 12345 get_seed \u00b6 The seed object allows you to query information about a particular seed in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this seed was generated for required unique_id str The unique ID of this particular seed required run_id int The run ID of the run in dbt Cloud that this seed was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 def get_seed ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The seed object allows you to query information about a particular seed in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this seed was generated for unique_id (str): The unique ID of this particular seed run_id (int, optional): The run ID of the run in dbt Cloud that this seed was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"seed\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_seed ( job_id ) dbtc get-seed --job-id = 12345 get_seeds \u00b6 The seeds object allows you to query information about a all seeds in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this seed was generated for required run_id int The run ID of the run in dbt Cloud that this seed was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 def get_seeds ( self , job_id : int , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The seeds object allows you to query information about a all seeds in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this seed was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this seed was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"seeds\" , { \"job_id\" : job_id , \"run_id\" : run_id }, fields ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_seeds ( job_id ) dbtc get-seeds --job-id = 12345 get_snapshot \u00b6 The snapshot object allows you to query information about a particular snapshot. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this snapshot was generated for required unique_id str The unique ID of this particular snapshot required run_id int The run ID of the run in dbt Cloud that this snapshot was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 def get_snapshot ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The snapshot object allows you to query information about a particular snapshot. Args: job_id (int): The unique ID of the job in dbt Cloud that this snapshot was generated for unique_id (str): The unique ID of this particular snapshot run_id (int, optional): The run ID of the run in dbt Cloud that this snapshot was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"snapshot\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_snapshot ( job_id ) dbtc get-snapshot --job-id = 12345 get_snapshots \u00b6 The snapshots object allows you to query information about all snapshots in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this snapshot was generated for required run_id int The run ID of the run in dbt Cloud that this snapshot was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 def get_snapshots ( self , job_id : int , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The snapshots object allows you to query information about all snapshots in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this snapshot was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this snapshot was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"snapshots\" , { \"job_id\" : job_id , \"run_id\" : run_id , }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_snapshots ( job_id ) dbtc get-snapshots --job-id = 12345 get_source \u00b6 The source object allows you to query information about a particular source in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this source was generated for required unique_id str The unique ID of this particular source required run_id int The run ID of the run in dbt Cloud that this source was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 def get_source ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The source object allows you to query information about a particular source in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this source was generated for unique_id (str): The unique ID of this particular source run_id (int, optional): The run ID of the run in dbt Cloud that this source was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"source\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_source ( job_id ) dbtc get-source --job-id = 12345 get_sources \u00b6 The snapshots object allows you to query information about all snapshots in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this source was generated for required run_id int The run ID of the run in dbt Cloud that this source was generated for None database str The database where this table/view lives None schema str The schema where this table/view lives None identifier str The identifier of this table/view None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 def get_sources ( self , job_id : int , * , database : str = None , schema : str = None , identifier : str = None , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The snapshots object allows you to query information about all snapshots in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this source was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this source was generated for database (str, optional): The database where this table/view lives schema (str, optional): The schema where this table/view lives identifier (str, optional): The identifier of this table/view fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"sources\" , { \"job_id\" : job_id , \"database\" : database , \"schema\" : schema , \"identifier\" : identifier , \"run_id\" : run_id , }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_sources ( job_id ) dbtc get-sources --job-id = 12345 get_test \u00b6 The test object allows you to query information about a particular test. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this test was generated for required unique_id str The unique ID of this particular test required run_id int The run ID of the run in dbt Cloud that this test was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 def get_test ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The test object allows you to query information about a particular test. Args: job_id (int): The unique ID of the job in dbt Cloud that this test was generated for unique_id (str): The unique ID of this particular test run_id (int, optional): The run ID of the run in dbt Cloud that this test was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"test\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_test ( job_id ) dbtc get-test --job-id = 12345 get_tests \u00b6 The tests object allows you to query information about all tests in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this test was generated for required run_id int The run ID of the run in dbt Cloud that this test was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 def get_tests ( self , job_id : int , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The tests object allows you to query information about all tests in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this test was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this test was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"tests\" , { \"job_id\" : job_id , \"run_id\" : run_id , }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_tests ( job_id ) dbtc get-tests --job-id = 12345 query \u00b6 Source code in dbtc/client/metadata.py 78 79 80 81 82 83 def query ( self , query : str , variables : Dict = None ): payload : Dict [ str , Any ] = { 'query' : query } if variables : payload . update ({ 'variables' : variables }) response = self . session . post ( self . full_url (), json = payload ) return response . json () Examples: Python Assuming that client is an instance of dbtCloudClient query = '{models(jobId: 1) {uniqueId} }' client . metadata . query ( query )","title":"Metadata"},{"location":"guide/metadata/#metadata","text":"The metadata property on the dbtCloudClient class contains methods that allow a user to retrieve metadata which pertains to the accuracy, recency, configuration, and structure of the views and tables in the warehouse. The Metadata API is a GraphQL API. Normally, this would require a user to write a GraphQL query as part of the required payload. However, this package provides a convenient interface that allows a user to write the GraphQL query in a more pythonic way. There are two options: Simply provide the minimal set of arguments to the functions below and get every field in the desired schema, including those that are nested. An example is below for the models schema: from dbtc import dbtCloudClient # Assuming DBT_CLOUD_SERVICE_TOKEN is set as an environment variable client = dbtCloudClient () job_id = 1 models = client . metadata . get_models ( job_id ) If you don't want or need all of the fields from a particular schema, use the optional fields argument to limit the amount of data that's returned. This argument accepts a list of strings where the strings are names of fields within the schema. Additionally, you can ask for nested fields using dot notation. from dbtc import dbtCloudClient # Assuming DBT_CLOUD_SERVICE_TOKEN is set as an environment variable client = dbtCloudClient () job_id = 1 fields = [ 'uniqueId' , 'runId' , 'projectId' , 'environmentId' , 'alias' , 'description' , 'parentsSources.name' , 'parentsSources.criteria.warnAfter.period' , 'parentsSources.criteria.warnAfter.count' , ] models = client . metadata . get_models ( job_id , fields = fields ) The video below provides some more detail.","title":"Metadata"},{"location":"guide/metadata/#get_exposure","text":"The exposure object allows you to query information about a particular exposure. You can learn more about exposures here . Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this expsoure was generated for required name str The name of this particular exposure required run_id int The run ID of the run in dbt Cloud that this exposure was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def get_exposure ( self , job_id : int , name : str , * , run_id : int = None , fields : List [ str ] = None ) -> Dict : \"\"\" The exposure object allows you to query information about a particular exposure. You can learn more about exposures [here]( https://docs.getdbt.com/docs/building-a-dbt-project/exposures). Args: job_id (int): The unique ID of the job in dbt Cloud that this expsoure was generated for name (str): The name of this particular exposure run_id (int, optional): The run ID of the run in dbt Cloud that this exposure was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"exposure\" , { \"job_id\" : job_id , \"name\" : name , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_exposure ( job_id ) dbtc get-exposure --job-id = 12345","title":"get_exposure"},{"location":"guide/metadata/#get_exposures","text":"The exposures object allows you to query information about all exposures in a given job. You can learn more about exposures here . Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this exposure was generated for required run_id int The run ID of the run in dbt Cloud that this exposure was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 def get_exposures ( self , job_id : int , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The exposures object allows you to query information about all exposures in a given job. You can learn more about exposures [here]( https://docs.getdbt.com/docs/building-a-dbt-project/exposures). Args: job_id (int): The unique ID of the job in dbt Cloud that this exposure was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this exposure was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"exposures\" , { \"job_id\" : job_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_exposures ( job_id ) dbtc get-exposures --job-id = 12345","title":"get_exposures"},{"location":"guide/metadata/#get_macro","text":"The macro object allows you to query information about a particular macro in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this macro was generated for required unique_id str The unique ID of this particular macro required run_id int The run ID of the run in dbt Cloud that this macro was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def get_macro ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The macro object allows you to query information about a particular macro in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this macro was generated for unique_id (str): The unique ID of this particular macro run_id (int, optional): The run ID of the run in dbt Cloud that this macro was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"macro\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_macro ( job_id ) dbtc get-macro --job-id = 12345","title":"get_macro"},{"location":"guide/metadata/#get_macros","text":"The macros object allows you to query information about all macros in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this macro was generated for required run_id int The run ID of the run in dbt Cloud that this macro was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def get_macros ( self , job_id : int , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The macros object allows you to query information about all macros in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this macro was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this macro was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"macros\" , { \"job_id\" : job_id , \"run_id\" : run_id }, fields ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_macros ( job_id ) dbtc get-macros --job-id = 12345","title":"get_macros"},{"location":"guide/metadata/#get_metric","text":"The metric object allows you to query information about metrics . Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this metric was generated for required unique_id str The unique ID of this particular metric required run_id int The run ID of the run in dbt Cloud that this metric was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 def get_metric ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The metric object allows you to query information about [metrics]( https://docs.getdbt.com/docs/building-a-dbt-project/metrics). Args: job_id (int): The unique ID of the job in dbt Cloud that this metric was generated for unique_id (str): The unique ID of this particular metric run_id (int, optional): The run ID of the run in dbt Cloud that this metric was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"metric\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_metric ( job_id ) dbtc get-metric --job-id = 12345","title":"get_metric"},{"location":"guide/metadata/#get_metrics","text":"The metrics object allows you to query information about metrics . Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this metric was generated for required run_id int The run ID of the run in dbt Cloud that this metric was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 def get_metrics ( self , job_id : int , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The metrics object allows you to query information about [metrics]( https://docs.getdbt.com/docs/building-a-dbt-project/metrics). Args: job_id (int): The unique ID of the job in dbt Cloud that this metric was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this metric was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"metrics\" , { \"job_id\" : job_id , \"run_id\" : run_id }, fields ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_metrics ( job_id ) dbtc get-metrics --job-id = 12345","title":"get_metrics"},{"location":"guide/metadata/#get_model","text":"The model object allows you to query information about a particular model in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this model was generated for required unique_id str The unique ID of this particular model required run_id int The run ID of the run in dbt Cloud that this model was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 def get_model ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The model object allows you to query information about a particular model in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this model was generated for unique_id (str): The unique ID of this particular model run_id (int, optional): The run ID of the run in dbt Cloud that this model was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"model\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_model ( job_id ) dbtc get-model --job-id = 12345","title":"get_model"},{"location":"guide/metadata/#get_model_by_environment","text":"The model by environment object allows you to query information about a particular model based on environment_id Warning This feature is currently in beta and subject to change. Parameters: Name Type Description Default environment_id int The environment_id for this model required unique_id str The unique ID of this model required last_run_count int Number of last run results where this model was built to return (max of 10). Defaults to 10. 10 with_catalog bool If true, return only runs that have catalog information for this model. Defaults to False. False fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 def get_model_by_environment ( self , environment_id : int , unique_id : str , last_run_count : int = 10 , with_catalog : bool = False , fields : List [ str ] = None , ): \"\"\"The model by environment object allows you to query information about a particular model based on environment_id !!! warning This feature is currently in beta and subject to change. Args: environment_id (int): The environment_id for this model unique_id (str): The unique ID of this model last_run_count (int, optional): Number of last run results where this model was built to return (max of 10). Defaults to 10. with_catalog (bool, optional): If true, return only runs that have catalog information for this model. Defaults to False. fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"model_by_environment\" , { \"environment_id\" : environment_id , \"unique_id\" : unique_id , \"last_run_count\" : last_run_count , \"with_catalog\" : with_catalog , }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_model_by_environment ( environment_id , unique_id ) dbtc get-model-by-environment --environment-id = 12345 --unique-id = models.tpch.order_items","title":"get_model_by_environment"},{"location":"guide/metadata/#get_models","text":"The models object allows you to query information about all models in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this model was generated for required run_id int The run ID of the run in dbt Cloud that this model was generated for None database str The database where this table/view lives None schema str The schema where this table/view lives None identifier str The identifier of this table/view None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 def get_models ( self , job_id : int , * , database : str = None , schema : str = None , identifier : str = None , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The models object allows you to query information about all models in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this model was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this model was generated for database (str, optional): The database where this table/view lives schema (str, optional): The schema where this table/view lives identifier (str, optional): The identifier of this table/view fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"models\" , { \"job_id\" : job_id , \"database\" : database , \"schema\" : schema , \"identifier\" : identifier , \"run_id\" : run_id , }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_models ( job_id ) dbtc get-models --job-id = 12345","title":"get_models"},{"location":"guide/metadata/#get_seed","text":"The seed object allows you to query information about a particular seed in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this seed was generated for required unique_id str The unique ID of this particular seed required run_id int The run ID of the run in dbt Cloud that this seed was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 def get_seed ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The seed object allows you to query information about a particular seed in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this seed was generated for unique_id (str): The unique ID of this particular seed run_id (int, optional): The run ID of the run in dbt Cloud that this seed was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"seed\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_seed ( job_id ) dbtc get-seed --job-id = 12345","title":"get_seed"},{"location":"guide/metadata/#get_seeds","text":"The seeds object allows you to query information about a all seeds in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this seed was generated for required run_id int The run ID of the run in dbt Cloud that this seed was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 def get_seeds ( self , job_id : int , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The seeds object allows you to query information about a all seeds in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this seed was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this seed was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"seeds\" , { \"job_id\" : job_id , \"run_id\" : run_id }, fields ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_seeds ( job_id ) dbtc get-seeds --job-id = 12345","title":"get_seeds"},{"location":"guide/metadata/#get_snapshot","text":"The snapshot object allows you to query information about a particular snapshot. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this snapshot was generated for required unique_id str The unique ID of this particular snapshot required run_id int The run ID of the run in dbt Cloud that this snapshot was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 def get_snapshot ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The snapshot object allows you to query information about a particular snapshot. Args: job_id (int): The unique ID of the job in dbt Cloud that this snapshot was generated for unique_id (str): The unique ID of this particular snapshot run_id (int, optional): The run ID of the run in dbt Cloud that this snapshot was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"snapshot\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_snapshot ( job_id ) dbtc get-snapshot --job-id = 12345","title":"get_snapshot"},{"location":"guide/metadata/#get_snapshots","text":"The snapshots object allows you to query information about all snapshots in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this snapshot was generated for required run_id int The run ID of the run in dbt Cloud that this snapshot was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 def get_snapshots ( self , job_id : int , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The snapshots object allows you to query information about all snapshots in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this snapshot was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this snapshot was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"snapshots\" , { \"job_id\" : job_id , \"run_id\" : run_id , }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_snapshots ( job_id ) dbtc get-snapshots --job-id = 12345","title":"get_snapshots"},{"location":"guide/metadata/#get_source","text":"The source object allows you to query information about a particular source in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this source was generated for required unique_id str The unique ID of this particular source required run_id int The run ID of the run in dbt Cloud that this source was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 def get_source ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The source object allows you to query information about a particular source in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this source was generated for unique_id (str): The unique ID of this particular source run_id (int, optional): The run ID of the run in dbt Cloud that this source was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"source\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_source ( job_id ) dbtc get-source --job-id = 12345","title":"get_source"},{"location":"guide/metadata/#get_sources","text":"The snapshots object allows you to query information about all snapshots in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this source was generated for required run_id int The run ID of the run in dbt Cloud that this source was generated for None database str The database where this table/view lives None schema str The schema where this table/view lives None identifier str The identifier of this table/view None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 def get_sources ( self , job_id : int , * , database : str = None , schema : str = None , identifier : str = None , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The snapshots object allows you to query information about all snapshots in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this source was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this source was generated for database (str, optional): The database where this table/view lives schema (str, optional): The schema where this table/view lives identifier (str, optional): The identifier of this table/view fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"sources\" , { \"job_id\" : job_id , \"database\" : database , \"schema\" : schema , \"identifier\" : identifier , \"run_id\" : run_id , }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_sources ( job_id ) dbtc get-sources --job-id = 12345","title":"get_sources"},{"location":"guide/metadata/#get_test","text":"The test object allows you to query information about a particular test. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this test was generated for required unique_id str The unique ID of this particular test required run_id int The run ID of the run in dbt Cloud that this test was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 def get_test ( self , job_id : int , unique_id : str , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The test object allows you to query information about a particular test. Args: job_id (int): The unique ID of the job in dbt Cloud that this test was generated for unique_id (str): The unique ID of this particular test run_id (int, optional): The run ID of the run in dbt Cloud that this test was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"test\" , { \"job_id\" : job_id , \"unique_id\" : unique_id , \"run_id\" : run_id }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_test ( job_id ) dbtc get-test --job-id = 12345","title":"get_test"},{"location":"guide/metadata/#get_tests","text":"The tests object allows you to query information about all tests in a given job. Parameters: Name Type Description Default job_id int The unique ID of the job in dbt Cloud that this test was generated for required run_id int The run ID of the run in dbt Cloud that this test was generated for None fields list The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a . (e.g. parentsSources.criteria.warnAfter.errorAfter ) None Note If you do not include a run_id, it will default to the most recent run of the specified job. Source code in dbtc/client/metadata.py 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 def get_tests ( self , job_id : int , * , run_id : int = None , fields : List [ str ] = None , ) -> Dict : \"\"\" The tests object allows you to query information about all tests in a given job. Args: job_id (int): The unique ID of the job in dbt Cloud that this test was generated for run_id (int, optional): The run ID of the run in dbt Cloud that this test was generated for fields (list, optional): The list of fields to include in the response. The field can either be in snake_case or camelCase (e.g. run_id and runId will be evaluated similarly). Nested fields can be accessed with a `.` (e.g. `parentsSources.criteria.warnAfter.errorAfter`) !!! note If you do not include a run_id, it will default to the most recent run of the specified job. \"\"\" return self . _make_request ( \"tests\" , { \"job_id\" : job_id , \"run_id\" : run_id , }, fields , ) Examples: Python CLI Assuming that client is an instance of dbtCloudClient client . metadata . get_tests ( job_id ) dbtc get-tests --job-id = 12345","title":"get_tests"},{"location":"guide/metadata/#query","text":"Source code in dbtc/client/metadata.py 78 79 80 81 82 83 def query ( self , query : str , variables : Dict = None ): payload : Dict [ str , Any ] = { 'query' : query } if variables : payload . update ({ 'variables' : variables }) response = self . session . post ( self . full_url (), json = payload ) return response . json () Examples: Python Assuming that client is an instance of dbtCloudClient query = '{models(jobId: 1) {uniqueId} }' client . metadata . query ( query )","title":"query"},{"location":"guide/restart_from_failure/","text":"Restart From Failure \u00b6 Thank You! All credit, for both the words below as well as the code that enables this functionality, should be directed to @matt-winkler . The initial work for this started with his incredible gist . Intro \u00b6 Summary \u00b6 This library offers a convenient interface to restart your jobs from the point of failure. At a high level, it will do the following: Inspect the run_results.json artifacts from the previous run to understand which nodes succeeded / failed Any steps that succeeded on the previous run are skipped Any steps that were skipped on the previous run (e.g. because they followed a failed / errored step) are repeated as-is Background \u00b6 dbt Cloud offers users the ability to run and monitor their data pipelines remotely via API endpoints. Each pipeline run produces metadata artifacts that provide rich information on the models run, success/failure status for each, timing, and more. Why Pipelines Might Fail \u00b6 There are a few scenarios in which the need to restart a job from failure occurs in practice: Database permission errors Code merged to production isn't properly tested (a related-but-separate problem with a distinct set of solutions) Data content changes (e.g. due to a problem in a raw data feed that wasn't historically present) Timeouts Despite our best intentions, the above can and will happen. How can we Respond to Failures \u00b6 When responding to failures in a particular area of the DAG, it's often expedient to avoid reprocessing data that's already been run, in particular for maintaining trust with stakeholders when pipelines are \"behind.\" In order to achieve this most efficiently and reliably, the solution should be programmatic, and contained with dbt's capabilities, versus expecting users to: Inspect the results of a run to identify the (potentially multiple) roots of failure points (e.g. the earliest failed dbt models or sources for a given run). Modify a job command (or create a new job) with the failure points from 1 and including the + syntax to run it's children. Ensure the job isn't triggered on an ongoing basis or otherwise put into the orchestration flow unintentionally. Examples \u00b6 Python CLI Github Action Response from dbtc import dbtCloudClient # Assumes I have DBT_CLOUD_SERVICE_TOKEN as an environment variable client = dbtCloudClient () account_id = 1 job_id = 1 payload = { 'cause' : 'Restarting from failure' } run = client . cloud . trigger_job_from_failure ( account_id , job_id , payload ) Assuming that DBT_CLOUD_SERVICE_TOKEN environment variable has been set. dbtc trigger-job-from-failure \\ --account-id 1 \\ --job-id 1 \\ --payload '{\"cause\": \"Restarting from failure\"}' Required : You'll need to create a secret in your repo called DBT_CLOUD_SERVICE_TOKEN . The token can be obtained from dbt Cloud name : Restart from Failure on : workflow_dispatch : jobs : restart : runs-on : ubuntu-latest env : DBT_CLOUD_SERVICE_TOKEN : ${{ secrets.DBT_CLOUD_SERVICE_TOKEN }} DBT_CLOUD_ACCOUNT_ID : 1 JOB_ID : 1 # Optional if statement to gate this to a particular user or users if : github.actor == 'dpguthrie' steps : - uses : actions/checkout@v2 - uses : actions/setup-python@v2 with : python-version : \"3.9.x\" - name : Restart Job from Failure run : | pip install dbtc==0.3.3 dbtc trigger-job-from-failure \\ --job-id=$JOB_ID \\ --payload='{\"cause\": \"Restarting job from failure\"}' \\ --no-should-poll \\ --restart-from-failure { 's tatus ' : { 'code' : 200 , 'is_success' : True , 'user_message' : 'Success!' , 'developer_message' : '' }, 'da ta ' : { 'id' : 78614274 , ' tr igger_id' : 79329387 , 'accou nt _id' : 1 , 'e n viro n me nt _id' : 1 , 'projec t _id' : 1 , 'job_de f i n i t io n _id' : 1 , 's tatus ' : 1 , 'db t _versio n ' : ' 1.2.0- la test ' , 'gi t _bra n ch' : No ne , 'gi t _sha' : No ne , 's tatus _message' : No ne , 'ow ner _ t hread_id' : No ne , 'execu te d_by_ t hread_id' : No ne , 'de ferr i n g_ru n _id' : No ne , 'ar t i fa c ts _saved' : False , 'ar t i fa c t _s 3 _pa t h' : No ne , 'has_docs_ge nerate d' : False , 'has_sources_ge nerate d' : False , ' n o t i f ica t io ns _se nt ' : False , 'blocked_by' : [], 'scribe_e na bled' : True , 'crea te d_a t ' : ' 2022-08-31 02 : 18 : 57.855152+00 : 00 ' , 'upda te d_a t ' : ' 2022-08-31 02 : 18 : 57.855169+00 : 00 ' , 'dequeued_a t ' : No ne , 's tarte d_a t ' : No ne , ' f i n ished_a t ' : No ne , 'las t _checked_a t ' : No ne , 'las t _hear t bea t _a t ' : No ne , 'should_s tart _a t ' : No ne , ' tr igger' : { 'id' : 79329387 , 'cause' : 'Jus t cause' , 'job_de f i n i t io n _id' : 1 , 'gi t _bra n ch' : No ne , 'gi t _sha' : No ne , 'azure_pull_reques t _id' : No ne , 'gi t hub_pull_reques t _id' : No ne , 'gi tla b_merge_reques t _id' : No ne , 'schema_override' : No ne , 'db t _versio n _override' : No ne , ' t hreads_override' : No ne , ' tar ge t _ na me_override' : No ne , 'ge nerate _docs_override' : No ne , ' t imeou t _seco n ds_override' : No ne , 's te ps_override' : [ 'db t ru n - s bad_model -- vars \\' { \"key\" : \"value\" } \\'' ], 'crea te d_a t ' : ' 2022-08-31 02 : 18 : 57.846515+00 : 00 ' , 'cause_huma n ized' : 'Jus t cause' , 'job' : No ne }, 'job' : { 'execu t io n ' : { ' t imeou t _seco n ds' : 0 }, 'ge nerate _docs' : False , 'ru n _ge nerate _sources' : False , 'id' : 1 , 'accou nt _id' : 1 , 'projec t _id' : 1 , 'e n viro n me nt _id' : 1 , ' na me' : 'Tes t 10 - Res tart wi t h Vars' , 'db t _versio n ' : No ne , 'crea te d_a t ' : ' 2022-08-29 T 14 : 02 : 57.378279 Z' , 'upda te d_a t ' : ' 2022-08-29 T 14 : 06 : 31.485879 Z' , 'execu te _s te ps' : [ 'db t ru n - s good_model bad_model -- vars \\' { \"key\" : \"value\" } \\'' ], 's tate ' : 1 , 'deac t iva te d' : False , 'ru n _ fa ilure_cou nt ' : 0 , 'de ferr i n g_job_de f i n i t io n _id' : No ne , 'li fe cycle_webhooks' : False , 'li fe cycle_webhooks_url' : No ne , ' tr iggers' : { 'gi t hub_webhook' : False , 'gi t _provider_webhook' : False , 'cus t om_bra n ch_o nl y' : False , 'schedule' : False }, 'se tt i n gs' : { ' t hreads' : 4 , ' tar ge t _ na me' : 'de fault ' }, 'schedule' : { 'cro n ' : ' 0 * * * 0 , 1 , 2 , 3 , 4 , 5 , 6 ' , 'da te ' : 'days_o f _week' , ' t ime' : 'every_hour' }, 'is_de ferra ble' : False }, 'e n viro n me nt ' : No ne , 'ru n _s te ps' : [], 's tatus _huma n ized' : 'Queued' , 'i n _progress' : True , 'is_comple te ' : False , 'is_success' : False , 'is_error' : False , 'is_ca n celled' : False , 'hre f ' : 'h tt ps : //cloud.getdbt.com/#/accounts/43786/projects/146089/runs/78614274/', 'dura t io n ' : ' 00 : 00 : 00 ' , 'queued_dura t io n ' : ' 00 : 00 : 00 ' , 'ru n _dura t io n ' : ' 00 : 00 : 00 ' , 'dura t io n _huma n ized' : ' 0 mi nutes ' , 'queued_dura t io n _huma n ized' : ' 0 mi nutes ' , 'ru n _dura t io n _huma n ized' : ' 0 mi nutes ' , 'crea te d_a t _huma n ized' : ' 0 mi nutes ago' , ' f i n ished_a t _huma n ized' : ' 0 mi nutes fr om n ow' , 'job_id' : 1 , 'is_ru nn i n g' : No ne } }","title":"Restart From Failure"},{"location":"guide/restart_from_failure/#restart-from-failure","text":"Thank You! All credit, for both the words below as well as the code that enables this functionality, should be directed to @matt-winkler . The initial work for this started with his incredible gist .","title":"Restart From Failure"},{"location":"guide/restart_from_failure/#intro","text":"","title":"Intro"},{"location":"guide/restart_from_failure/#summary","text":"This library offers a convenient interface to restart your jobs from the point of failure. At a high level, it will do the following: Inspect the run_results.json artifacts from the previous run to understand which nodes succeeded / failed Any steps that succeeded on the previous run are skipped Any steps that were skipped on the previous run (e.g. because they followed a failed / errored step) are repeated as-is","title":"Summary"},{"location":"guide/restart_from_failure/#background","text":"dbt Cloud offers users the ability to run and monitor their data pipelines remotely via API endpoints. Each pipeline run produces metadata artifacts that provide rich information on the models run, success/failure status for each, timing, and more.","title":"Background"},{"location":"guide/restart_from_failure/#why-pipelines-might-fail","text":"There are a few scenarios in which the need to restart a job from failure occurs in practice: Database permission errors Code merged to production isn't properly tested (a related-but-separate problem with a distinct set of solutions) Data content changes (e.g. due to a problem in a raw data feed that wasn't historically present) Timeouts Despite our best intentions, the above can and will happen.","title":"Why Pipelines Might Fail"},{"location":"guide/restart_from_failure/#how-can-we-respond-to-failures","text":"When responding to failures in a particular area of the DAG, it's often expedient to avoid reprocessing data that's already been run, in particular for maintaining trust with stakeholders when pipelines are \"behind.\" In order to achieve this most efficiently and reliably, the solution should be programmatic, and contained with dbt's capabilities, versus expecting users to: Inspect the results of a run to identify the (potentially multiple) roots of failure points (e.g. the earliest failed dbt models or sources for a given run). Modify a job command (or create a new job) with the failure points from 1 and including the + syntax to run it's children. Ensure the job isn't triggered on an ongoing basis or otherwise put into the orchestration flow unintentionally.","title":"How can we Respond to Failures"},{"location":"guide/restart_from_failure/#examples","text":"Python CLI Github Action Response from dbtc import dbtCloudClient # Assumes I have DBT_CLOUD_SERVICE_TOKEN as an environment variable client = dbtCloudClient () account_id = 1 job_id = 1 payload = { 'cause' : 'Restarting from failure' } run = client . cloud . trigger_job_from_failure ( account_id , job_id , payload ) Assuming that DBT_CLOUD_SERVICE_TOKEN environment variable has been set. dbtc trigger-job-from-failure \\ --account-id 1 \\ --job-id 1 \\ --payload '{\"cause\": \"Restarting from failure\"}' Required : You'll need to create a secret in your repo called DBT_CLOUD_SERVICE_TOKEN . The token can be obtained from dbt Cloud name : Restart from Failure on : workflow_dispatch : jobs : restart : runs-on : ubuntu-latest env : DBT_CLOUD_SERVICE_TOKEN : ${{ secrets.DBT_CLOUD_SERVICE_TOKEN }} DBT_CLOUD_ACCOUNT_ID : 1 JOB_ID : 1 # Optional if statement to gate this to a particular user or users if : github.actor == 'dpguthrie' steps : - uses : actions/checkout@v2 - uses : actions/setup-python@v2 with : python-version : \"3.9.x\" - name : Restart Job from Failure run : | pip install dbtc==0.3.3 dbtc trigger-job-from-failure \\ --job-id=$JOB_ID \\ --payload='{\"cause\": \"Restarting job from failure\"}' \\ --no-should-poll \\ --restart-from-failure { 's tatus ' : { 'code' : 200 , 'is_success' : True , 'user_message' : 'Success!' , 'developer_message' : '' }, 'da ta ' : { 'id' : 78614274 , ' tr igger_id' : 79329387 , 'accou nt _id' : 1 , 'e n viro n me nt _id' : 1 , 'projec t _id' : 1 , 'job_de f i n i t io n _id' : 1 , 's tatus ' : 1 , 'db t _versio n ' : ' 1.2.0- la test ' , 'gi t _bra n ch' : No ne , 'gi t _sha' : No ne , 's tatus _message' : No ne , 'ow ner _ t hread_id' : No ne , 'execu te d_by_ t hread_id' : No ne , 'de ferr i n g_ru n _id' : No ne , 'ar t i fa c ts _saved' : False , 'ar t i fa c t _s 3 _pa t h' : No ne , 'has_docs_ge nerate d' : False , 'has_sources_ge nerate d' : False , ' n o t i f ica t io ns _se nt ' : False , 'blocked_by' : [], 'scribe_e na bled' : True , 'crea te d_a t ' : ' 2022-08-31 02 : 18 : 57.855152+00 : 00 ' , 'upda te d_a t ' : ' 2022-08-31 02 : 18 : 57.855169+00 : 00 ' , 'dequeued_a t ' : No ne , 's tarte d_a t ' : No ne , ' f i n ished_a t ' : No ne , 'las t _checked_a t ' : No ne , 'las t _hear t bea t _a t ' : No ne , 'should_s tart _a t ' : No ne , ' tr igger' : { 'id' : 79329387 , 'cause' : 'Jus t cause' , 'job_de f i n i t io n _id' : 1 , 'gi t _bra n ch' : No ne , 'gi t _sha' : No ne , 'azure_pull_reques t _id' : No ne , 'gi t hub_pull_reques t _id' : No ne , 'gi tla b_merge_reques t _id' : No ne , 'schema_override' : No ne , 'db t _versio n _override' : No ne , ' t hreads_override' : No ne , ' tar ge t _ na me_override' : No ne , 'ge nerate _docs_override' : No ne , ' t imeou t _seco n ds_override' : No ne , 's te ps_override' : [ 'db t ru n - s bad_model -- vars \\' { \"key\" : \"value\" } \\'' ], 'crea te d_a t ' : ' 2022-08-31 02 : 18 : 57.846515+00 : 00 ' , 'cause_huma n ized' : 'Jus t cause' , 'job' : No ne }, 'job' : { 'execu t io n ' : { ' t imeou t _seco n ds' : 0 }, 'ge nerate _docs' : False , 'ru n _ge nerate _sources' : False , 'id' : 1 , 'accou nt _id' : 1 , 'projec t _id' : 1 , 'e n viro n me nt _id' : 1 , ' na me' : 'Tes t 10 - Res tart wi t h Vars' , 'db t _versio n ' : No ne , 'crea te d_a t ' : ' 2022-08-29 T 14 : 02 : 57.378279 Z' , 'upda te d_a t ' : ' 2022-08-29 T 14 : 06 : 31.485879 Z' , 'execu te _s te ps' : [ 'db t ru n - s good_model bad_model -- vars \\' { \"key\" : \"value\" } \\'' ], 's tate ' : 1 , 'deac t iva te d' : False , 'ru n _ fa ilure_cou nt ' : 0 , 'de ferr i n g_job_de f i n i t io n _id' : No ne , 'li fe cycle_webhooks' : False , 'li fe cycle_webhooks_url' : No ne , ' tr iggers' : { 'gi t hub_webhook' : False , 'gi t _provider_webhook' : False , 'cus t om_bra n ch_o nl y' : False , 'schedule' : False }, 'se tt i n gs' : { ' t hreads' : 4 , ' tar ge t _ na me' : 'de fault ' }, 'schedule' : { 'cro n ' : ' 0 * * * 0 , 1 , 2 , 3 , 4 , 5 , 6 ' , 'da te ' : 'days_o f _week' , ' t ime' : 'every_hour' }, 'is_de ferra ble' : False }, 'e n viro n me nt ' : No ne , 'ru n _s te ps' : [], 's tatus _huma n ized' : 'Queued' , 'i n _progress' : True , 'is_comple te ' : False , 'is_success' : False , 'is_error' : False , 'is_ca n celled' : False , 'hre f ' : 'h tt ps : //cloud.getdbt.com/#/accounts/43786/projects/146089/runs/78614274/', 'dura t io n ' : ' 00 : 00 : 00 ' , 'queued_dura t io n ' : ' 00 : 00 : 00 ' , 'ru n _dura t io n ' : ' 00 : 00 : 00 ' , 'dura t io n _huma n ized' : ' 0 mi nutes ' , 'queued_dura t io n _huma n ized' : ' 0 mi nutes ' , 'ru n _dura t io n _huma n ized' : ' 0 mi nutes ' , 'crea te d_a t _huma n ized' : ' 0 mi nutes ago' , ' f i n ished_a t _huma n ized' : ' 0 mi nutes fr om n ow' , 'job_id' : 1 , 'is_ru nn i n g' : No ne } }","title":"Examples"}]}